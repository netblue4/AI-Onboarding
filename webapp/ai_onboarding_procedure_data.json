{
    "(A.9.4) AI system's intended use and limitations": {
        "WebFormTitle": "Document the purpose, target users, and intended use cases of the AI system.",
        "Fields": [
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - AI System ID",
                "FieldLabel": "AI System ID",
                "FieldText": "AI System Unique Number",
                "FieldType": "Auto generated number"
            },
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - Name",
                "FieldLabel": "Name",
                "FieldText": "Name of the AI application",
                "FieldType": "TextBox"
            },
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - Target Users",
                "FieldLabel": "",
                "FieldText": "Who are the Target Users of the Ai system?",
                "FieldType": "Dropdown box with values:/Employees/Customers/Analysts/Customer/Supplier/Partner/Regulator"
            },
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - Business Purpose",
                "FieldLabel": "Business Purpose",
                "FieldText": "What specific business problem or task does this system address?",
                "FieldType": "TextBox"
            },
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - Intended Use",
                "FieldLabel": "Intended Use",
                "FieldText": "Describe the use cases of how the AI system will solve the specific business problem or task",
                "FieldType": "TextBox"
            }
        ]
    },
     "(A.6.2.2) AI system's Functional Requirement": {
        "WebFormTitle": "Document all requirements for new AI systems or for material enhancements to existing systems.",
        "Fields": [       
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Processing Logic",
                "FieldLabel": "Processing Logic",
                "FieldText": "What’s the core logic or model behavior expected?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Outputs",
                "FieldLabel": "Outputs",
                "FieldText": "What outputs should the system produce?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Interaction Model",
                "FieldLabel": "Interaction Model",
                "FieldText": "Will it run in the background, have a UI, API, etc.?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Performance",
                "FieldLabel": "Performance",
                "FieldText": "Are there any SLA's associated with the AI system?",
                "FieldType": "TextBox"
            }
        ]
    },
    "AI Act Prohibited Practices Assessment": {
        "WebFormTitle": "Determine if the AI system falls under prohibited practices according to the AI Act.",
        "Fields": [
            {
                "FieldName": "Subliminal Manipulation",
                "FieldLabel": "Subliminal Manipulation",
                "FieldText": "Does the AI system deploy techniques beyond a person's consciousness to materially distort their behavior in a way that is likely to cause harm?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Exploitation of Vulnerabilities",
                "FieldLabel": "Exploitation of Vulnerabilities",
                "FieldText": "Does the AI system exploit vulnerabilities of a specific group (e.g., due to age, physical or mental disability, social or economic situation) to materially distort their behavior in a way likely to cause harm to that person or another?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Social Scoring",
                "FieldLabel": "Social Scoring",
                "FieldText": "Is the AI system used by public authorities for evaluating or classifying the trustworthiness of natural persons based on their social behavior or personal characteristics, leading to detrimental or unfavorable treatment?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Real-time Remote Biometric Identification",
                "FieldLabel": "Biometric Identification",
                "FieldText": "Is the AI system used by law enforcement for real-time remote biometric identification of natural persons in publicly accessible spaces? (Note: Very limited exceptions exist)",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Emotion Inference",
                "FieldLabel": "Emotion Inference",
                "FieldText": "Does the AI system infer emotions of natural persons in the context of workplaces or educational institutions?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Biometric Categorization",
                "FieldLabel": "Biometric Categorization",
                "FieldText": "Does the AI system use biometric data to categorize natural persons based on sensitive attributes like race, political opinions, trade union membership, religious or philosophical beliefs, or sexual orientation?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Untargeted Scraping of Facial Images",
                "FieldLabel": "Untargeted Scraping of Facial Images",
                "FieldText": "Does the AI system involve untargeted scraping of facial images from the internet or CCTV footage to create or expand facial recognition databases?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Risk Assessment of Criminal Offenses (Profiling)",
                "FieldLabel": "Criminal Offenses (Profiling)",
                "FieldText": "Does the AI system assess the risk of a natural person committing a criminal offense based solely on profiling or assessment of their personality traits or characteristics?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "AI system is Prohibited",
                "FieldLabel": "AI system is Prohibited",
                "FieldText": "If the answer to any of these questions is \"Yes,\" the AI system may be prohibited under the AI Act.||For a more detailed assessment, you can refer to the EU AI Act Compliance Checker: https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/",
                "FieldType": "Option box with values:Yes/No"
            }
        ]
    },
    "Decision point": {
        "WebFormTitle": "If the system is Prohibited then Exit else continue to next step.",
        "Fields": [
            {
                "FieldName": "Prohibited Practices - AI system is Prohibited",
                "FieldLabel": "FieldName = the field to interigate to determine the decision branch.",
                "FieldText": "If the answer to any of these questions is \"Yes,\" the AI system may be prohibited under the AI Act.\nFor a more detailed assessment, you can refer to the EU AI Act Compliance Checker||https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/",
                "FieldType": "Decision:Yes=Document AI system approvals/No=Determine the AI system's Data Sensitivity & Privacy impact",
                "YesTarget": "Document AI system approvals",
                "NoTarget": "Determine the AI System Significance"
            }
        ]
    },
    "(5.4) Assessing AI system impact on individuals or groups of individuals": {
        "WebFormTitle": "Assess the AI system's impact on individuals or groups of individuals.",
        "Fields": [
                {
                    "FieldName": "AI system impact assessment - Employees - Benefits",
                    "FieldLabel": "Employees",
                    "FieldText": "Select Potential Benefits:",
                    "FieldType": "Option box with values:Faster Service/Reduced Error Rate/Increased Efficiency/Personalized Training or Upskilling/Better Decision-Making Tools"
                },
            
            {
                "FieldType": "risk",
                "FieldName": "Data Privacy and Protection in AI Systems",
                "question": "Are the implemented tools, policies, and training sufficient to ensure the privacy, confidentiality, and security of user data throughout AI system operation?",
                "controls": [
                      {
                        "control": "DP-DP-01 - 01: Maintain and update a Data Privacy Implementation Guide that prescribes encryption, anonymization, and access control measures.",
                        "control_objective": "To ensure that strong privacy-preserving mechanisms are consistently implemented in AI systems."
                      },
                      {
                        "control": "DP-DP-01 - 02: Develop and maintain Data Privacy Training Modules to educate personnel on privacy protection practices.",
                        "control_objective": "To enhance personnel awareness and compliance with data privacy requirements."
                      },
                      {
                        "control": "DP-DP-01 - 03: Produce a Data Privacy Compliance Report documenting compliance status and identifying gaps in privacy enforcement.",
                        "control_objective": "To continuously monitor and validate compliance with privacy standards."
                      },
                      {
                        "control": "DP-DP-01 - 04: Maintain official Data Privacy Policy Documents describing organizational commitments and policies.",
                        "control_objective": "To establish organizational accountability for data protection."
                      },
                      {
                        "control": "DP-DP-01 - 05: Keep staff training materials and records on data privacy practices.",
                        "control_objective": "To provide auditable evidence of personnel training and compliance on privacy matters."
                      },
                      {
                        "control": "DP-DP-01 - 06: Document results from penetration tests assessing privacy vulnerabilities.",
                        "control_objective": "To validate that privacy protocols effectively resist breaches and intrusions."
                      },
                      {
                        "control": "DP-DP-01 - 07: Produce Data Privacy Tools and Protocol Documentation for encryption, anonymization, and access controls.",
                        "control_objective": "To ensure transparency and reproducibility of privacy safeguards."
                      },
                      {
                        "control": "DP-DP-01 - 08: Maintain Data Access and Privacy Logs to track use of sensitive data.",
                        "control_objective": "To detect and investigate any unauthorized access or misuse of personal data."
                      }
                ]
              },                        
              {
    "FieldType": "risk",
    "FieldName": "Environmental Sustainability of AI Systems",
    "question": "Do AI systems incorporate proper environmental assessments, eco-efficient practices, and sustainable lifecycle management controls to minimize ecological impacts?",
    "controls": [
      {
        "control": "EA-EI-01 - 01: Implement and update an Environmental Impact Assessment Protocol for AI systems.",
        "control_objective": "To systematically evaluate the ecological footprint of AI systems across their lifecycle."
      },
      {
        "control": "EA-EI-01 - 02: Maintain a Sustainability Implementation Guide that prescribes eco-friendly design and operation practices.",
        "control_objective": "To ensure integration of sustainable practices in AI development and deployment."
      },
      {
        "control": "EA-EI-01 - 03: Provide a Green Technology Training Program to educate stakeholders on sustainable AI technologies.",
        "control_objective": "To build organizational capacity for green development practices in AI."
      },
      {
        "control": "EA-EI-01 - 04: Maintain environmental impact assessment reports with findings on data center, algorithm, and hardware impacts.",
        "control_objective": "To measure and document the environmental risks associated with AI systems."
      },
      {
        "control": "EA-EI-01 - 05: Maintain energy-efficient computing policies and green data center use guidelines.",
        "control_objective": "To reduce energy consumption and promote efficient data center operations."
      },
      {
        "control": "EA-EI-01 - 06: Keep documentation on hardware recycling and disposal procedures.",
        "control_objective": "To ensure responsible management of AI hardware across its lifecycle."
      },
      {
        "control": "EA-EI-01 - 07: Document algorithm selection guidelines that factor in energy efficiency.",
        "control_objective": "To promote the use of algorithms that minimize resource consumption."
      },
      {
        "control": "EA-EI-01 - 08: Maintain data center sustainability certifications and energy consumption records.",
        "control_objective": "To provide independent verification of data center sustainability practices."
      }
    ]
  },
  {
    "FieldType": "risk",
    "FieldName": "Workforce Transition and Adaptation for AI Integration",
    "question": "Are workforce adaptation and training strategies sufficient to address risks from job role evolution due to AI adoption?",
    "controls": [
      {
        "control": "HI-WF-01 - 01: Maintain a Workforce Transition Plan detailing workforce transformation steps, timelines, and training requirements.",
        "control_objective": "To systematically manage workforce adaptation as AI is deployed."
      },
      {
        "control": "HI-WF-01 - 02: Provide an AI Training Program for employees developing skills in new AI-enabled roles.",
        "control_objective": "To equip staff with the competencies necessary for AI-era job responsibilities."
      },
      {
        "control": "HI-WF-01 - 03: Operate a Role Evolution Tracking System to monitor job function changes resulting from AI integration.",
        "control_objective": "To proactively manage and track workforce role evolution."
      },
      {
        "control": "HI-WF-01 - 04: Maintain a Training Needs Analysis to discover skills gaps arising from AI-enabled transformation.",
        "control_objective": "To continuously assess and respond to workforce reskilling needs."
      },
      {
        "control": "HI-WF-01 - 05: Implement a Role Evolution Framework for adapting career paths and support structures.",
        "control_objective": "To provide clarity and fairness in career transformation due to AI."
      },
      {
        "control": "HI-WF-01 - 06: Produce a Training Effectiveness Report measuring the success of workforce transition training programs.",
        "control_objective": "To evaluate whether training equips employees effectively for new AI roles."
      },
      {
        "control": "HI-WF-01 - 07: Prepare a Job Evolution Roadmap outlining projected role transformations.",
        "control_objective": "To anticipate and plan for role changes across the organization."
      }
    ]
  },
              {
    "FieldType": "risk",
    "FieldName": "Protection of Vulnerable Populations in AI Deployment",
    "question": "Are there adequate measures to ensure AI deployments do not unfairly impact or discriminate against vulnerable populations, and are controls in place to prevent unethical outcomes?",
    "controls": [
      {
        "control": "RM-EI-01 - 01: Establish and maintain a Vulnerable Population Protection Plan documenting approaches to safeguard vulnerable groups in AI deployments.",
        "control_objective": "To ensure that AI deployment includes effective measures to protect vulnerable populations from unfair discrimination or unethical considerations.",
        "risk_name": "Unprotected vulnerable populations leading to discrimination in AI deployment."
      },
      {
        "control": "RM-EI-01 - 02: Implement documented Impact Mitigation Strategies to reduce negative effects on vulnerable groups identified during AI system assessments.",
        "control_objective": "To minimize the adverse impacts of AI systems on vulnerable populations through documented mitigation strategies.",
        "risk_name": "Insufficient mitigation causing adverse effects on vulnerable groups."
      },
      {
        "control": "RM-EI-01 - 03: Apply a Vulnerability Assessment Protocol to evaluate and address risks for vulnerable populations in AI system deployment.",
        "control_objective": "To rigorously assess and manage vulnerabilities affecting sensitive groups in AI deployments.",
        "risk_name": "Unassessed vulnerabilities leading to unnoticed risks for vulnerable populations."
      },
      {
        "control": "RM-EI-01 - 04: Use a Vulnerability Impact Assessment Framework to formally analyze AI system effects on vulnerable communities.",
        "control_objective": "To ensure systematic assessment of the impacts of AI systems on vulnerable populations.",
        "risk_name": "Insufficient impact analysis resulting in harm to vulnerable groups."
      },
      {
        "control": "RM-EI-01 - 05: Enforce Child Protection Protocols to safeguard children from harmful impacts of AI systems.",
        "control_objective": "To protect minors from negative effects and risks posed by AI systems.",
        "risk_name": "Lack of child protection in AI deployment."
      },
      {
        "control": "RM-EI-01 - 06: Maintain Mitigation Strategy Documents detailing plans developed to address risks identified for vulnerable populations.",
        "control_objective": "To document and implement comprehensive mitigation strategies for vulnerable groups exposed to AI risks.",
        "risk_name": "Undocumented mitigation resulting in unmanaged risks."
      },
      {
        "control": "RM-EI-01 - 07: Prepare a Vulnerable Populations Protection Plan including strategies and evidence of safeguarding efforts.",
        "control_objective": "To ensure robust and transparent safeguarding approaches for vulnerable populations in AI implementation.",
        "risk_name": "Deficient safeguarding strategy for vulnerable populations."
      },
      {
        "control": "RM-EI-01 - 08: Document an Adverse Impact Mitigation Report that details actions taken to reduce negative outcomes for vulnerable groups.",
        "control_objective": "To transparently record mitigation actions and outcomes related to vulnerable populations.",
        "risk_name": "Omission of negative impact mitigation."
      },
      {
        "control": "RM-EI-01 - 09: Develop an Impact Assessment Toolkit focused on identifying and assessing risks for vulnerable groups including children.",
        "control_objective": "To provide actionable tools and procedures for identifying risks to vulnerable populations prior to AI system deployment.",
        "risk_name": "Unidentified risks due to lack of assessment tools."
      }
    ]
  },
  {
    "FieldType": "risk",
    "FieldName": "High-Risk AI System Impact Assessment",
    "question": "Are required fundamental rights impact assessments, mitigation plans, and system registrations being conducted and documented for high-risk AI systems?",
    "controls": [
      {
        "control": "RM-AI-01 - 01: Maintain an Impact Assessment Report documenting the outcomes and procedures of fundamental rights impact assessments for AI systems.",
        "control_objective": "To ensure all high-risk AI systems are rigorously assessed for their impact on fundamental rights before deployment.",
        "risk_name": "Deployment of high-risk AI systems without fundamental rights assessment."
      },
      {
        "control": "RM-AI-01 - 02: Prepare and maintain a Mitigation Plan Document outlining strategies to address risks discovered during impact assessments.",
        "control_objective": "To document and execute effective mitigation strategies for risks associated with high-risk AI systems.",
        "risk_name": "Lack of mitigation planning for high-risk AI systems."
      },
      {
        "control": "RM-AI-01 - 03: Ensure System Registration in Public Database for all identified high-risk AI systems, including confirmation of registration.",
        "control_objective": "To guarantee transparency and accountability by publicly registering high-risk AI systems.",
        "risk_name": "Unregistered high-risk AI systems operating without oversight."
      },
      {
        "control": "RM-AI-01 - 04: Generate a Fundamental Rights Impact Assessment Report that documents identified impacts on individual rights.",
        "control_objective": "To enable compliance monitoring and protection of rights affected by AI deployment.",
        "risk_name": "Insufficient documentation of rights impacts in high-risk AI systems."
      },
      {
        "control": "RM-AI-01 - 05: Maintain a Risk Mitigation Plan identifying actions to address every risk found during the rights assessments.",
        "control_objective": "To ensure continuous improvement and monitoring of mitigation actions for risks to individuals.",
        "risk_name": "Risks remain unaddressed due to missing mitigation records."
      },
      {
        "control": "RM-AI-01 - 06: Retain AI System Registration Proof that confirms listing in the designated high-risk public database.",
        "control_objective": "To verify compliance with external registry and transparency requirements for high-risk AI systems.",
        "risk_name": "AI systems risk evading public transparency without registry proof."
      },
      {
        "control": "RM-AI-01 - 07: Provide a Fundamental Rights Impact Assessment Report for tracking assessment results and impacts.",
        "control_objective": "To support regular review and monitoring of rights impacts over time.",
        "risk_name": "Failure to track and monitor evolving rights impacts."
      },
      {
        "control": "RM-AI-01 - 08: Maintain a Mitigation Strategy Document specifying actionable plans to address each identified risk.",
        "control_objective": "To enable effective implementation and follow-up of mitigation actions.",
        "risk_name": "Unimplemented or unaccounted-for mitigation strategies."
      },
      {
        "control": "RM-AI-01 - 09: Secure a Registration Confirmation Receipt from the public database for all high-risk AI systems.",
        "control_objective": "To document final registration status and facilitate auditability.",
        "risk_name": "Lack of official audit trail for system registration."
      }
    ]
  },
  {
    "FieldType": "risk",
    "FieldName": "Predeployment Impact Assessment",
    "question": "Are comprehensive predeployment assessments carried out for high-risk AI systems—including user, process, and environmental impact evaluations—and are controls in place for responsible deployment?",
    "controls": [
      {
        "control": "RM-AI-02 - 01: Implement a documented Predeployment Assessment Procedure for evaluating high-risk AI impacts before deployment.",
        "control_objective": "To ensure all high-risk AI systems undergo thorough predeployment impact evaluations.",
        "risk_name": "Inadequate predeployment assessment for high-risk AI systems."
      },
      {
        "control": "RM-AI-02 - 02: Utilize an Impact Evaluation Report Template to capture and structure assessment findings for each deployment.",
        "control_objective": "To ensure consistent and comprehensive documentation of impact findings across all high-risk deployments.",
        "risk_name": "Unstructured or incomplete recording of deployment impacts."
      },
      {
        "control": "RM-AI-02 - 03: Deliver Risk Assessment Training Modules to teams involved in conducting predeployment risk evaluations.",
        "control_objective": "To maintain skilled, well-trained teams able to identify and address deployment risks effectively.",
        "risk_name": "Untrained personnel conducting critical risk assessments."
      },
      {
        "control": "RM-AI-02 - 04: Create and maintain a Predeployment Assessment Report that documents detailed impact evaluation findings for each AI system prior to launch.",
        "control_objective": "To establish a clear record of risks and impacts associated with each high-risk AI deployment.",
        "risk_name": "Deployment of high-risk AI systems without detailed assessment records."
      },
      {
        "control": "RM-AI-02 - 05: Conduct and document a User Impact Analysis to determine how AI systems may affect end users predeployment.",
        "control_objective": "To identify and protect end users from negative consequences of AI implementation.",
        "risk_name": "Unidentified user impacts leading to unintended harm."
      },
      {
        "control": "RM-AI-02 - 06: Carry out an Environmental Impact Study prior to deployment to analyze potential effects of AI systems on surroundings.",
        "control_objective": "To ensure all environmental risks are identified and addressed before AI system rollout.",
        "risk_name": "Environmental consequences going unrecognized in AI deployments."
      },
      {
        "control": "RM-AI-02 - 07: Prepare a Predeployment Impact Assessment Report containing technical and procedural findings for each high-risk AI system.",
        "control_objective": "To enable stakeholders to understand, mitigate, and monitor risks associated with new deployments.",
        "risk_name": "Stakeholders unprepared for deployment risks due to missing reports."
      },
      {
        "control": "RM-AI-02 - 08: Maintain a Risk Mitigation Plan outlining concrete steps for managing predeployment risks identified in assessments.",
        "control_objective": "To put effective controls in place ahead of each deployment for minimizing identified risks.",
        "risk_name": "Deployment without actionable risk mitigation steps."
      },
      {
        "control": "RM-AI-02 - 09: Document Environmental Impact Statements for each deployment as evidence of compliance and environmental evaluation.",
        "control_objective": "To verify that all environmental concerns have been comprehensively evaluated and addressed.",
        "risk_name": "Environmental risks remain unmanaged due to lack of documentation."
      }
    ]
  }
        ]
    },
    "(A.4.4) AI Systems Software and Tooling Resources": {
        "WebFormTitle": "Define the software and tools used by the AI system.",
        "Fields": [
            {
                "FieldName": "(A.4.2, A.4.4) - Tool Name and Version",
                "FieldLabel": "Tool Name and Version",
                "FieldText": "Name of the software, library, or framework and Version number.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.4) - Category",
                "FieldLabel": "",
                "FieldText": "Category of the tool?",
                "FieldType": "Dropdown box with values:/Programming Language/IDE/Data Processing/ML Framework/Version Control/Deployment"
            },
            {
                "FieldName": "(A.4.2, A.4.4) - Purpose/Use Case in Project",
                "FieldLabel": "Purpose/Use Case in Project",
                "FieldText": "Tooling Resources: How this tool will be used in the AI system's lifecycle.",
                "FieldType": "TextBox"
            }
        ]
    },
    "(A.4.5) AI Systems Computing Resources": {
        "WebFormTitle": "Define the computing resources used by the AI system",
        "Fields": [
            {
                "FieldName": "(A.4.2, A.4.5) - Computing Resource Name and Version",
                "FieldLabel": "Computing Resource Name and Version",
                "FieldText": "Name of the software, library, or framework.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.5) - Category",
                "FieldLabel": "",
                "FieldText": "Category of the computing resource.",
                "FieldType": "Dropdown box with values:/Dev Workstation/ML Training Cluster/Inference API Server/Data Lake Storage/EC2/S3/SQL Database"
            },
            {
                "FieldName": "(A.4.2, A.4.5) - Lifecycle Phase(s) Supported",
                "FieldLabel": "",
                "FieldText": "Which part of the AI lifecycle does this resource supports?",
                "FieldType": "Dropdown box with values:/Development/Training/Testing/Staging/Production/Monitoring"
            }
        ]
    },
    "(A.4.3) AI Systems Data Resources": {
        "WebFormTitle": "Define the data resources used by the AI system.",
        "Fields": [
            {
                "FieldName": "(A.4.2, A.4.3) - Dataset Name",
                "FieldLabel": "Dataset Name",
                "FieldText": "Common or descriptive name of the dataset.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Description",
                "FieldLabel": "Description",
                "FieldText": "Brief overview of the dataset's content and general purpose.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.3, A.7.5) - Source",
                "FieldLabel": "",
                "FieldText": "Where does the data originate from?",
                "FieldType": "Dropdown box with values:/Internal database/Third-party vendor/Public repository/Synthetic generation"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Intended Use",
                "FieldLabel": "",
                "FieldText": "What is the specific purpose(s) of the data?",
                "FieldType": "Dropdown box with values:/Training data/Validation data/Test data/Production data"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Format",
                "FieldLabel": "",
                "FieldText": "What is the File format or storage system?",
                "FieldType": "Dropdown box with values:/CSV/JSON/Parquet/SQL DB"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Data Labeling",
                "FieldLabel": "",
                "FieldText": "How is the Data Labeled?",
                "FieldType": "Dropdown box with values:/Sensitive/Internal/Public"
            },
            {
                "FieldName": "(A.4.2, A.4.3, A.7.3,A.7.2) - Acquisition of data",
                "FieldLabel": "",
                "FieldText": "How will the Data be acquired and selected?",
                "FieldType": "Dropdown box with values:/Extracted from internal company databases (e.g., CRM, ERP)/Sourced from a publicly available dataset/Purchased or licensed from a third-party data provider/Collected directly from users with explicit consent/Scraped from public websites in compliance with terms of service/Streamed from IoT sensors or application logs/Artificially generated (synthetic data)/Selected based on defined quality and relevance criteria/Manually curated by subject matter experts/Sampled to ensure fair representation of subgroups (stratified sampling)/A combination of multiple sources/methods/Other (requires specific documentation)"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Retention Schedules",
                "FieldLabel": "",
                "FieldText": "What is the data Retention schedules based on legal and operational requirements?",
                "FieldType": "Dropdown box with values:/1 Year/5 Years/10 Years"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Secure Disposing",
                "FieldLabel": "Secure Disposing",
                "FieldText": "Descripbe the Secure methods for disposing of obsolete or redundant data.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Approximate Size",
                "FieldLabel": "Approximate Size",
                "FieldText": "What is the Estimated size of the data (e.g., number of records, GB, TB)?",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Access Method",
                "FieldLabel": "",
                "FieldText": "How will the data be accessed?",
                "FieldType": "Dropdown box with values:/S3 bucket path/API endpoint/Database query/Shared drive"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Owner/Custodian",
                "FieldLabel": "Owner/Custodian",
                "FieldText": "Person or team responsible for the data?",
                "FieldType": "TextBox"
            }
        ]
    },
    "(A.7.4) AI System Data Quality Requirements for Sensitive data": {
        "WebFormTitle": "Define the AI system's Data Quality Requirements for Sensitive data.",
        "Fields": [ 
            {
                "FieldName": "(A.7.4) - Accuracy",
                "FieldLabel": "Accuracy",
                "FieldText": "Specify the minimum acceptable accuracy level, defined as the percentage of data points that are correct when compared to a trusted source.",
                "FieldType": "Dropdown box with values:/> 95%/> 50%/> 20%"
            },
            {
                "FieldName": "(A.7.4) - Completeness",
                "FieldLabel": "Completeness",
                "FieldText": "Specify the required level of data completeness, ensuring that all necessary data fields are populated.",
                "FieldType": "Dropdown box with values:/All critical information present/No nulls in essential fields/> 98% completeness for important fields"
            },
            {
                "FieldName": "(A.7.4) - Consistency",
                "FieldLabel": "Consistency",
                "FieldText": "Define the requirement for data consistency, ensuring data is free from logical contradictions and maintains integrity across related datasets.",
                "FieldType": "Dropdown box with values:/No contradictory information/No logical contradictions/< 1% inconsistency rate"
            },
            {
                "FieldName": "(A.7.4) - Recency",
                "FieldLabel": "Recency",
                "FieldText": "Specify how frequently the data must be updated to be considered current for its intended use.",
                "FieldType": "Dropdown box with values:/Real-time/Daily/Monthly/Yearly"
            },
            {
                "FieldName": "(A.7.4) - Source Traceability",
                "FieldLabel": "",
                "FieldText": "Specify whether the origin and history (provenance) of the data can be fully traced and verified.",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "(A.7.4) - Versioning Applied",
                "FieldLabel": "",
                "FieldText": "Specify the system or method used to manage and track different versions of the dataset.",
                "FieldType": "Dropdown box with values:/Git/DVC/Manual/Not Applicable"
            }
        ]
    },
    "(A.7.6) AI System Data Preparation Plan for Sensitive data": {
        "WebFormTitle": "Define the AI system's Data Preparation Plan for Sensitive Data.",
        "Fields": [ 
            {
                "FieldName": "(A.7.2, A.7.6) - De-identification & Anonymization - Masking",
                "FieldLabel": "Masking",
                "FieldText": "Replace parts of sensitive data with a generic character (e.g., 'XXX-XX-1234' for a Social Security Number).",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - De-identification & Anonymization - Tokenization",
                "FieldLabel": "Tokenization",
                "FieldText": "Replace a sensitive data element with a non-sensitive equivalent, referred to as a \"token.\" The original data is stored in a secure vault.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - De-identification & Anonymization - Hashing",
                "FieldLabel": "Hashing",
                "FieldText": "Data Preparation Plan - Hashing||Use a cryptographic function to convert sensitive data into a fixed-size string of characters. It's a one-way process.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - De-identification & Anonymization - Generalization",
                "FieldLabel": "Generalization",
                "FieldText": "Reduce the precision of data. For example, changing a specific age ('34') to an age range ('30-40') or a full date of birth to just the year.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Access Control & Governance - Data Segregation",
                "FieldLabel": "Data Segregation",
                "FieldText": "Create physically or logically separate data stores for sensitive information, with strict access controls.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Access Control & Governance - Attribute-Based Access Control",
                "FieldLabel": "Attribute-Based Access Control",
                "FieldText": "Apply rules so that only users with specific attributes (e.g., role, department) can access certain data fields.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Minimization - Feature Pruning",
                "FieldLabel": "Feature Pruning",
                "FieldText": "Remove any data fields or columns that are not strictly necessary for the AI model's purpose.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Minimization",
                "FieldLabel": "Data Minimization",
                "FieldText": "Remove records of individuals who have not given consent for their data to be used for AI training.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Quality & Integrity (Post-Anonymization) - Integrity Checks",
                "FieldLabel": "Integrity Checks",
                "FieldText": "After de-identification, verify that relationships between anonymized fields (e.g., a tokenized user ID and their records) remain intact.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Cleaning & Quality - Handling Missing Values",
                "FieldLabel": "Handling Missing Values",
                "FieldText": "Remove empty or null fields, such as filling them with a mean/median/mode, or removing the row/column.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Cleaning & Quality - Correcting Inaccuracies",
                "FieldLabel": "Correcting Inaccuracies",
                "FieldText": "Identify and fixing demonstrably incorrect data points (e.g., typos, out-of-range values like a temperature of '1000°C').",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Cleaning & Quality - Removing Duplicates",
                "FieldLabel": "Removing Duplicates",
                "FieldText": "Identify and deleting redundant records from the dataset.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            }
        ]
    },
    "(A.8.4) AI System Documentation and User Information": {
        "WebFormTitle": "Define and document the information, reporting, and incident communication plan for all internal and external interested parties.",
        "Fields": [
            {
                "FieldName": "(A.8.4) - Incident Communication Plan - Data Breach",
                "FieldLabel": "Data Breach",
                "FieldText": "Describe how incidents related to \"Unintended exposure of training data\" will be comunicated.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.8.4) - Incident Communication Plan - Model Misuse",
                "FieldLabel": "Model Misuse",
                "FieldText": "Describe how incidents related to \"AI model used outside intended scope\" will be comunicated.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.8.4) - Incident Communication Plan - Model Failure",
                "FieldLabel": "Model Failure",
                "FieldText": "Describe how incidents related to \"False predictions causing harm\" will be comunicated.",
                "FieldType": "TextBox"
            }
        ]
    },
    "AI Act - Section 2: Requirements for High-Risk AI Systems": {
        "WebFormTitle": "If the AI system is categorised as high-risk according to the AI Acty, define the security requirements for - High-Risk AI Systems.",
        "Fields": [
            {
                "FieldType": "risk",
                "FieldName": "[Article 8] - Non-Compliance with High-Risk AI System Requirements",
                "question": "Is the AI system, or the product incorporating the AI system, subject to other EU regulations, and if so, how is compliance with all applicable regulations, including the AI Act, managed and documented?",
                "controls": [
                 {
                  "control": "[Art-8][Par-1][1] - Establish and maintain a documented process to ensure and demonstrate that high-risk AI systems comply with the requirements of Section 2 of the AI Act, considering the system's intended purpose and the state of the art in AI.",
                  "control_objective": "To ensure that high-risk AI systems meet all legal and technical standards set forth in the AI Act, and to have a clear, auditable trail of compliance."
                 },
                 {
                  "control": "[Art-8][Par-2][2] - For products containing a high-risk AI system that are also subject to other Union harmonisation legislation, ensure the product is fully compliant with all applicable requirements from all relevant regulations.",
                  "control_objective": "To achieve comprehensive legal compliance for products that incorporate AI systems and are subject to multiple regulatory frameworks."
                 },
                 {
                  "control": "[Art-8][Par-2][3] - Where applicable, integrate the testing, reporting, and documentation processes required by the AI Act with existing compliance processes under other EU legislation to ensure consistency, avoid duplication, and minimize administrative burden.",
                  "control_objective": "To streamline compliance activities, improve efficiency, and ensure a coherent approach to regulatory requirements across different legal instruments."
                 }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 9] - Inadequate or Ineffective Risk Management",
                "question": "Does the organization have a documented and continuously updated risk management system for its high-risk AI systems that covers the entire lifecycle of the system?",
                "controls": [
                  {
                    "control": "[Art-9][Par-1][1] - Establish, implement, document, and maintain a comprehensive risk management system for high-risk AI systems.",
                    "control_objective": "To ensure a systematic and ongoing process for identifying, evaluating, and mitigating risks associated with high-risk AI systems throughout their lifecycle."
                  },
                  {
                    "control": "[Art-9][Par-2][2] - Implement a continuous iterative risk management process that includes regular systematic reviews and updates, covering identification, analysis, estimation, and evaluation of foreseeable risks.",
                    "control_objective": "To proactively manage and adapt to evolving risks by maintaining a dynamic and up-to-date risk management framework."
                  },
                  {
                    "control": "[Art-9][Par-2][3] - Adopt appropriate and targeted risk management measures to address identified risks, including those from post-market monitoring.",
                    "control_objective": "To effectively mitigate identified risks through the implementation of specific and relevant control measures."
                  },
                  {
                    "control": "[Art-9][Par-5][4] - Ensure that residual risks, both individual and overall, are acceptable by eliminating or reducing risks as far as technically feasible through design, implementing mitigation measures, and providing information and training.",
                    "control_objective": "To reduce the potential for harm to an acceptable level by employing a multi-layered approach to risk mitigation."
                  },
                  {
                    "control": "[Art-9][Par-6][5] - Conduct testing of high-risk AI systems to identify the most appropriate risk management measures and to ensure consistent performance and compliance with requirements.",
                    "control_objective": "To validate the effectiveness of risk management measures and ensure the AI system operates as intended."
                  },
                  {
                    "control": "[Art-9][Par-9][6] - Consider the potential adverse impact on persons under the age of 18 and other vulnerable groups when implementing the risk management system.",
                    "control_objective": "To provide heightened protection for vulnerable populations who may be disproportionately affected by the AI system."
                  }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 10] - Poor Data Quality and Governance",
                "question": "Are there appropriate data governance and management practices in place for the training, validation, and testing datasets used by the high-risk AI system to ensure they are relevant, representative, and free of errors and biases?",
                "controls": [
                  {
                    "control": "[Art-10][Par-2][1] - Implement and document data governance and management practices covering the entire data lifecycle, including design choices, collection, and preparation processes like annotation and cleaning.",
                    "control_objective": "To ensure that data used for high-risk AI systems is handled systematically and responsibly, maintaining quality and integrity from collection to use."
                  },
                  {
                    "control": "[Art-10][Par-2][2] - Establish a process to examine data sets for possible biases that could negatively impact fundamental rights, health, or safety, and implement measures to detect, prevent, and mitigate these biases.",
                    "control_objective": "To minimize the risk of discriminatory or unfair outcomes and ensure the AI system operates in a manner that is safe and respects fundamental rights."
                  },
                  {
                    "control": "[Art-10][Par-3][3] - Ensure that training, validation, and testing data sets are relevant, sufficiently representative, free of errors, and complete for the system's intended purpose, with appropriate statistical properties.",
                    "control_objective": "To build a robust and reliable AI system by using high-quality data that accurately reflects the operational environment and minimizes performance issues."
                  },
                  {
                    "control": "[Art-10][Par-4][4] - Verify that data sets account for the specific geographical, contextual, behavioral, or functional settings in which the high-risk AI system will be used.",
                    "control_objective": "To ensure the AI system performs effectively and as intended in its specific operational context, reducing the risk of failures due to environmental mismatches."
                  },
                  {
                    "control": "[Art-10][Par-5][5] - Where strictly necessary for bias detection and correction, process special categories of personal data only with appropriate safeguards, technical limitations, and security measures, ensuring data is deleted after use.",
                    "control_objective": "To enable effective bias mitigation while upholding the highest standards of data protection and privacy for sensitive personal information."
                  }
                ]
             },
             {
                "FieldType": "risk",
                "FieldName": "[Article 12] - Inadequate Traceability and Record-Keeping",
                "question": "Does the organization need to trace the operational history of its high-risk AI system to investigate incidents, audit results, or ensure accountability?",
                "controls": [
                 {
                  "control": "[Art-12][Par-1][1] - Implement capabilities for the automatic recording of events (logs) while the high-risk AI system is operating.",
                  "control_objective": "To ensure a level of traceability of the AI system’s functioning throughout its lifecycle that is appropriate to its intended purpose."
                 },
                 {
                  "control": "[Art-12][Par-2][2] - For high-risk AI systems covered by specific points in Annex III (e.g., biometrics, law enforcement), ensure logging capabilities record the period of each use, the reference database, the input data, and the identity of the persons involved in verifying the results.",
                  "control_objective": "To provide detailed operational transparency and accountability for AI systems used in critical public and justice-related applications."
                 },
                 {
                  "control": "[Art-12][Par-4][3] - For AI systems intended for remote biometric identification, ensure logging capabilities record the period of use, reference database, input data, and the identification of the person generating the match.",
                  "control_objective": "To enhance auditability and accountability in the use of sensitive remote biometric identification technologies."
                 }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 13] - Lack of Transparency and Provision of Information to Users",
                "question": "Will users of this AI system need to understand its capabilities, limitations, and the meaning of its outputs to use it safely and effectively?",
                "controls": [
                  {
                    "control": "[Art-13][Par-1] - Ensure the design of high-risk AI systems allows users to interpret outputs and use the system appropriately.",
                    "control_objective": "To enable safe and effective use of the AI system by ensuring user comprehension."
                  },
                  {
                    "control": "[Art-13][Par-2] - Provide clear, complete, and accessible instructions for use with all high-risk AI systems.",
                    "control_objective": "To ensure users have the necessary information to operate the AI system correctly and safely."
                  },
                  {
                    "control": "[Art-13][Par-3a] - Include the identity and contact details of the provider and their authorized representative in the instructions for use.",
                    "control_objective": "To establish clear lines of communication and accountability for the AI system."
                  },
                  {
                    "control": "[Art-13][Par-3b] - Detail the AI system's characteristics, capabilities, limitations, intended purpose, accuracy, robustness, cybersecurity, and performance metrics in the instructions for use.",
                    "control_objective": "To provide a comprehensive understanding of the AI system's operational parameters and performance expectations."
                  },
                  {
                    "control": "[Art-13][Par-3c-e-f] - Specify the necessary hardware resources, expected lifetime, maintenance, and pre-determined changes for operating the AI system in the instructions for use.",
                    "control_objective": "To ensure users have the required infrastructure and information to run and maintain the AI system effectively over its lifecycle."
                  },
                  {
                    "control": "[Art-13][Par-3d] - Detail the human oversight measures from Article 14, including technical aids for interpreting system outputs, in the instructions for use.",
                    "control_objective": "To facilitate effective human oversight and intervention in the AI system's operation."
                  }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 14] - Ineffective or Insufficient Human Oversight",
                "question": "Does the AI system operate in a way that requires human monitoring, intervention, or decision-making to prevent or mitigate risks to health, safety, or fundamental rights?",
                "controls": [
                  {
                    "control": "[Art-14][Par-1] - Design and develop high-risk AI systems with appropriate human-machine interface tools to enable effective oversight by natural persons.",
                    "control_objective": "To ensure that a human can effectively monitor and control the AI system while it is in use."
                  },
                  {
                    "control": "[Art-14][Par-2] - Implement human oversight to prevent or minimize risks to health, safety, or fundamental rights, especially those risks that persist after other requirements have been applied.",
                    "control_objective": "To provide a final layer of risk mitigation through active human involvement."
                  },
                  {
                    "control": "[Art-14][Par-3] - Ensure human oversight measures are built into the AI system by the provider or are appropriate for implementation by the deployer.",
                    "control_objective": "To integrate necessary oversight capabilities either directly into the system or into the operational procedures of the user."
                  },
                  {
                    "control": "[Art-14][Par-4a, 4b, 4c] - Enable assigned human overseers to understand the AI system's capabilities and limitations, monitor for anomalies, and correctly interpret its output, while remaining aware of potential automation bias.",
                    "control_objective": "To empower human overseers with the knowledge and awareness needed to make informed judgments about the system's performance."
                  },
                  {
                    "control": "[Art-14][Par-4d, 4e] - Enable assigned human overseers to have the ability to decide not to use the system, override its output, or interrupt its operation via a 'stop' button or similar procedure.",
                    "control_objective": "To ensure ultimate human control over the AI system's actions and decisions in any given situation."
                  },
                  {
                    "control": "[Art-14][Par-5] - For remote biometric identification systems, ensure that any identification is verified and confirmed by at least two competent, trained, and authorized natural persons before action is taken.",
                    "control_objective": "To increase the reliability and accountability of critical identification tasks performed by AI."
                  }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 15] - Inadequate Accuracy, Robustness, and Cybersecurity",
                "question": "Will poor AI performance (e.g., incorrect or unreliable outputs) cause business disruption, compliance issues, or customer dissatisfaction?",
                "controls": [
                  {
                    "control": "[Art-15][Par-1] - Ensure high-risk AI systems are designed and developed to achieve and maintain an appropriate level of accuracy, robustness, and cybersecurity throughout their lifecycle.",
                    "control_objective": "To maintain the system's trustworthiness and prevent harm from inaccurate or insecure operation."
                  },
                  {
                    "control": "[Art-15][Par-2] - Encourage the development of benchmarks and measurement methodologies for accuracy and robustness in cooperation with relevant stakeholders.",
                    "control_objective": "To establish standardized methods for evaluating and verifying the performance of AI systems."
                  },
                  {
                    "control": "[Art-15][Par-3] - Clearly state the levels of accuracy and the relevant accuracy metrics in the AI system's instructions for use.",
                    "control_objective": "To provide transparency to users about the system's expected performance."
                  },
                  {
                    "control": "[Art-15][Par-4] - Design AI systems to be resilient to errors, faults, or inconsistencies, using technical redundancies and fail-safe plans where appropriate, and mitigate risks from biased feedback loops in learning systems.",
                    "control_objective": "To ensure the system can handle unexpected situations and maintain stable performance without being negatively influenced by its own outputs."
                  },
                  {
                    "control": "[Art-15][Par-5] - Implement cybersecurity measures to protect high-risk AI systems from unauthorized alteration of their use, outputs, or performance by exploiting vulnerabilities.",
                    "control_objective": "To safeguard the AI system against malicious attacks such as data poisoning, model poisoning, and adversarial examples."
                  }
                ]
              }
        ]
    },
    
    "(6.2.1) AI Lifecycle Phase requirements - Design and Development": {
        "WebFormTitle": "Define the security requirements for lifecycle phase - Design and Development.",
        "Fields": [
          {
    "FieldType": "risk",
    "FieldName": "AI System Quality and Development Criteria",
    "question": "Are the established quality criteria for AI system datasets sufficient, adaptable, and consistently applied to ensure the development of high-risk AI systems meets required quality standards across different market segments?",
    "controls": [
      {
        "control": "SD-QS-01 - 01: Maintain a guide that outlines the **quality criteria** for AI system datasets.",
        "control_objective": "To ensure high-risk AI systems adhere to established quality criteria for datasets.",
        "risk": "Failure to develop high-risk AI systems that adhere to quality criteria due to undefined or undocumented dataset standards."
      },
      {
        "control": "SD-QS-01 - 02: Maintain a **plan** detailing how AI systems will be adapted to meet different market segment requirements.",
        "control_objective": "To ensure high-risk AI systems maintain dataset quality while allowing for **adaptability** based on the system's market segment or application.",
        "risk": "Inability to deploy high-risk AI systems across various market segments because the system's quality criteria lack the necessary adaptability."
      },
      {
        "control": "SD-QS-01 - 03: Establish a **protocol** for ensuring AI systems consistently meet the established quality criteria.",
        "control_objective": "To ensure high-risk AI systems adhere to established quality criteria for datasets.",
        "risk": "Release of AI systems that do not meet required quality standards due to the lack of a formal quality assurance protocol."
      },
      {
        "control": "SD-QS-01 - 04: Maintain **detailed documentation** specifying the quality criteria for datasets used in AI system development.",
        "control_objective": "To ensure high-risk AI systems adhere to established quality criteria for datasets.",
        "risk": "Dataset quality inconsistencies caused by a lack of clear and detailed documentation of quality criteria."
      },
      {
        "control": "SD-QS-01 - 05: Maintain **documentation** outlining how data quality criteria can be adapted based on the AI system's market segment or application.",
        "control_objective": "To ensure high-risk AI systems maintain dataset quality while allowing for adaptability based on the system's market segment or application.",
        "risk": "Mismatched data quality criteria for specific applications, resulting in system failures or suboptimal performance in target market segments."
      },
      {
        "control": "SD-QS-01 - 06: Maintain a **Quality Management System (QMS) Document** tailored for AI development outlining the quality criteria and processes.",
        "control_objective": "To ensure high-risk AI systems adhere to established quality criteria for datasets.",
        "risk": "Non-compliance with internal and external quality standards due to the absence of an AI-specific Quality Management System."
      },
      {
        "control": "SD-QS-01 - 07: Maintain a **Dataset Quality Assurance Report** detailing the measures taken to ensure datasets meet established criteria.",
        "control_objective": "To ensure high-risk AI systems adhere to established quality criteria for datasets.",
        "risk": "Unverified dataset quality due to a lack of formal reporting on quality assurance measures."
      },
      {
        "control": "SD-QS-01 - 08: Maintain a **Market Segment Adaptability Analysis** showing how the system's quality criteria are customized for various applications.",
        "control_objective": "To ensure high-risk AI systems maintain dataset quality while allowing for adaptability based on the system's market segment or application.",
        "risk": "Poor system performance in new market segments because quality criteria customization was not formally analyzed and documented."
      }
    ]
  },
  {
    "FieldType": "risk",
    "FieldName": "AI System Safety and Compliance",
    "question": "Is the enterprise consistently implementing regular safety and compliance checks across all AI systems, regardless of risk classification, to ensure adherence to minimum market safety standards?",
    "controls": [
      {
        "control": "SD-AV-01 - 01: Establish a **procedure** for conducting regular safety checks on all AI systems.",
        "control_objective": "To ensure enterprise AI systems meet minimum safety standards when released to the market by implementing regular safety and compliance checks.",
        "risk": "Release of unsafe AI systems due to the lack of a formalized procedure for conducting safety checks."
      },
      {
        "control": "SD-AV-01 - 02: Maintain a **checklist** of minimum safety standards that all AI systems must meet prior to release.",
        "control_objective": "To ensure enterprise AI systems meet minimum safety standards when released to the market by implementing regular safety and compliance checks.",
        "risk": "Failure to meet mandatory safety requirements due to the absence of a clear, comprehensive checklist of minimum safety standards."
      },
      {
        "control": "SD-AV-01 - 03: Implement a **system** for reporting compliance with established safety standards.",
        "control_objective": "To ensure enterprise AI systems meet minimum safety standards when released to the market by implementing regular safety and compliance checks.",
        "risk": "Non-compliance risks remaining undetected due to the lack of a formal and reliable compliance reporting system."
      },
      {
        "control": "SD-AV-01 - 04: Maintain **documentation** specifying the safety and compliance checks conducted for AI systems, including data-related aspects.",
        "control_objective": "To ensure enterprise AI systems meet minimum safety standards when released to the market by implementing regular safety and compliance checks.",
        "risk": "Inability to demonstrate due diligence in safety and compliance due to incomplete or absent documentation of checks performed."
      },
      {
        "control": "SD-AV-01 - 05: Maintain **reports** detailing the outcomes of safety assessments, including data-related findings.",
        "control_objective": "To ensure enterprise AI systems meet minimum safety standards when released to the market by implementing regular safety and compliance checks.",
        "risk": "Unaddressed safety vulnerabilities arising from a failure to formally document and review safety assessment findings."
      },
      {
        "control": "SD-AV-01 - 06: Maintain a **Universal Safety Standards Checklist** outlining the minimum safety criteria applicable to all AI systems.",
        "control_objective": "To ensure enterprise AI systems meet minimum safety standards when released to the market by implementing regular safety and compliance checks.",
        "risk": "Inconsistent application of safety standards across different AI systems due to a lack of a universal checklist."
      },
      {
        "control": "SD-AV-01 - 07: Maintain a **Compliance Certification** for each system released, affirming its adherence to minimum safety standards.",
        "control_objective": "To ensure enterprise AI systems meet minimum safety standards when released to the market by implementing regular safety and compliance checks.",
        "risk": "Release of non-compliant systems without formal sign-off on safety adherence."
      },
      {
        "control": "SD-AV-01 - 08: Maintain a **Premarket Safety Assessment Report** documenting the results of safety checks performed prior to release.",
        "control_objective": "To ensure enterprise AI systems meet minimum safety standards when released to the market by implementing regular safety and compliance checks.",
        "risk": "Release of systems without a premarket safety assessment, exposing the enterprise to unmitigated safety risks."
      }
    ]
  },
  {
    "FieldType": "risk",
    "FieldName": "AI System Security and Traceability",
    "question": "Do high-risk AI systems have robust, state-of-the-art automatic event logging capabilities to ensure full traceability and effective postmarket security monitoring?",
    "controls": [
      {
        "control": "SD-ST-01 - 01: Maintain **standards** for security design and event logging in high-risk AI systems.",
        "control_objective": "To ensure high-risk AI systems have built-in automatic event logging capabilities and adhere to state-of-the-art logging standards.",
        "risk": "Insecure or non-traceable AI systems due to the lack of formal design and logging standards."
      },
      {
        "control": "SD-ST-01 - 02: Maintain a **guide** for the implementation of the event logging systems in AI systems.",
        "control_objective": "To ensure high-risk AI systems have built-in automatic event logging capabilities and adhere to state-of-the-art logging standards.",
        "risk": "Inconsistent or incorrect implementation of event logging across high-risk AI systems."
      },
      {
        "control": "SD-ST-01 - 03: Maintain a **checklist** for ensuring compliance with security assessment and logging standards.",
        "control_objective": "To ensure high-risk AI systems have built-in automatic event logging capabilities and adhere to state-of-the-art logging standards.",
        "risk": "Failure to detect non-compliance with security and logging standards during the prelaunch assessment."
      },
      {
        "control": "SD-ST-01 - 04: Maintain **documentation** specifying the design of automatic event logging capabilities, including the data elements to capture.",
        "control_objective": "To ensure high-risk AI systems have built-in automatic event logging capabilities and adhere to state-of-the-art logging standards, capturing essential data for traceability and postmarket monitoring.",
        "risk": "Incomplete or irrelevant data capture in event logs, hindering effective postmarket monitoring and traceability."
      },
      {
        "control": "SD-ST-01 - 05: Maintain **records** of events captured by the system, including data elements for traceability and monitoring.",
        "control_objective": "To ensure high-risk AI systems have built-in automatic event logging capabilities and adhere to state-of-the-art logging standards, capturing essential data for traceability and postmarket monitoring.",
        "risk": "Inability to perform root cause analysis or track system behavior due to missing or corrupted event logs."
      },
      {
        "control": "SD-ST-01 - 06: Maintain a **Logging Capability Design Document** outlining the event logging architecture and how it adheres to state-of-the-art standards.",
        "control_objective": "To ensure high-risk AI systems have built-in automatic event logging capabilities and adhere to state-of-the-art logging standards.",
        "risk": "Logging architecture that is not scalable or fails to meet modern security standards."
      },
      {
        "control": "SD-ST-01 - 07: Maintain an **Event Log Report** that samples and demonstrates the data captured during system operations.",
        "control_objective": "To ensure high-risk AI systems have built-in automatic event logging capabilities and adhere to state-of-the-art logging standards, capturing essential data for traceability and postmarket monitoring.",
        "risk": "Undetected logging failures or data capture errors due to the lack of periodic sampling and review of event logs."
      },
      {
        "control": "SD-ST-01 - 08: Maintain a **Prelaunch Logging Test Summary** to confirm the system's logging capabilities before market release.",
        "control_objective": "To ensure high-risk AI systems have built-in automatic event logging capabilities and adhere to state-of-the-art logging standards.",
        "risk": "Deploying a system with non-functional or untested logging capabilities, compromising postmarket monitoring and traceability."
      }
    ]
  },
                {
        "FieldType": "risk",
        "FieldName": "Failure to Detect AI System Risks During Prerelease Testing",
        "question": "Are the national supervisory authority's mechanisms for organizing and overseeing prerelease testing of high-risk AI systems sufficient to ensure a comprehensive evaluation and effective risk mitigation?",
        "controls": [
            {
                "control": "SD-ST-02 - 01: Maintain a procedure testing coordination procedure A procedure for coordinating prerelease testing of high-risk AI systems.",
                "control_objective": "To ensure comprehensive and coordinated prerelease testing of high-risk AI systems by the national supervisory authority, setting robust testing parameters for effective evaluation."
            },
            {
                "control": "SD-ST-02 - 02: Establish guidelines testing parameter guidelines Guidelines for setting testing parameters.",
                "control_objective": "To ensure comprehensive and coordinated prerelease testing of high-risk AI systems by the national supervisory authority, setting robust testing parameters for effective evaluation."
            },
            {
                "control": "SD-ST-02 - 03: Maintain a template comprehensive evaluation report template A template for documenting the evaluation of AI systems.",
                "control_objective": "To ensure comprehensive and coordinated prerelease testing of high-risk AI systems by the national supervisory authority, setting robust testing parameters for effective evaluation."
            },
            {
                "control": "SD-ST-02 - 04: Maintain documentation testing oversight mechanism documentation Documentation outlining the mechanism for national supervisory authority oversight of high-risk AI system testing, including data-related aspects.",
                "control_objective": "To ensure comprehensive and coordinated prerelease testing of high-risk AI systems by the national supervisory authority, setting robust testing parameters for effective evaluation."
            },
            {
                "control": "SD-ST-02 - 05: Maintain testing parameters Specifications for testing parameters, including data-related criteria.",
                "control_objective": "To ensure comprehensive and coordinated prerelease testing of high-risk AI systems by the national supervisory authority, setting robust testing parameters for effective evaluation."
            },
            {
                "control": "SD-ST-02 - 06: Generate and maintain reports testing reports Reports generated as a result of the oversight and testing process, focusing on data-related findings.",
                "control_objective": "To ensure comprehensive and coordinated prerelease testing of high-risk AI systems by the national supervisory authority, setting robust testing parameters for effective evaluation."
            },
            {
                "control": "SD-ST-02 - 07: Maintain a protocol supervisory authority testing protocol which defines the methodologies and standards for testing",
                "control_objective": "To ensure comprehensive and coordinated prerelease testing of high-risk AI systems by the national supervisory authority, setting robust testing parameters for effective evaluation."
            },
            {
                "control": "SD-ST-02 - 08: Maintain a plan testing coordination plan that outlines the roles and responsibilities of the AI providers in the testing process",
                "control_objective": "To ensure comprehensive and coordinated prerelease testing of high-risk AI systems by the national supervisory authority, setting robust testing parameters for effective evaluation."
            },
            {
                "control": "SD-ST-02 - 09: Maintain testing report which documents the outcomes and any recommendations",
                "control_objective": "To ensure comprehensive and coordinated prerelease testing of high-risk AI systems by the national supervisory authority, setting robust testing parameters for effective evaluation."
            }
        ]
    },
    {
        "FieldType": "risk",
        "FieldName": "Model Intellectual Property Theft and Reverse Engineering",
        "question": "Is the model code obfuscation adequate to effectively prevent unauthorized reverse engineering and protect the AI system's proprietary algorithms?",
        "controls": [
            {
                "control": "SD-PC-01 - 01: Maintain the code obfuscation techniques guide code A guide detailing techniques for model code obfuscation.",
                "control_objective": "To prevent unauthorized intellectual property theft and reverse engineering by attackers through robust model code obfuscation."
            },
            {
                "control": "SD-PC-01 - 02: Maintain a record obfuscation implementation record A record of implementing code obfuscation in AI models.",
                "control_objective": "To prevent unauthorized intellectual property theft and reverse engineering by attackers through robust model code obfuscation."
            },
            {
                "control": "SD-PC-01 - 03: Maintain the code security training on  protection code Training materials for developers on code obfuscation techniques.",
                "control_objective": "To prevent unauthorized intellectual property theft and reverse engineering by attackers through robust model code obfuscation."
            },
            {
                "control": "SD-PC-01 - 04: Maintain a plan code obfuscation plan Documentation outlining the strategy and techniques used for obfuscating model code, including data protection considerations.",
                "control_objective": "To prevent unauthorized intellectual property theft and reverse engineering by attackers through robust model code obfuscation."
            },
            {
                "control": "SD-PC-01 - 05: Maintain the code obfuscated model code The actual obfuscated model code.",
                "control_objective": "To prevent unauthorized intellectual property theft and reverse engineering by attackers through robust model code obfuscation."
            },
            {
                "control": "SD-PC-01 - 06: Maintain a document obfuscation techniques document detailing the methods used to obfuscate the code",
                "control_objective": "To prevent unauthorized intellectual property theft and reverse engineering by attackers through robust model code obfuscation."
            },
            {
                "control": "SD-PC-01 - 07: Maintain the code obfuscated model base code which is the result of applying these techniques",
                "control_objective": "To prevent unauthorized intellectual property theft and reverse engineering by attackers through robust model code obfuscation."
            },
            {
                "control": "SD-PC-01 - 08: Maintain obfuscation efficacy report evaluating the strength of the obfuscation against reverse engineering attempts",
                "control_objective": "To prevent unauthorized intellectual property theft and reverse engineering by attackers through robust model code obfuscation."
            }
        ]
    },
    {
        "FieldType": "risk",
        "FieldName": "Unauthorized Access and Cyberattack on Model Information",
        "question": "Are the security measures for model information robust enough to prevent potential cyberattacks, unauthorized access, and ensure the integrity of the AI system?",
        "controls": [
            {
                "control": "SD-MP-01 - 01: Maintain a protocol model information security protocol A protocol for securing model information.",
                "control_objective": "To protect model information, including data and intellectual property, from potential cyberattacks and unauthorized access."
            },
            {
                "control": "SD-MP-01 - 02: Maintain a record cybersecurity measures implementation record A record of implementing cybersecurity measures for model protection.",
                "control_objective": "To protect model information, including data and intellectual property, from potential cyberattacks and unauthorized access."
            },
            {
                "control": "SD-MP-01 - 03: Provide training information security  modules training Training materials for IT staff on securing model information.",
                "control_objective": "To protect model information, including data and intellectual property, from potential cyberattacks and unauthorized access."
            },
            {
                "control": "SD-MP-01 - 04: Maintain a plan model information security plan Documentation outlining the strategies and measures implemented to secure model information, including data-related security controls.",
                "control_objective": "To protect model information, including data and intellectual property, from potential cyberattacks and unauthorized access."
            },
            {
                "control": "SD-MP-01 - 05: Maintain security logs security logs Records of security-related events and activities related to model information.",
                "control_objective": "To protect model information, including data and intellectual property, from potential cyberattacks and unauthorized access."
            },
            {
                "control": "SD-MP-01 - 06: Maintain a plan model information security plan which documents the security measures in place",
                "control_objective": "To protect model information, including data and intellectual property, from potential cyberattacks and unauthorized access."
            },
            {
                "control": "SD-MP-01 - 07: Generate and maintain an audit report information security audit report which provides an analysis of the model's security posture",
                "control_objective": "To protect model information, including data and intellectual property, from potential cyberattacks and unauthorized access."
            },
            {
                "control": "SD-MP-01 - 08: Maintain a plan cybersecurity incident response plan which would also be essential to outline actions to take in case of a security breach",
                "control_objective": "To protect model information, including data and intellectual property, from potential cyberattacks and unauthorized access."
            }
        ]
    },
            {
        "FieldType": "risk",
        "FieldName": "Compromise of AI System Integrity and Stability",
        "question": "How can ai system integrity maintenance measures ensure the AI system's integrity, and are there sufficient controls to prevent compromise of ai system integrity and stability?",
        "controls": [
            {
                "control": "SD-SR-01-01: Document and maintain integrity assurance protocol document: provides a step-by-step approach to maintaining integrity.",
                "control_objective": "To maintain ai system integrity against adversarial attacks or operational changes."
            },
            {
                "control": "SD-SR-01-02: Document and maintain technical safeguard specifications: outlining different countermeasures against specific types of adversarial attacks.",
                "control_objective": "To maintain ai system integrity against adversarial attacks or operational changes."
            },
            {
                "control": "SD-SR-01-03: Maintain a dynamic change ledger: records of all operational changes and their assessments.",
                "control_objective": "To maintain ai system integrity against adversarial attacks or operational changes."
            },
            {
                "control": "SD-SR-01-04: Ensure the existence of repository of system configurations: a version-controlled repository to track historical and current system states.",
                "control_objective": "To maintain ai system integrity against adversarial attacks or operational changes."
            }
        ]
    },
    {
        "FieldType": "risk",
        "FieldName": "Input Manipulation and Membership Inference Attacks",
        "question": "How can input validation & model obfuscation measures ensure the AI system's integrity, and are there sufficient controls to prevent input manipulation and membership inference attacks?",
        "controls": [
            {
                "control": "SD-IM-01-01: Document and maintain input validation procedure guide: outlining the methods used to check and sanitize inputs.",
                "control_objective": "To implement input validation to detect and prevent input manipulation attacks. use model obfuscation techniques to prevent membership inference attacks."
            },
            {
                "control": "SD-IM-01-02: Document and maintain obfuscation technique report: detailing the specific approaches taken to obscure the ai model's data and operations.",
                "control_objective": "To implement input validation to detect and prevent input manipulation attacks. use model obfuscation techniques to prevent membership inference attacks."
            },
            {
                "control": "SD-IM-01-03: Maintain a input and model security log: record all validation and obfuscation activities.",
                "control_objective": "To implement input validation to detect and prevent input manipulation attacks. use model obfuscation techniques to prevent membership inference attacks."
            }
        ]
    },
    {
        "FieldType": "risk",
        "FieldName": "Data Poisoning and Manipulative Attacks on Models",
        "question": "How can data validation & use of robust models measures ensure the AI system's integrity, and are there sufficient controls to prevent data poisoning and manipulative attacks on models?",
        "controls": [
            {
                "control": "SD-DI-01-01: Ensure the existence of data validation procedure: a procedure for validating and verifying training data.",
                "control_objective": "To perform a thorough validation and verification of training data before using it to train the model. use robust models designed to withstand manipulative attacks."
            },
            {
                "control": "SD-DI-01-02: Document and maintain robust model development guide: a guide for developing robust ai models resistant to attacks.",
                "control_objective": "To perform a thorough validation and verification of training data before using it to train the model. use robust models designed to withstand manipulative attacks."
            },
            {
                "control": "SD-DI-01-03: Establish and implement a data and model security training program: a training program for staff on data validation and robust model development.",
                "control_objective": "To perform a thorough validation and verification of training data before using it to train the model. use robust models designed to withstand manipulative attacks."
            },
            {
                "control": "SD-DI-01-04: Document and maintain data validation plan: documentation specifying the processes and criteria for validating training data, including data quality and security considerations.",
                "control_objective": "To perform a thorough validation and verification of training data before using it to train the model. use robust models designed to withstand manipulative attacks."
            },
            {
                "control": "SD-DI-01-05: Document and maintain model robustness assessment: documentation outlining the measures and techniques used to ensure the model's robustness against manipulative attacks.",
                "control_objective": "To perform a thorough validation and verification of training data before using it to train the model. use robust models designed to withstand manipulative attacks."
            },
            {
                "control": "SD-DI-01-06: Document and maintain data validation report: details the methods and results of the training data verification process.",
                "control_objective": "To perform a thorough validation and verification of training data before using it to train the model. use robust models designed to withstand manipulative attacks."
            },
            {
                "control": "SD-DI-01-07: Document and maintain robust model selection criteria document: outlining the standards and requirements that models must meet to be considered robust against attacks.",
                "control_objective": "To perform a thorough validation and verification of training data before using it to train the model. use robust models designed to withstand manipulative attacks."
            },
            {
                "control": "SD-DI-01-08: Maintain a training data integrity log: must also be maintained.",
                "control_objective": "To perform a thorough validation and verification of training data before using it to train the model. use robust models designed to withstand manipulative attacks."
            }
        ]
    },
              {
    "FieldType": "risk",
    "FieldName": "Inadequate Testing and Undocumented AI System Errors",
    "question": "Are the AI system's errors and limitations fully identified, documented, and mitigated through rigorous testing, including adversarial and stress testing?",
    "controls": [
      {
        "control": "SD-EH-01 - 01: Maintain a **Testing Methodology Document** detailing the testing approach used for the AI system.",
        "control_objective": "To establish and document a clear and comprehensive methodology for testing the AI system.",
        "risk_name": "Failure to define a comprehensive and repeatable testing process."
      },
      {
        "control": "SD-EH-01 - 02: Maintain a **Test Performance Report** documenting metrics and outcomes of all tests conducted.",
        "control_objective": "To document and analyze the performance and outcomes of all AI system tests.",
        "risk_name": "Inability to accurately assess the AI system's performance and identify failures."
      },
      {
        "control": "SD-EH-01 - 03: Maintain **Adversarial and Stress Testing Guidelines** to govern the execution of these specific test types.",
        "control_objective": "To ensure rigorous and systematic identification of system weaknesses through adversarial and stress testing.",
        "risk_name": "Systemic weaknesses or vulnerabilities remaining undetected due to insufficient stress or adversarial testing."
      },
      {
        "control": "SD-EH-01 - 04: Maintain a **Testing Methodology Guide** that outlines the approach and types of tests conducted on the data.",
        "control_objective": "To provide a comprehensive guide on the types of data tests and their execution approach.",
        "risk_name": "Misapplication of data testing techniques leading to unreliable results."
      },
      {
        "control": "SD-EH-01 - 05: Maintain a **Testing Metrics and Performance Outcomes Report** detailing the criteria for success and the results of the data tests.",
        "control_objective": "To systematically report on the success criteria and results of data-related testing metrics.",
        "risk_name": "Lack of standardized performance metrics for data testing, hindering objective evaluation."
      },
      {
        "control": "SD-EH-01 - 06: Maintain **Error and Limitation Documentation** that systematically records all issues uncovered during testing.",
        "control_objective": "To create a systematic record of all identified errors and limitations in the AI system's data processing.",
        "risk_name": "Critical system errors or limitations being missed or forgotten due to poor documentation."
      }
    ]
  },
  {
    "FieldType": "risk",
    "FieldName": "Malicious Data Input and Attack Prevention",
    "question": "Is the AI system protected against malicious inputs and potential buffer overflow attacks through stringent input validation, and are the security measures effective?",
    "controls": [
      {
        "control": "SD-AI-01 - 01: Maintain an **Input Validation Plan** that specifies the strategies and techniques for input validation, emphasizing data-related aspects.",
        "control_objective": "To establish a documented strategy for preventing malicious data input through validation.",
        "risk_name": "Inadequate or undefined input validation strategies, allowing malicious data to enter the system."
      },
      {
        "control": "SD-AI-01 - 02: Maintain an **Input Validation Protocol Document** describing the technical safeguards and validation checks in place.",
        "control_objective": "To establish and document the technical controls for input validation.",
        "risk_name": "Failure of technical safeguards to effectively identify and block malicious inputs."
      },
      {
        "control": "SD-AI-01 - 03: Maintain an **Input Validation Log** recording all input checks and any detected attempts at malicious data entry.",
        "control_objective": "To log and track all input validation activity and attempted malicious data entries.",
        "risk_name": "Undetected or unlogged malicious input attempts, masking active security threats."
      },
      {
        "control": "SD-AI-01 - 04: Maintain a **Security Measures Effectiveness Report** summarizing the performance of the input validation system.",
        "control_objective": "To periodically assess and report on the overall effectiveness of input validation security measures.",
        "risk_name": "Security controls becoming outdated or ineffective over time without performance monitoring."
      }
    ]
  },
  {
    "FieldType": "risk",
    "FieldName": "Vulnerability to Physical Adversarial Objects",
    "question": "Is the machine learning model sufficiently robust to detect and correctly handle physical adversarial objects in real-world operating environments?",
    "controls": [
      {
        "control": "SD-HS-01 - 01: Maintain a **Physical Adversarial Object Detection Strategy** outlining how the models are trained to detect anomalies.",
        "control_objective": "To define the strategic approach for training models to detect physical adversarial objects.",
        "risk_name": "Failure to strategically prepare the model for physical-world adversarial attacks."
      },
      {
        "control": "SD-HS-01 - 02: Maintain a **Detection Test Report** summarizing the models' response to various physical adversarial objects during testing.",
        "control_objective": "To document and analyze the model's performance when faced with physical adversarial objects.",
        "risk_name": "Models exhibiting unpredictable or incorrect behavior when encountering novel physical adversarial objects."
      },
      {
        "control": "SD-HS-01 - 03: Maintain **Model Resilience Documentation** that records the model's robustness to physical adversarial objects.",
        "control_objective": "To formally document the model's ability to resist and correctly handle physical adversarial objects.",
        "risk_name": "Overestimation of model resilience leading to deployment in high-risk environments."
      }
    ]
  },
  {
    "FieldType": "risk",
    "FieldName": "Security Flaws in Model Interaction and Data Flow",
    "question": "Are all data fed into the AI models subject to stringent input validation to prevent malicious inputs, and are potential system vulnerabilities effectively analyzed and addressed?",
    "controls": [
      {
        "control": "SD-PI-01 - 01: Maintain an **Input Validation Protocol** detailing the criteria and methods for data validation at the point of model interaction.",
        "control_objective": "To establish clear and documented procedures for validating all data before it interacts with the models.",
        "risk_name": "Unvalidated data being fed directly into the model, leading to system corruption or malicious outcomes."
      },
      {
        "control": "SD-PI-01 - 02: Maintain a **Model Interaction Security Report** documenting the effectiveness of input validation checks in preventing unwanted or harmful inputs.",
        "control_objective": "To report on the performance and effectiveness of input validation checks at the model interaction layer.",
        "risk_name": "Input validation checks proving ineffective against sophisticated or novel attack vectors."
      },
      {
        "control": "SD-PI-01 - 03: Maintain a **System Vulnerability Analysis** assessing potential weak points in model interactions.",
        "control_objective": "To proactively identify and analyze potential weak points and vulnerabilities in the model interaction process.",
        "risk_name": "Unidentified system vulnerabilities being exploited for data exfiltration or model manipulation."
      }
    ]
  },
  {
    "FieldType": "risk",
    "FieldName": "Neural Network Input Manipulation and Unsanitized Data",
    "question": "Are sufficient measures in place to validate and sanitize neural network inputs, and are the effectiveness of these measures consistently evaluated to prevent misleading or manipulated outputs?",
    "controls": [
      {
        "control": "SD-PI-02 - 01: Maintain a **Neural Network Input Validation Procedure Guide** outlining the steps and techniques for input validation and sanitization.",
        "control_objective": "To establish a formal procedure for validating and sanitizing all inputs to the neural network.",
        "risk_name": "Inconsistent or ad-hoc input sanitization procedures leading to unreliable model behavior."
      },
      {
        "control": "SD-PI-02 - 02: Maintain a **Neural Network Input Sanitization Log** documenting all instances of input checks and any actions taken to rectify problematic inputs.",
        "control_objective": "To systematically log and track all validation and sanitization actions performed on neural network inputs.",
        "risk_name": "Inability to audit or investigate past incidents due to poor logging of input sanitization activities."
      },
      {
        "control": "SD-PI-02 - 03: Maintain a **Validation Techniques Effectiveness Report** to evaluate the success of the input validation methods used.",
        "control_objective": "To periodically evaluate and report on the efficacy of the chosen neural network input validation techniques.",
        "risk_name": "Reliance on ineffective or outdated input validation techniques, making the model vulnerable."
      }
    ]
  }
        ]
    },

    "(6.2.1) AI Lifecycle Phase requirements - Training": {
        "WebFormTitle": "Define the security requirements for lifecycle phase - Training.",
        "Fields": [
            {
                "FieldType": "risk",
                "FieldName": "Failure to Develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models.",
                "question": "How can we ensure the effective Develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models.?",
                "controls": [
                    {
                        "control": "AF-BV-03 - 01: Maintain Rationale Explanation Report that provides A document explaining the importance of considering adversarial machine learning for bias measurement and its role in promoting fairness and equity in AI systems.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 02: Maintain Bias Measurement Guidelines that provides A set of guidelines outlining how adversarial machine learning is used to measure bias in AI systems.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 03: Maintain Bias Mitigation Plan that provides A plan detailing strategies and methods for addressing biases identified through adversarial machine learning.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 04: Maintain Adversarial Testing Plan that provides A document detailing the plan for adversarial testing to measure bias, including personnel roles.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 05: Maintain Bias Measurement Reports that provides Reports from adversarial tests that indicate levels of bias discovered.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 06: Maintain Bias Adjustment Records that provides Documentation of adjustments made to models in response to bias measurements.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 07: Development of a Bias Measurement Protocol that utilizes adversarial machine learning techniques. The protocol should detail how prompt engineering and adversarial models are used to uncover and measure bias in AI systems.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 08: Maintain Adversarial Testing Guidelines that provides Detailed instructions on how to conduct adversarial tests to uncover bias within AI models.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 09: Maintain Bias Measurement Reports that provides The findings from adversarial testing, including metrics and analyses, that indicate the presence and severity of biases.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 10: Maintain Adversarial Model Development Documentation that provides Technical documents that describe the creation and use of models designed to challenge and test the fairness of the primary AI system.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 11: Maintain Bias Measurement Report that provides A report that details findings from adversarial testing, highlighting potential biases and recommendations for improvement.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 12: Maintain Adversarial Test Suite that provides A collection of tools and tests designed for prompting AI systems in order to uncover biases.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    },
                    {
                        "control": "AF-BV-03 - 13: Maintain Model Response Analysis Documentation that provides Documentation of how the AI model responds to adversarial inputs, which can be indicative of bias.",
                        "control_objective": "To develop and implement adversarial machine learning approaches for measuring bias and discrimination, including prompt engineering and adversarial models."
                    }
                ]
            },
            {
                "FieldType": "risk",
                "FieldName": "Failure to Implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome.",
                "question": "How can we ensure the effective Implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome.?",
                "controls": [
                    {
                        "control": "AF-BV-04 - 01: Maintain Rationale Explanation Report that provides A document explaining the importance of bias detection and correction and its role in promoting fairness and equity in AI systems.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 02: Maintain Bias Detection Guidelines that provides Guidelines outlining the methodologies and tools used for identifying biases in AI models and decision-making processes.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 03: Maintain Bias Mitigation Plan that provides A plan detailing the strategies and methods for addressing biases once detected.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 04: Maintain Bias Detection Framework that provides A comprehensive framework detailing procedures for detecting biases and assigning responsibilities.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 05: Maintain Correction Implementation Logs that provides Logs that track the implementation of corrective actions.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 06: Maintain Fairness Audit Reports that provides Periodic reports assessing the fairness of the model post correction.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 07: A comprehensive Bias Detection and Correction Framework, including a description of the methodologies used to detect biases in the data, as well as the techniques employed to correct these biases before they affect the model’s predictions.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 08: Maintain Bias Detection and Correction Protocol that provides A comprehensive guide that outlines the steps to identify and mitigate bias in AI datasets.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 09: Maintain Training Data Audit Reports that provides Documents that record the findings of biases in training datasets, along with the steps taken to correct them.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 10: Maintain Corrective Action Plans that provides Strategic plans that specify the actions required to adjust biased data and improve model fairness.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 11: Maintain Bias Audit Report that provides A comprehensive document detailing detected biases in training data and subsequent corrections applied.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 12: Maintain Corrective Action Plan that provides A strategic plan outlining steps for rectifying identified biases, including data resampling or algorithmic adjustments.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    },
                    {
                        "control": "AF-BV-04 - 13: Maintain Fairness Metrics Dashboard that provides An interactive dashboard that monitors key fairness metrics over time, reflecting the impact of corrective measures.",
                        "control_objective": "To implement the identification and mitigation of biased processes and procedures to detect and correct biases in training data, ensuring fairness in model predictions and to document, analyze and follow up on unfairness that could result in a discriminatory outcome."
                    }
                ]
            },
      {
        "FieldType": "risk",
        "FieldName": "Flawed Training Process and Overfitting",
        "question": "Is there a risk that the AI model will perform well on training data but fail in real-world scenarios because it has memorized noise instead of learning generalizable patterns?",
        "controls": [
            {
                "control": "AL-MT-18 - 01: Maintain Regularization Techniques Document that provides A document outlining the specific regularization techniques used, such as L1, L2, dropout, or others and the reasons for their application.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 02: Maintain Overfitting Risk Assessment that provides A report that assesses the potential risk of overfitting in the model and explains how the chosen regularization techniques mitigate this risk.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 03: Maintain Model Performance Metrics that provides Detailed information on how the model's performance is monitored and improved through the application of regularization techniques.\\nRationale Document: A comprehensive nontechnical report that justifies the use of regularization techniques and their contribution to the AI system's objectives.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 04: Maintain Regularization Technique Guidelines that provides A comprehensive set of guidelines on how to apply regularization techniques correctly in the model training process.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 05: Maintain Model Training Records that provides Documentation of the model training process, including details on the regularization techniques used.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 06: Maintain Overfitting Prevention Audit Reports that provides Reports from audits that evaluate the effectiveness of the regularization techniques in preventing overfitting.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 07: Regularization Implementation Guide detailing the types of regularization techniques used, the scenarios for their application, and guidance on how to configure them to mitigate the risk of overfitting and poisoning.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 08: Maintain Overfitting Prevention Fairness Strategy that provides A strategy that includes regularization techniques to prevent overfitting while considering fairness.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 09: Maintain Regularization Impact on Model Fairness Report that provides A report on how regularization techniques like L1 and L2 impact the fairness of model outcomes.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 10: Maintain Overfitting Prevention Technique Fairness Certificates that provides Certificates that confirm the application of regularization techniques enhances the fairness of the AI system.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 11: Regularization Implementation Guide that outlines the regularization methods applied to the model.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 12: Overfitting Mitigation Report which documents the effect of regularization on model performance.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 13: Model Poisoning Prevention Strategy that details how regularization contributes to model security.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 14: Maintain Regularization Implementation Documentation that provides Detailed descriptions of the regularization techniques used, including technical specifics, implementation strategies, and rationales for their selection.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 15: Maintain Model Evaluation Reports that provides Documentation of model performance before and after applying regularization, highlighting changes in overfitting tendencies and model robustness.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            },
            {
                "control": "AL-MT-18 - 16: Maintain Security Assessment Reports that provides Analysis of the model's resilience to poisoning attacks post regularization implementation.",
                "control_objective": "To add regularization techniques to prevent overfitting and model poisoning attacks."
            }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "[C.3.4] - Vulnerability to Adversarial Evasion Attacks",
        "question": "Could an adversary intentionally craft inputs to deceive the AI system at the time of prediction, causing it to make a wrong and potentially dangerous decision?",
        "controls": [
          {
            "control": "[C.3.4][AA-1] - Incorporate adversarial training by exposing the model to crafted adversarial examples during the training phase to improve its resilience.",
            "control_objective": "To build model robustness and make it less susceptible to slight, malicious perturbations in its input."
          },
          {
            "control": "[C.3.4][AA-2] - Implement input sanitization and validation filters to detect and flag or reject inputs that exhibit characteristics of known adversarial patterns.",
            "control_objective": "To create a first line of defense by identifying and blocking malicious inputs before they can be processed by the model."
          },
          {
            "control": "[C.3.4][AA-3] - For critical systems, design fail-safe mechanisms that trigger a safe mode or alert a human operator when the model's prediction confidence is low or an input is anomalous.",
            "control_objective": "To ensure system safety and prevent harmful outcomes even if an adversarial attack is successful or suspected."
          },
          {
            "control": "[C.3.4][AA-4] - Conduct physical and digital security testing to simulate adversarial attacks under realistic conditions (e.g., testing vision systems with altered signs or objects).",
            "control_objective": "To understand and mitigate the real-world vulnerabilities of the deployed AI system to adversarial manipulation."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "[C.3.4] - Susceptibility to Data Poisoning Attacks",
        "question": "Could an attacker maliciously influence the data used to train or retrain the AI system, deliberately teaching it to behave incorrectly or to create a backdoor?",
        "controls": [
          {
            "control": "[C.3.4][DP-1] - Establish strong data provenance and validation controls to verify the source and integrity of all data used for model training and retraining.",
            "control_objective": "To prevent unauthorized or corrupt data from being introduced into the model development pipeline."
          },
          {
            "control": "[C.3.4][DP-2] - For systems that learn continuously from new data, implement anomaly detection on the incoming data stream to flag and isolate suspicious data points before they are used for training.",
            "control_objective": "To protect online learning systems from real-time manipulation and poisoning attacks."
          },
          {
            "control": "[C.3.4][DP-3] - Treat the training dataset as a critical information asset with strict access controls, versioning, and security measures to prevent unauthorized modification.",
            "control_objective": "To secure the training pipeline at its source and maintain the integrity of the ground-truth data."
          },
          {
            "control": "[C.3.4][DP-4] - Utilize poisoning-resistant or robust training algorithms that are specifically designed to be less influenced by a small fraction of malicious data points.",
            "control_objective": "To reduce the impact of potential data poisoning attempts on the final model's integrity and behavior."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "[C.3.4] - Performance Degradation due to Concept Drift",
        "question": "Will the AI system operate in a dynamic environment where the statistical properties of the data can change over time, potentially causing the model's accuracy to degrade silently?",
        "controls": [
          {
            "control": "[C.3.4][CD-1] - Implement a continuous MLOps monitoring system to track key model performance metrics (e.g., accuracy, error rate, prediction latency) in real-time post-deployment.",
            "control_objective": "To provide immediate visibility into the model's effectiveness and detect performance degradation as it happens."
          },
          {
            "control": "[C.3.4][CD-2] - Employ automated drift detection algorithms to compare the statistical distribution of live input data against the training data, with alerts triggered by significant divergence.",
            "control_objective": "To proactively identify when the real-world environment has changed, indicating that the model may no longer be valid."
          },
          {
            "control": "[C.3.4][CD-3] - Establish a formal process for periodic model retraining on more recent and relevant data, triggered either by detected drift, performance degradation, or a set schedule.",
            "control_objective": "To ensure the AI model remains up-to-date and accurately reflects the current state of the operating environment."
          },
          {
            "control": "[C.3.4][CD-4] - Maintain comprehensive version control for both models and datasets (MLOps) to enable traceability, reproducibility, and the ability to roll back to a previous model version if needed.",
            "control_objective": "To manage the model lifecycle effectively and ensure operational stability and accountability."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Inadequate Data & Privacy Protection Measures",
        "question": "Will this AI system process personal, confidential, or sensitive business data?",
        "controls": [
          {
            "control": "PPM[1] -  Implement data anonymization and pseudonymization techniques during the pre-processing stage to remove or obfuscate personally identifiable information (PII) and sensitive data from proprietary datasets used for fine-tuning.",
            "control_objective": "To protect the privacy of individuals by reducing the risk of re-identification and unauthorised access to sensitive personal data within the training datasets."
          },
          {
            "control": "PPM[2] -  Establish data privacy policies and guidelines that define the criteria and methods for anonymization and pseudonymization, ensuring consistent and effective privacy protection across the organisation's datasets.",
            "control_objective": "To provide a standardised framework for privacy reduction techniques, ensuring compliance with data protection regulations and ethical standards."
          },
          {
            "control": "PPM[3] -  Conduct regular privacy impact assessments and audits to identify and address any potential privacy risks or vulnerabilities introduced during data collection, processing, or fine-tuning.",
            "control_objective": "To continuously monitor and improve the effectiveness of privacy reduction measures, ensuring that the AI model is trained on data that adheres to privacy regulations and ethical standards."
          },
          {
            "control": "DRP.01 Establish data risk profiles to better understand the specific security and privacy risks associated with the types of data managed by the organisation, such as:\na) Confidentiality rating 1, 2, and 3\nb) Integrity rating 1, 2, and 3\nc) Availability rating 1, 2, and 3",
            "control_objective": "To categorise data based on its security and privacy risks to ensure appropriate protection measures."
          },
          {
            "control": "DRP.02 Perform an IT risk assessment on each data risk profile, and assign proportionate data protection measures to it.",
            "control_objective": "To evaluate and apply appropriate data protection strategies for each risk profile."
          },
          {
            "control": "DRP.03 Define the legal and regulatory compliance requirements relevant to each data risk profile, considering regulations such as GDPR and HIPAA.",
            "control_objective": "To ensure compliance with legal and regulatory standards for each type of data."
          },
          {
            "control": "DRP.04 Define requirements relating to the incident breach notification responsibilities for each data risk profile.",
            "control_objective": "To establish clear breach notification protocols for different types of data breaches."
          },
          {
            "control": "DRP.05 Document Data risk profile mapping criteria to facilitate the consistent and correct mapping of software change to the most appropriate Data risk profile.",
            "control_objective": "To establish clear criteria for accurately mapping system changes to relevant data risk profiles."
          },
          {
            "control": "DRP.06 Periodically review and update data risk profiles to reflect changes in data types, emerging threats, and evolving regulatory requirements.",
            "control_objective": "To Ensure that data risk profiles remain relevant and effective in the face of evolving data types, threats, and regulatory changes."
          },
          {
            "control": "DRP.07 Develop training modules for DevSecOps teams on the application and implications of Data risk profiles, focusing on how to utilise them effectively in their workflows.",
            "control_objective": "To educate DevSecOps teams on the importance and application of Data risk profiles."
          },
          {
            "control": "DRP.08 Involve relevant stakeholders, such as legal, compliance, and data privacy teams, in the creation and refinement of data risk profiles to ensure comprehensive coverage of all risk aspects.",
            "control_objective": "To develop well-rounded and comprehensive data risk profiles through multi-disciplinary collaboration."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Uncontrolled Synthetic Data Usage",
        "question": "Will synthetic (artificially generated) data be used in training or testing without clear documentation or controls?",
        "controls": [
          {
            "control": "SD[1] -  Establish guidelines and criteria for data augmentation, including acceptable techniques, quality standards, and validation processes.",
            "control_objective": "To ensure that data augmentation is performed consistently and effectively, while maintaining the integrity and relevance of the generated or augmented data."
          },
          {
            "control": "SD[2] -  Maintain detailed records of all data augmentation or generation methods used, including parameters, algorithms, and the rationale behind their selection. Implement version control for these techniques to track changes and ensure reproducibility.",
            "control_objective": "To ensure transparency, traceability, and auditability of data augmentation processes, allowing for the identification and correction of potential issues or biases introduced during augmentation."
          },
          {
            "control": "SD[3] -  When generating synthetic data or augmenting existing data, employ privacy-preserving techniques (e.g., differential privacy, data masking) to protect sensitive information and ensure compliance with data protection regulations.",
            "control_objective": "To safeguard the confidentiality and privacy of individuals while still allowing for the creation of diverse and representative training data."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Undetected Changes in Data Distribution",
        "question": "Could shifts in customer behavior, market trends, or other inputs cause the AI to produce unexpected results over time?",
        "controls": [
          {
            "control": "DD[1] -  Establish clear thresholds for data drift based on statistical measures (e.g., Kullback-Leibler divergence, Kolmogorov-Smirnov test) to determine when data changes are significant enough to warrant action.",
            "control_objective": "To trigger alerts or initiate retraining procedures when data drift exceeds predefined thresholds, ensuring the model's accuracy remains reliable despite changes in data distribution."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "AI system hallucinations",
        "question": "Will the AI generate content (text, images, etc.) that could be factually wrong but appear convincing?",
        "controls": [
          {
            "control": "HA[1] -  Establish an AI system hallucination detection and mitigation process.",
            "control_objective": "To implement robust administrative controls that define roles, responsibilities, policies, and procedures for managing and mitigating AI system hallucinations, ensuring the accuracy and reliability of AI outputs."
          },
          {
            "control": "HA[2] -  Implement advanced technical measures to detect, prevent, and mitigate AI system hallucinations, ensuring the reliability and accuracy of AI outputs.",
            "control_objective": "To deploy comprehensive technical controls that enable real-time detection, analysis, and correction of AI system hallucinations, maintaining the integrity and reliability of AI models."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Exposure of Sensitive Data Through Federated Learning",
        "question": "Will the AI system collaborate or learn from external datasets without centralizing data (e.g., via federated learning)?",
        "controls": [
          {
            "control": "FL[1] -  Ensure a secure federated learning process",
            "control_objective": "To ensure the secure handling of distributed sensitive data used in federated learning"
          }
        ]
      }
        ]
            },
    "(6.2.1) AI Lifecycle Phase requirements - Package": {
        "WebFormTitle": "Define the security requirements for lifecycle phase - Package.",
        "Fields": [
      {
        "FieldType": "risk",
        "FieldName": "Insecure AI component Packaging",
        "question": "Are any components of the AI system be packaged in containers?",
        "controls": [
          {
            "control": "PROTE.01 Ensure masking and anonymisation of sensitive or confidential data.",
            "control_objective": "To protect sensitive data from unauthorised exposure during the packaging process."
          },
          {
            "control": "PROTE.02 Configure development tools, orchestrators, and container runtimes to exclusively use encrypted channels when connecting to registries.",
            "control_objective": "To safeguard the integrity and confidentiality of container images and code during transit to and from registries."
          },
          {
            "control": "PROTE.03 Implement time-triggered pruning of registries to remove unsafe or vulnerable container images.",
            "control_objective": "To maintain the security and integrity of container images in registries by eliminating outdated and vulnerable images."
          },
          {
            "control": "PROTE.04 Enforce read/write access control for registries containing proprietary or sensitive container images.",
            "control_objective": "To restrict unauthorised access and modifications to container images stored in registries."
          },
          {
            "control": "PROTE.05 Control access to cluster-wide administrative accounts using strong authentication methods like multifactor authentication and single sign-on to existing directory systems where applicable.",
            "control_objective": "To ensure secure and controlled access to administrative accounts within the cluster."
          },
          {
            "control": "PROTE.06 Implement network isolation protocols that configure orchestrators to segregate network traffic based on sensitivity levels.",
            "control_objective": "To maintain distinct network environments for different levels of data sensitivity, enhancing overall network security."
          },
          {
            "control": "PROTE.07 Deploy policies that configure orchestrators to isolate deployments to specific sets of hosts based on security requirements or sensitivity levels.",
            "control_objective": "To ensure that deployments are conducted on secure, appropriate hosts in alignment with their security needs."
          },
          {
            "control": "PROTE.08 Establish stringent trust mechanisms for orchestrator nodes, including\na) secure introduction to the cluster\nb) persistent node identity\nc) inventory of nodes and their connectivity states\nd) resilience to individual node compromise\ne) mutual authentication of network connections with end-to-end encryption of intracluster traffic.",
            "control_objective": "To build a secure and resilient orchestrator environment with trusted nodes and secure communications."
          },
          {
            "control": "PROTE.09 Implement mechanisms for identifying Common Vulnerabilities and Exposures (CVEs) in the runtimes deployed.",
            "control_objective": "To promptly identify and address known vulnerabilities in deployed runtimes, enhancing system security."
          },
          {
            "control": "PROTE.10 Implement robust controls at network borders for monitoring and regulating egress network traffic originating from containers.",
            "control_objective": "To control and monitor the outbound network traffic from containers, enhancing network security."
          },
          {
            "control": "PROTE.11 Develop mechanisms to automatically enforce compliance requirements and, where applicable, prevent the execution of noncompliant container images.",
            "control_objective": "To ensure that only compliant container images are deployed, maintaining a secure and regulated environment."
          },
          {
            "control": "PROTE.12 Implement mechanisms to reduce Host Operating System (OS) attack surfaces, including\na) using container-specific OSs with unnecessary services disabled (e.g., print spooler)\nb) employing read-only file systems\nc) regularly updating and patching OSs and lower-level components like the kernel\nd) validating versioning of components for base OS management and functionality.",
            "control_objective": "To minimise vulnerabilities and enhance the security of the host operating systems used in containerised environments."
          },
          {
            "control": "PROTE.13 Establish mechanisms to prevent the mixing of containerised and non-containerised workloads on the same host instance.",
            "control_objective": "To segregate containerised workloads from non-containerised ones, reducing the risk of cross-contamination and attacks."
          },
          {
            "control": "PROTE.14 Implement mechanisms to enforce minimal file system permissions for all containers, ensuring that they cannot mount sensitive directories on the host's file system.",
            "control_objective": "To restrict container access to the host's file system, preventing unauthorised access or manipulation of sensitive data."
          },
          {
            "control": "PROTE.15 Implement mechanisms for continuous updating, centralised reporting, and monitoring of image compliance to identify weaknesses and risks.",
            "control_objective": "To maintain up-to-date compliance and security status of container images, enabling proactive risk management."
          },
          {
            "control": "PROTE.16 Ensure that only images from trusted image stores and registries are permitted to run in the environment.",
            "control_objective": "To safeguard the environment from untrusted or potentially harmful container images."
          },
          {
            "control": "PROTE.17 Utilise network policies and firewall rules to restrict container network access and isolate sensitive workloads.",
            "control_objective": "To enhance network security by controlling container access and isolating sensitive workloads."
          },
          {
            "control": "PROTE.18 Adopt the use of immutable containers, which cannot be altered post-deployment, wherever feasible.",
            "control_objective": "To prevent runtime attacks by ensuring container configurations remain unchanged after deployment."
          },
          {
            "control": "PROTE.19 Implement security measures for APIs, including robust API authentication mechanisms (e.g., OAuth 2.0, API keys), fine-grained access controls, and rate limiting to protect against abuse.",
            "control_objective": "To ensure the secure operation of APIs"
          },
          {
            "control": "PROTE.20 Images should be configured to run as non-privileged users.",
            "control_objective": "To enhance security by minimising the potential impact of a security breach from a containerised environment."
          },
          {
            "control": "PROTE.21 Secrets should be stored outside of images and provided dynamically at runtime as needed.",
            "control_objective": "To protect sensitive information like credentials and keys by managing them securely and separately from container images."
          },
          {
            "control": "PROTE.22 Implement security policies and access controls at both the container and host levels to restrict unauthorised access and privilege escalation.",
            "control_objective": "To enhance container and host security by limiting access and preventing unauthorised privilege escalation."
          },
          {
            "control": "PROTE.23 Utilise built-in security features of your containerisation platform.",
            "control_objective": "To leverage platform-specific security features to enhance the security posture of containerised applications."
          },
          {
            "control": "PROTE.24 Mechanisms exist to implement resource limitations to prevent containers from consuming excessive resources and potentially causing a Denial of Service (DoS) attack.",
            "control_objective": "To prevent containers from over-utilising system resources, thereby safeguarding against resource exhaustion and DoS attacks."
          }
        ]
      }
        ]
    },

    "(6.2.1) AI Lifecycle Phase requirements - Deployment, Maintenance and Updates": {
        "WebFormTitle": "Define the security requirements for lifecycle phase - Deployment, Maintenance and Updates.",
        "Fields": [
      {
        "FieldType": "risk",
        "FieldName": "[C.3.6] - Mismanaged AI System Deployment and Transition",
        "question": "Is the plan to deploy the AI system a 'big bang' launch without sufficient user training, a pilot phase, or a clear transition plan from the legacy system?",
        "controls": [
          {
            "control": "[C.3.6][BP-4] - Develop and deliver comprehensive training programs for all users and operators on the AI system's capabilities, limitations, and proper operational procedures before deployment.",
            "control_objective": "To minimize misuse, build user trust, and ensure the AI system is operated correctly and effectively."
          },
          {
            "control": "[C.3.6][BP-5] - Implement a phased rollout or pilot program in a controlled environment to identify and resolve unforeseen issues before a full-scale, system-wide launch.",
            "control_objective": "To reduce the risk of widespread disruption and failure by validating system performance in a live but limited setting."
          },
          {
            "control": "[C.3.6][BP-6] - Establish a clear transition plan that includes running the new AI system in parallel with any legacy system to verify outputs and ensure a smooth handover without creating an operational gap.",
            "control_objective": "To guarantee operational continuity and validate the new AI system's performance against established benchmarks before decommissioning the previous system."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "[C.3.6] - Inadequate Post-Deployment Maintenance and Monitoring",
        "question": "Once the AI system is live, is there a risk it will be treated with a 'set and forget' mentality, without a dedicated team or process for continuous performance monitoring and regular maintenance?",
        "controls": [
          {
            "control": "[C.3.6][BP-7] - Assign clear ownership for the deployed AI system and implement a continuous monitoring framework with predefined KPIs (e.g., for accuracy, data drift, fairness) and automated alerts to detect performance degradation.",
            "control_objective": "To ensure proactive oversight and rapid detection of issues, preventing the AI system from making flawed decisions over extended periods."
          },
          {
            "control": "[C.3.6][BP-8] - Establish a formal maintenance schedule for the AI system, including periodic model retraining with new data, recalibration, and updates to adapt to changing operational environments.",
            "control_objective": "To prevent model obsolescence and ensure the AI system remains accurate, relevant, and effective throughout its operational life."
          },
          {
            "control": "[C.3.6][BP-9] - Implement a formal feedback loop for users to easily report issues, anomalies, or incorrect outputs, and ensure this feedback is systematically reviewed and used to improve the system.",
            "control_objective": "To leverage end-user experience as a critical source for identifying subtle performance issues and driving continuous improvement."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Insufficient Scalability Management",
        "question": "Will this AI be used across multiple teams, products, or regions — and is it ready to scale reliably?",
        "controls": [
          {
            "control": "SC[1] -  Develop and implement a structured scalability management process for AI infrastructure to ensure efficient handling of increasing workloads and data volumes.",
            "control_objective": "To ensure that the AI infrastructure can scale effectively and efficiently, meeting the growing demands of the organisation while maintaining performance, stability, and security."
          },
          {
            "control": "SC[2] -  Deploy comprehensive technical measures to ensure the AI infrastructure can scale seamlessly to accommodate varying workloads and future growth.",
            "control_objective": "To guarantee that the AI infrastructure is equipped with the necessary technical capabilities to support scalability, ensuring uninterrupted performance and resource availability as demands increase."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "[C.3.6] - Poor Management of AI System Evolution and Updates",
        "question": "When the AI system is updated (e.g., retrained model, new features), are there formal processes for testing, documenting, and deploying these changes, including a plan to roll back if the update causes problems?",
        "controls": [
          {
            "control": "[C.3.6][BP-10] - Enforce a strict change management process for all AI system updates, requiring thorough testing (e.g., A/B testing, shadow mode), impact analysis, and a documented rollback plan before deployment.",
            "control_objective": "To prevent system degradation caused by faulty updates and ensure that changes improve, rather than harm, system performance and reliability."
          },
          {
            "control": "[C.3.6][BP-11] - Maintain comprehensive and up-to-date documentation for the AI system, including design rationale, model parameters, data sources, and a version history of all changes made.",
            "control_objective": "To ensure knowledge continuity, facilitate troubleshooting, and support consistent and informed management of the AI system over time."
          },
          {
            "control": "[C.3.6][BP-12] - Implement version control for all components of the AI system, including data, code, and models, to ensure traceability and the ability to rapidly revert to a previously stable version in case of an incident.",
            "control_objective": "To provide a safety net against failed updates and enable quick recovery of system functionality."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Inadequate Disaster Recovery and Business Continuity Planning",
        "question": "What would happen to your business process if this AI system suddenly stopped working?",
        "controls": [
          {
            "control": "BU[1] -  Establish a comprehensive disaster recovery and business continuity planning process to ensure preparedness and resilience in the face of disruptions to AI infrastructure.",
            "control_objective": "To develop and implement administrative controls that ensure the organisation is prepared for and can effectively respond to disruptions, thereby maintaining the continuity of AI operations and minimising downtime."
          },
          {
            "control": "BU[2] -  Implement technical measures to support disaster recovery and business continuity, ensuring the resilience and availability of AI infrastructure.",
            "control_objective": "To deploy comprehensive technical controls that enable rapid recovery and continuity of AI operations in the event of a disruption, minimising data loss and operational downtime."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Insufficient Performance Monitoring and Analysis",
        "question": "Will the AI’s outputs need to be continuously monitored to ensure they stay accurate and relevant?",
        "controls": [
          {
            "control": "PER[1] -  Establish a structured performance monitoring and analysis process to ensure continuous oversight and optimization of AI infrastructure performance.",
            "control_objective": "To implement robust administrative controls that define roles, responsibilities, and procedures for performance monitoring and analysis, ensuring that performance issues are identified and addressed proactively."
          },
          {
            "control": "PER[2] -  Implement advanced technical measures to ensure continuous and effective performance monitoring and analysis of AI infrastructure.",
            "control_objective": "To deploy comprehensive technical controls that provide real-time visibility into AI system performance, enabling prompt detection and resolution of performance issues to maintain optimal operation."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Inadequate Security Monitoring and Threat Detection",
        "question": "Do you need visibility into whether this AI system is under attack or being misused?",
        "controls": [
          {
            "control": "STM[1] -  Establish a security monitoring and threat detection process to ensure continuous oversight and protection of AI infrastructure.",
            "control_objective": "To implement robust administrative controls that define roles, responsibilities, policies, and procedures for effective security monitoring and threat detection, ensuring proactive identification and mitigation of security threats."
          },
          {
            "control": "STM[2] -  Implement advanced technical measures to ensure continuous and effective security monitoring and threat detection within AI infrastructure.",
            "control_objective": "To deploy comprehensive technical controls that provide real-time visibility into security threats and enable prompt detection and response to ensure the protection and integrity of AI systems."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Ineffective Incident Management",
        "question": "Do you have a process in place if the AI system causes an issue (e.g., incorrect output, outage, or data leak)?",
        "controls": [
          {
            "control": "IM[1] -  Establish an incident management capability to ensure effective detection, response, and mitigation of AI-related incidents.",
            "control_objective": "To establish incident management processes that define roles, responsibilities, and procedures for managing AI-related incidents, ensuring timely and effective response to maintain AI system integrity and security."
          },
          {
            "control": "IM[2] -  Implement advanced technical measures to detect, prevent, and mitigate AI system hallucinations and other incidents, ensuring the reliability and accuracy of AI outputs.",
            "control_objective": "To deploy comprehensive technical controls that provide real-time visibility into AI system performance and security, enabling prompt detection and resolution of incidents to maintain optimal operation."
          }
        ]
      }
        ]
    },

    "(6.2.1) AI Lifecycle Phase requirements - Use and Decommissioning": {
        "WebFormTitle": "Define the security requirements for - Use and Decommissioning.",
        "Fields": [
      {
        "FieldType": "risk",
        "FieldName": "Insufficient Audit Trails and Logging",
        "question": "Will you need to track who accessed the AI system, what it did, and when — for accountability or regulatory purposes?",
        "controls": [
          {
            "control": "AT[1] -  Record detailed logs of all data pre-processing activities, including data cleaning, normalisation, transformation, and any outlier removal or imputation techniques applied. Include timestamps, user IDs, and descriptions of actions taken.",
            "control_objective": "To enable traceability and reconstruction of the entire data pre-processing workflow, providing a clear audit trail for identifying any issues or anomalies that may arise during this phase."
          },
          {
            "control": "AT[2] -  Store logs in a secure and tamper-proof manner, ensuring their integrity and availability for future audits or investigations.",
            "control_objective": "To ensure the availability of audit logs for a sufficient period to allow for thorough analysis and investigation of potential security or compliance issues. Protect logs from unauthorised modification or deletion to maintain their evidentiary value."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Insecure Data Sharing and Transfer",
        "question": "Will this AI system exchange data across teams, systems, or external vendors that may not have the same security controls?",
        "controls": [
          {
            "control": "DT[1] -  Implement secure data transfer protocols and encryption mechanisms for proprietary datasets during collection, storage, and fine-tuning processes.",
            "control_objective": "To protect the confidentiality and integrity of sensitive data throughout its lifecycle, preventing unauthorised access or tampering during data sharing and transfer activities. [PR.DS-02]"
          },
          {
            "control": "DT[2] -  Establish data sharing agreements and protocols with internal and external stakeholders involved in the data collection and fine-tuning processes.",
            "control_objective": "To define clear guidelines, roles, and responsibilities for secure data sharing, ensuring compliance with data protection regulations and ethical standards. [GV.SC-02, GV.SC-05]"
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "Inadequate User Training and Awareness",
        "question": "Will non-technical users rely on this AI — and have they been trained on its limitations and correct usage?",
        "controls": [
          {
            "control": "[Art-9][Par-5][5c] -  Provide comprehensive information and training to AI system users within the organisation, considering their technical knowledge, experience, and education.",
            "control_objective": "To ensure safe and responsible use of the adopted AI system by equipping users with necessary knowledge and skills."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "LLM01 Prompt Injection",
        "question": "Will external users or other systems provide text prompts or instructions to the AI model?",
        "controls": [
          {
            "control": "[LLM01][1] - All user inputs within the UI must be validated to prevent the injection of malicious code.",
            "control_objective": "Prevent attackers from exploiting vulnerabilities in the UI to inject malicious code and compromise the AI system."
          },
          {
            "control": "[LLM01][2] - Implement input sanitization techniques to remove harmful characters from user inputs.",
            "control_objective": "Further mitigate the risk of malicious code injection attempts through the UI."
          },
          {
            "control": "[LLM01][4] - Encrypt all sensitive data transmitted through APIs.",
            "control_objective": "Protect sensitive data from unauthorised interception or tampering during communication through APIs."
          },
          {
            "control": "[LLM01][5] - Enforce privilege control on LLM access to backend systems.",
            "control_objective": "To restrict the LLM to the minimum level of access necessary, mitigating the risk of prompt injection leading to unauthorised operations."
          },
          {
            "control": "[LLM01][8] - Treat the LLM as an untrusted component, ensuring user oversight over decision-making processes.",
            "control_objective": "To treat the LLM as an untrusted component, ensuring user oversight over decision-making processes."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "LLM02 Insecure Output Handling",
        "question": "Will the AI output be used in other systems, documents, or communications without being verified first?",
        "controls": [
          {
            "control": "[LLM02][1] - Ensure that sensitive or IP data is not exposed in AI system outputs.",
            "control_objective": "To mitigate the risk of insecure output handling by treating LLM-generated outputs as potentially untrusted."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "LLM04 Model Denial of Service",
        "question": "Could this AI system be overwhelmed or misused in a way that impacts availability?",
        "controls": [
          {
            "control": "[LLM04][3] - Enforce API rate limits to restrict the number of requests an individual user or IP address can make within a specific timeframe.",
            "control_objective": "To control the rate of requests and prevent overwhelming the LLM with a high volume of concurrent requests."
          },
          {
            "control": "[LLM04][4] - Limit the number of queued actions and the number of total actions in a system reacting to LLM responses.",
            "control_objective": "To prevent the accumulation of excessive workload and ensure that the system can effectively process LLM responses without becoming overwhelmed."
          },
          {
            "control": "[LLM04][5] - Continuously monitor the resource utilisation of the LLM to identify abnormal spikes or patterns that may indicate a DoS attack.",
            "control_objective": "To detect and respond to anomalous resource usage patterns indicative of a denial of service attack on the LLM."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "LLM05: Supply Chain Vulnerabilities",
        "question": "Does the AI system depend on third-party libraries, tools, or models you haven’t vetted?",
        "controls": [
          {
            "control": "[LLM05][2] - Only use reputable plugins that have been tested for application requirements.",
            "control_objective": "Minimise plugin-related vulnerabilities."
          },
          {
            "control": "[LLM05][4] - Maintain an up-to-date inventory using a Software Bill of Materials (SBOM).",
            "control_objective": "Track and manage components."
          },
          {
            "control": "[LLM05][6] - Implement anomaly detection and adversarial robustness tests.",
            "control_objective": "Detect tampering and poisoning."
          },
          {
            "control": "[LLM05][7] - Implement sufficient monitoring and a robust patching policy.",
            "control_objective": "Maintain system security and component currency."
          },
          {
            "control": "[LLM05][8] - Regularly review and audit supplier security and access controls.",
            "control_objective": "Verify supplier compliance and security."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "LLM08 Excessive Agency",
        "question": "Will the AI be allowed to take actions or make decisions automatically on behalf of a person or system?",
        "controls": [
          {
            "control": "[LLM08][4] - Limit the permissions that LLM plugins/tools are granted to other systems to the minimum necessary.",
            "control_objective": "To restrict the scope of actions that LLM agents can perform on other systems, thereby minimising the potential for harmful activities."
          },
          {
            "control": "[LLM08][5] - Track user authorization and security scope to ensure actions taken on behalf of a user are executed with the minimum privileges necessary.",
            "control_objective": "To enforce proper user authentication and authorization, limiting the potential impact of actions performed by LLM agents."
          },
          {
            "control": "[LLM08][8] - Log and monitor the activity of LLM plugins/tools and downstream systems to identify and respond to undesirable actions.",
            "control_objective": "To detect and mitigate unauthorised or harmful activities by monitoring system activity and responding promptly to incidents."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "LLM10: Model Theft",
        "question": "Is this AI system considered a valuable business asset — and could losing it expose intellectual property or trade secrets?",
        "controls": [
          {
            "control": "[LLM10][4] - Restrict the LLMs access to network resources, internal services, and APIs.",
            "control_objective": "Control what the LLM application has access to."
          },
          {
            "control": "[LLM10][6] - Automate MLOps deployment with governance and tracking and approval workflows.",
            "control_objective": "Tighten access and deployment controls."
          }
        ]
      },
      {
        "FieldType": "risk",
        "FieldName": "[C.3.6] - Unsafe Decommissioning of AI Systems",
        "question": "When this AI system is eventually retired, is there a formal plan to handle its data and models securely and to manage the transition to a replacement system without creating operational gaps?",
        "controls": [
          {
            "control": "[C.3.6][BP-13] - Establish a formal decommissioning plan that specifies procedures for the secure archiving or certified destruction of the AI model and all associated data, in compliance with data retention policies and privacy regulations.",
            "control_objective": "To prevent data breaches and the misuse of sensitive information or obsolete models after the system is retired."
          },
          {
            "control": "[C.3.6][BP-14] - Ensure a managed transition when replacing an AI system by maintaining operational continuity, potentially through a period of overlap with the new system, to prevent any gaps in critical functionality.",
            "control_objective": "To avoid creating vulnerabilities or disruptions to business processes during the transition from an old AI system to its replacement."
          },
          {
            "control": "[C.3.6][BP-15] - Have an incident response plan for AI-related failures, including procedures for safe shutdown, reversion to manual processes, and clear communication to stakeholders.",
            "control_objective": "To minimize harm and operational disruption when an AI incident occurs and ensure a structured recovery process."
          }
        ]
      }   
        ]
    },
    "(A.6.2.4) AI Systems verifications": {
        "WebFormTitle": "Document verification and validation measures for the AI system and specify criteria for their use.",
        "Fields": [
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Performance and Fairness Monitoring V&V",
                "FieldLabel": "Performance Monitoring Verification",
                "FieldText": "Verify the implementation of monitoring tools and dashboards. Test the system's ability to detect simulated performance degradation (e.g., accuracy drop >5%) and fairness metric violations (e.g., disparate impact ratio <0.8). Confirm that automated alerts are configured and successfully trigger notifications to the designated personnel.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Human Oversight V&V",
                "FieldLabel": "Human Oversight Validation",
                "FieldText": "Review and approve the documented human oversight procedures. Validate that the user interface provides the necessary information and controls for a human to intervene, override, or stop the system's process. Conduct user acceptance testing (UAT) with designated overseers to confirm they can effectively perform their roles.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Adherence to Intended Use V&V",
                "FieldLabel": "Intended Use Adherence Verification",
                "FieldText": "Verify that the 'Intended Use' documentation is clear, complete, and accessible to all users. Test any implemented technical controls (e.g., access restrictions, input validation) designed to prevent use outside the defined scope. Confirm user training materials explicitly cover approved use cases and limitations.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Incident Management V&V",
                "FieldLabel": "Incident Management Validation",
                "FieldText": "Verify that an AI-specific incident management plan exists. Conduct a tabletop exercise or simulation of a critical AI failure (e.g., major bias detection, system outage). Validate that reporting channels, escalation paths, and response roles function as documented and meet defined SLAs.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Operational Transparency V&V",
                "FieldLabel": "Operational Transparency Validation",
                "FieldText": "Validate that all user interfaces clearly disclose that an AI system is in use. Review system-generated notifications and explanations for clarity, accuracy, and completeness. Verify that mechanisms for users to access more detailed information or provide feedback are implemented as specified in the requirements.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Data Management V&V",
                "FieldLabel": "Operational Data Management Verification",
                "FieldText": "Verify that data handling processes align with the Data Privacy Impact Assessment (DPIA). Conduct penetration testing and vulnerability scans on data storage and transmission channels. Validate that data minimization techniques (e.g., anonymization) are correctly implemented and that data retention policies are automatically enforced.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - System Maintenance V&V",
                "FieldLabel": "System Maintenance Plan Verification",
                "FieldText": "Verify the existence of a comprehensive system maintenance plan, including schedules for performance reviews and security patching. Validate the documented procedure for model retraining and redeployment. Review and approve the decommissioning plan to ensure it addresses data archival/deletion and stakeholder communication.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            }
        ]
    },
    "AI Systems approvals": {
        "WebFormTitle": "Document AI system approvals",
        "Fields": [
            {
                "FieldName": "AI System Security Approver",
                "FieldLabel": "Security Approver",
                "FieldText": "Name/Role of the Security Aprover",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "AI System Security Approval",
                "FieldLabel": "Security Approved",
                "FieldText": "",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "AI System DPO Approver",
                "FieldLabel": "DPO Approver",
                "FieldText": "Name/Role of the DPO Aprover",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "AI System DPO Approval",
                "FieldLabel": "DPO Approved",
                "FieldText": "",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "AI System Risk Approver",
                "FieldLabel": "Risk Approver",
                "FieldText": "Name/Role of the Risk Aprover",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "AI System Risk Approval",
                "FieldLabel": "Risk Approved",
                "FieldText": "",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "AI System Business Approver",
                "FieldLabel": "Business Approver",
                "FieldText": "Name/Role of the Business Approver",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "AI System Business Approval",
                "FieldLabel": "Business Approved",
                "FieldText": "",
                "FieldType": "Option box with values:Yes/No"
            }
        ]
    }
}
