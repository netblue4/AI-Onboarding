{
    "(A.9.4) AI system's intended use and limitations": {
        "WebFormTitle": "Document the AI system's intended use and limitations.",
        "Fields": [
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - AI System ID",
                "FieldLabel": "AI System ID",
                "FieldText": "AI System Unique Number",
                "FieldType": "Auto generated number"
            },
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - Name",
                "FieldLabel": "Name",
                "FieldText": "Name of the AI application",
                "FieldType": "TextBox"
            },
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - Target Users",
                "FieldLabel": "",
                "FieldText": "Who are the Target Users of the Ai system?",
                "FieldType": "Dropdown box with values:/Employees/Customers/Analysts/Customer/Supplier/Partner/Regulator"
            },
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - Business Purpose",
                "FieldLabel": "Business Purpose",
                "FieldText": "What specific business problem or task does this system address?",
                "FieldType": "TextBox"
            },
            {
                "Control": "A.9.4 – Intended use of the AI system",
                "FieldName": "(A.9.4) - Intended Use",
                "FieldLabel": "Intended Use",
                "FieldText": "Describe the use cases of how the AI system will solve the specific business problem or task",
                "FieldType": "TextBox"
            }
        ]
    },
    /*"(A.9.3) Objectives for Responsible and Ethical Use of AI Systems": {
        "WebFormTitle": "Describe the Responsible and Ethical objectives to guide the use of AI systems.",
        "Fields": [    
            {
                "Control": "A.9.3 – Objectives for responsible use of AI system",
                "FieldName": "(9.3) - Performance and Fairness Monitoring",
                "FieldLabel": "Performance Monitoring",
                "FieldText": "To continuously monitor the AI system's performance and fairness in the live environment to promptly detect and address model drift or emergent biases.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.9.3 – Objectives for responsible use of AI system",
                "FieldName": "(9.3) - Human Oversight",
                "FieldLabel": "Human Oversight",
                "FieldText": "To ensure that all required human oversight and intervention procedures are consistently followed for AI-generated decisions, especially in high-risk scenarios.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.9.3 – Objectives for responsible use of AI system",
                "FieldName": "(9.3) - Adherence to Intended Use",
                "FieldLabel": "Intended Use Adherence",
                "FieldText": "To ensure the AI system is used strictly within its defined and approved scope, and to prevent its application in unauthorized or unintended contexts.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.9.3 – Objectives for responsible use of AI system",
                "FieldName": "(9.3) - Incident Management",
                "FieldLabel": "Incident Management",
                "FieldText": "To establish and maintain a responsive process for identifying, reporting, and remediating incidents or adverse outcomes resulting from the AI system's operation.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.9.3 – Objectives for responsible use of AI system",
                "FieldName": "(9.3) - Operational Transparency",
                "FieldLabel": "Operational Transparency",
                "FieldText": "To provide clear and timely communication to users and affected stakeholders about the AI system's presence, capabilities, and limitations during its operation.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.9.3 – Objectives for responsible use of AI system",
                "FieldName": "(9.3) - Data Management",
                "FieldLabel": "Operational Data Management",
                "FieldText": "To apply data protection and privacy principles to all data processed by the AI system in the production environment, in line with legal and policy requirements.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.9.3 – Objectives for responsible use of AI system",
                "FieldName": "(9.3) - System Maintenance",
                "FieldLabel": "System Maintenance",
                "FieldText": "To maintain the AI system through regular updates, security patches, and performance reviews, and to manage its eventual decommissioning responsibly.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            }
        ]
    },*/
     "(A.6.2.2) AI system's Functional Requirement": {
        "WebFormTitle": "Specify and document all requirements for new AI systems or for material enhancements to existing systems.",
        "Fields": [       
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Processing Logic",
                "FieldLabel": "Processing Logic",
                "FieldText": "What’s the core logic or model behavior expected?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Outputs",
                "FieldLabel": "Outputs",
                "FieldText": "What outputs should the system produce?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Interaction Model",
                "FieldLabel": "Interaction Model",
                "FieldText": "Will it run in the background, have a UI, API, etc.?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Performance",
                "FieldLabel": "Performance",
                "FieldText": "Are there any SLA's associated with the AI system?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Compliance",
                "FieldLabel": "Compliance",
                "FieldText": "Are there regulations or policies it must follow? (e.g., GDPR, AI Act)",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Performance and Fairness Monitoring",
                "FieldLabel": "Performance and Fairness Monitoring",
                "FieldText": "What are the requirements for monitoring the AI system's performance and fairness in the live environment to detect and address model drift or emergent biases?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Human Oversight",
                "FieldLabel": "Human Oversight",
                "FieldText": "Specify the requirements for human oversight and intervention procedures, especially for high-risk scenarios.",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Intended Use Adherence",
                "FieldLabel": "Intended Use Adherence",
                "FieldText": "What technical or procedural controls are required to ensure the AI system is used strictly within its defined and approved scope?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Incident Management",
                "FieldLabel": "Incident Management",
                "FieldText": "What processes are required for identifying, reporting, and remediating incidents or adverse outcomes from the AI system's operation?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Operational Transparency",
                "FieldLabel": "Operational Transparency",
                "FieldText": "What are the requirements for communicating the AI system's presence, capabilities, and limitations to users and affected stakeholders?",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - Operational Data Management",
                "FieldLabel": "Operational Data Management",
                "FieldText": "Specify the data protection and privacy requirements for all data processed by the AI system in the production environment.",
                "FieldType": "TextBox"
            },
            {
                "Control": "6.2.2 – AI system requirements and specification",
                "FieldName": "(A.6.2.2) - System Maintenance",
                "FieldLabel": "System Maintenance",
                "FieldText": "What are the requirements for system maintenance, including updates, security patches, performance reviews, and eventual decommissioning?",
                "FieldType": "TextBox"
            }
        ]
    },
    "AI Act Prohibited Practices Assessment": {
        "WebFormTitle": "Determine if the AI system is prohibited",
        "Fields": [
            {
                "FieldName": "Subliminal Manipulation",
                "FieldLabel": "Subliminal Manipulation",
                "FieldText": "Does the AI system deploy techniques beyond a person's consciousness to materially distort their behavior in a way that is likely to cause harm?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Exploitation of Vulnerabilities",
                "FieldLabel": "Exploitation of Vulnerabilities",
                "FieldText": "Does the AI system exploit vulnerabilities of a specific group (e.g., due to age, physical or mental disability, social or economic situation) to materially distort their behavior in a way likely to cause harm to that person or another?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Social Scoring",
                "FieldLabel": "Social Scoring",
                "FieldText": "Is the AI system used by public authorities for evaluating or classifying the trustworthiness of natural persons based on their social behavior or personal characteristics, leading to detrimental or unfavorable treatment?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Real-time Remote Biometric Identification",
                "FieldLabel": "Biometric Identification",
                "FieldText": "Is the AI system used by law enforcement for real-time remote biometric identification of natural persons in publicly accessible spaces? (Note: Very limited exceptions exist)",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Emotion Inference",
                "FieldLabel": "Emotion Inference",
                "FieldText": "Does the AI system infer emotions of natural persons in the context of workplaces or educational institutions?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Biometric Categorization",
                "FieldLabel": "Biometric Categorization",
                "FieldText": "Does the AI system use biometric data to categorize natural persons based on sensitive attributes like race, political opinions, trade union membership, religious or philosophical beliefs, or sexual orientation?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Untargeted Scraping of Facial Images",
                "FieldLabel": "Untargeted Scraping of Facial Images",
                "FieldText": "Does the AI system involve untargeted scraping of facial images from the internet or CCTV footage to create or expand facial recognition databases?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Risk Assessment of Criminal Offenses (Profiling)",
                "FieldLabel": "Criminal Offenses (Profiling)",
                "FieldText": "Does the AI system assess the risk of a natural person committing a criminal offense based solely on profiling or assessment of their personality traits or characteristics?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "AI system is Prohibited",
                "FieldLabel": "AI system is Prohibited",
                "FieldText": "If the answer to any of these questions is \"Yes,\" the AI system may be prohibited under the AI Act.||For a more detailed assessment, you can refer to the EU AI Act Compliance Checker: https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/",
                "FieldType": "Option box with values:Yes/No"
            }
        ]
    },
    "Decision point": {
        "WebFormTitle": "If the system is Prohibited then Exit else continue to next step.",
        "Fields": [
            {
                "FieldName": "Prohibited Practices - AI system is Prohibited",
                "FieldLabel": "FieldName = the field to interigate to determine the decision branch.",
                "FieldText": "If the answer to any of these questions is \"Yes,\" the AI system may be prohibited under the AI Act.\nFor a more detailed assessment, you can refer to the EU AI Act Compliance Checker||https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/",
                "FieldType": "Decision:Yes=Document AI system approvals/No=Determine the AI system's Data Sensitivity & Privacy impact",
                "YesTarget": "Document AI system approvals",
                "NoTarget": "Determine the AI System Significance"
            }
        ]
    },
    "High-Risk AI Systems Questionnaire": {
        "WebFormTitle": "Determine the AI System is High-Risk according to the AI Act.",
        "Fields": [
            {
                "FieldName": "Process, store, or interpret any sensitive data",
                "FieldLabel": "Process, store, or interpret any sensitive data",
                "FieldText": "Will the AI system process, store, or interpret any sensitive data (e.g., personal health information (PHI), personally identifiable information (PII) beyond basic contact details, financial data, biometric data, protected class information, classified data)?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Output directly or indirectly lead to decisions or actions that impact an individual's privacy rights",
                "FieldLabel": "Individual's privacy rights",
                "FieldText": "Will the AI system's output directly or indirectly lead to decisions or actions that impact an individual's privacy rights (e.g., surveillance, profiling for targeted advertising, monitoring of online behavior)?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Calculations, make decisions, or provide recommendations that support a critical business function",
                "FieldLabel": "Critical business function",
                "FieldText": "Will the AI system perform calculations, make decisions, or provide recommendations that support a critical business function (e.g., fraud detection, credit scoring, medical diagnosis, infrastructure management, legal compliance, safety-critical operations)?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "Failure, error, or bias negitively impact organiation or individual",
                "FieldLabel": "Risk exposure",
                "FieldText": "Could a failure, error, or bias in the AI system's operation lead to significant financial loss, reputational damage, legal/regulatory penalties, or harm to individuals (e.g., physical harm, denial of services, unfair treatment)?",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "AI system is High-Risk",
                "FieldLabel": "AI system is Significant",
                "FieldText": "An AI system is considered 'Significant' and requires a more detailed risk assessment if:\n- Any single question in Section 1 (Data Sensitivity & Privacy) or Section 2 (Critical Business Function & Impact) is answered 'Yes'.\n- Three or more questions across all sections (excluding Section 1 and 2 if they triggered significance) are answered 'Yes'.\nIf the AI system is determined to be 'Significant', proceed with the detailed risk assessment. Otherwise, it can proceed with standard operational reviews.",
                "DecisionFieldType": "Option box with values:/Yes=\"Conduct a detialed AI System Risk Impact Assessment.\"/No=\"Conduct a AI System Risk Category Impact Assessment.\""
            }
        ]
    },
    "Decidion point": {
        "WebFormTitle": "Define the AI system's Significance",
        "Fields": [                        
            {
                "FieldName": "AI System Significance: AI system is Significant",
                "FieldLabel": "FieldName = the field to interigate to determine the decision branch.",
                "FieldText": "An AI system is considered 'Significant' and requires a more detailed risk assessment if:\n- Any single question in Section 1 (Data Sensitivity & Privacy) or Section 2 (Critical Business Function & Impact) is answered 'Yes'.\n- Three or more questions across all sections (excluding Section 1 and 2 if they triggered significance) are answered 'Yes'.\nIf the AI system is determined to be 'Significant', proceed with the detailed risk assessment. Otherwise, it can proceed with standard operational reviews.",
                "FieldType": "Decision",
                "YesTarget": "Conduct a detialed AI System Risk Impact Assessments",
                "NoTarget": "Conduct a AI System Risk Category Impact Assessment"           
            }
        ]
    },
    "AI Act - Section 2: Requirements for High-Risk AI Systems": {
        "WebFormTitle": "Define the security requirements for - High-Risk AI Systems.",
        "Fields": [
            {
                "FieldType": "risk",
                "FieldName": "[Article 8] - Non-Compliance with High-Risk AI System Requirements",
                "question": "Is the AI system, or the product incorporating the AI system, subject to other EU regulations, and if so, how is compliance with all applicable regulations, including the AI Act, managed and documented?",
                "controls": [
                 {
                  "control": "[Art-8][Par-1][1] - Establish and maintain a documented process to ensure and demonstrate that high-risk AI systems comply with the requirements of Section 2 of the AI Act, considering the system's intended purpose and the state of the art in AI.",
                  "control_objective": "To ensure that high-risk AI systems meet all legal and technical standards set forth in the AI Act, and to have a clear, auditable trail of compliance."
                 },
                 {
                  "control": "[Art-8][Par-2][2] - For products containing a high-risk AI system that are also subject to other Union harmonisation legislation, ensure the product is fully compliant with all applicable requirements from all relevant regulations.",
                  "control_objective": "To achieve comprehensive legal compliance for products that incorporate AI systems and are subject to multiple regulatory frameworks."
                 },
                 {
                  "control": "[Art-8][Par-2][3] - Where applicable, integrate the testing, reporting, and documentation processes required by the AI Act with existing compliance processes under other EU legislation to ensure consistency, avoid duplication, and minimize administrative burden.",
                  "control_objective": "To streamline compliance activities, improve efficiency, and ensure a coherent approach to regulatory requirements across different legal instruments."
                 }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 9] - Inadequate or Ineffective Risk Management",
                "question": "Does the organization have a documented and continuously updated risk management system for its high-risk AI systems that covers the entire lifecycle of the system?",
                "controls": [
                  {
                    "control": "[Art-9][Par-1][1] - Establish, implement, document, and maintain a comprehensive risk management system for high-risk AI systems.",
                    "control_objective": "To ensure a systematic and ongoing process for identifying, evaluating, and mitigating risks associated with high-risk AI systems throughout their lifecycle."
                  },
                  {
                    "control": "[Art-9][Par-2][2] - Implement a continuous iterative risk management process that includes regular systematic reviews and updates, covering identification, analysis, estimation, and evaluation of foreseeable risks.",
                    "control_objective": "To proactively manage and adapt to evolving risks by maintaining a dynamic and up-to-date risk management framework."
                  },
                  {
                    "control": "[Art-9][Par-2][3] - Adopt appropriate and targeted risk management measures to address identified risks, including those from post-market monitoring.",
                    "control_objective": "To effectively mitigate identified risks through the implementation of specific and relevant control measures."
                  },
                  {
                    "control": "[Art-9][Par-5][4] - Ensure that residual risks, both individual and overall, are acceptable by eliminating or reducing risks as far as technically feasible through design, implementing mitigation measures, and providing information and training.",
                    "control_objective": "To reduce the potential for harm to an acceptable level by employing a multi-layered approach to risk mitigation."
                  },
                  {
                    "control": "[Art-9][Par-6][5] - Conduct testing of high-risk AI systems to identify the most appropriate risk management measures and to ensure consistent performance and compliance with requirements.",
                    "control_objective": "To validate the effectiveness of risk management measures and ensure the AI system operates as intended."
                  },
                  {
                    "control": "[Art-9][Par-9][6] - Consider the potential adverse impact on persons under the age of 18 and other vulnerable groups when implementing the risk management system.",
                    "control_objective": "To provide heightened protection for vulnerable populations who may be disproportionately affected by the AI system."
                  }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 10] - Poor Data Quality and Governance",
                "question": "Are there appropriate data governance and management practices in place for the training, validation, and testing datasets used by the high-risk AI system to ensure they are relevant, representative, and free of errors and biases?",
                "controls": [
                  {
                    "control": "[Art-10][Par-2][1] - Implement and document data governance and management practices covering the entire data lifecycle, including design choices, collection, and preparation processes like annotation and cleaning.",
                    "control_objective": "To ensure that data used for high-risk AI systems is handled systematically and responsibly, maintaining quality and integrity from collection to use."
                  },
                  {
                    "control": "[Art-10][Par-2][2] - Establish a process to examine data sets for possible biases that could negatively impact fundamental rights, health, or safety, and implement measures to detect, prevent, and mitigate these biases.",
                    "control_objective": "To minimize the risk of discriminatory or unfair outcomes and ensure the AI system operates in a manner that is safe and respects fundamental rights."
                  },
                  {
                    "control": "[Art-10][Par-3][3] - Ensure that training, validation, and testing data sets are relevant, sufficiently representative, free of errors, and complete for the system's intended purpose, with appropriate statistical properties.",
                    "control_objective": "To build a robust and reliable AI system by using high-quality data that accurately reflects the operational environment and minimizes performance issues."
                  },
                  {
                    "control": "[Art-10][Par-4][4] - Verify that data sets account for the specific geographical, contextual, behavioral, or functional settings in which the high-risk AI system will be used.",
                    "control_objective": "To ensure the AI system performs effectively and as intended in its specific operational context, reducing the risk of failures due to environmental mismatches."
                  },
                  {
                    "control": "[Art-10][Par-5][5] - Where strictly necessary for bias detection and correction, process special categories of personal data only with appropriate safeguards, technical limitations, and security measures, ensuring data is deleted after use.",
                    "control_objective": "To enable effective bias mitigation while upholding the highest standards of data protection and privacy for sensitive personal information."
                  }
                ]
             },
             {
                "FieldType": "risk",
                "FieldName": "[Article 12] - Inadequate Traceability and Record-Keeping",
                "question": "Does the organization need to trace the operational history of its high-risk AI system to investigate incidents, audit results, or ensure accountability?",
                "controls": [
                 {
                  "control": "[Art-12][Par-1][1] - Implement capabilities for the automatic recording of events (logs) while the high-risk AI system is operating.",
                  "control_objective": "To ensure a level of traceability of the AI system’s functioning throughout its lifecycle that is appropriate to its intended purpose."
                 },
                 {
                  "control": "[Art-12][Par-2][2] - For high-risk AI systems covered by specific points in Annex III (e.g., biometrics, law enforcement), ensure logging capabilities record the period of each use, the reference database, the input data, and the identity of the persons involved in verifying the results.",
                  "control_objective": "To provide detailed operational transparency and accountability for AI systems used in critical public and justice-related applications."
                 },
                 {
                  "control": "[Art-12][Par-4][3] - For AI systems intended for remote biometric identification, ensure logging capabilities record the period of use, reference database, input data, and the identification of the person generating the match.",
                  "control_objective": "To enhance auditability and accountability in the use of sensitive remote biometric identification technologies."
                 }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 13] - Lack of Transparency and Provision of Information to Users",
                "question": "Will users of this AI system need to understand its capabilities, limitations, and the meaning of its outputs to use it safely and effectively?",
                "controls": [
                  {
                    "control": "[Art-13][Par-1] - Ensure the design of high-risk AI systems allows users to interpret outputs and use the system appropriately.",
                    "control_objective": "To enable safe and effective use of the AI system by ensuring user comprehension."
                  },
                  {
                    "control": "[Art-13][Par-2] - Provide clear, complete, and accessible instructions for use with all high-risk AI systems.",
                    "control_objective": "To ensure users have the necessary information to operate the AI system correctly and safely."
                  },
                  {
                    "control": "[Art-13][Par-3a] - Include the identity and contact details of the provider and their authorized representative in the instructions for use.",
                    "control_objective": "To establish clear lines of communication and accountability for the AI system."
                  },
                  {
                    "control": "[Art-13][Par-3b] - Detail the AI system's characteristics, capabilities, limitations, intended purpose, accuracy, robustness, cybersecurity, and performance metrics in the instructions for use.",
                    "control_objective": "To provide a comprehensive understanding of the AI system's operational parameters and performance expectations."
                  },
                  {
                    "control": "[Art-13][Par-3c-e-f] - Specify the necessary hardware resources, expected lifetime, maintenance, and pre-determined changes for operating the AI system in the instructions for use.",
                    "control_objective": "To ensure users have the required infrastructure and information to run and maintain the AI system effectively over its lifecycle."
                  },
                  {
                    "control": "[Art-13][Par-3d] - Detail the human oversight measures from Article 14, including technical aids for interpreting system outputs, in the instructions for use.",
                    "control_objective": "To facilitate effective human oversight and intervention in the AI system's operation."
                  }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 14] - Ineffective or Insufficient Human Oversight",
                "question": "Does the AI system operate in a way that requires human monitoring, intervention, or decision-making to prevent or mitigate risks to health, safety, or fundamental rights?",
                "controls": [
                  {
                    "control": "[Art-14][Par-1] - Design and develop high-risk AI systems with appropriate human-machine interface tools to enable effective oversight by natural persons.",
                    "control_objective": "To ensure that a human can effectively monitor and control the AI system while it is in use."
                  },
                  {
                    "control": "[Art-14][Par-2] - Implement human oversight to prevent or minimize risks to health, safety, or fundamental rights, especially those risks that persist after other requirements have been applied.",
                    "control_objective": "To provide a final layer of risk mitigation through active human involvement."
                  },
                  {
                    "control": "[Art-14][Par-3] - Ensure human oversight measures are built into the AI system by the provider or are appropriate for implementation by the deployer.",
                    "control_objective": "To integrate necessary oversight capabilities either directly into the system or into the operational procedures of the user."
                  },
                  {
                    "control": "[Art-14][Par-4a, 4b, 4c] - Enable assigned human overseers to understand the AI system's capabilities and limitations, monitor for anomalies, and correctly interpret its output, while remaining aware of potential automation bias.",
                    "control_objective": "To empower human overseers with the knowledge and awareness needed to make informed judgments about the system's performance."
                  },
                  {
                    "control": "[Art-14][Par-4d, 4e] - Enable assigned human overseers to have the ability to decide not to use the system, override its output, or interrupt its operation via a 'stop' button or similar procedure.",
                    "control_objective": "To ensure ultimate human control over the AI system's actions and decisions in any given situation."
                  },
                  {
                    "control": "[Art-14][Par-5] - For remote biometric identification systems, ensure that any identification is verified and confirmed by at least two competent, trained, and authorized natural persons before action is taken.",
                    "control_objective": "To increase the reliability and accountability of critical identification tasks performed by AI."
                  }
                ]
              },
              {
                "FieldType": "risk",
                "FieldName": "[Article 15] - Inadequate Accuracy, Robustness, and Cybersecurity",
                "question": "Will poor AI performance (e.g., incorrect or unreliable outputs) cause business disruption, compliance issues, or customer dissatisfaction?",
                "controls": [
                  {
                    "control": "[Art-15][Par-1] - Ensure high-risk AI systems are designed and developed to achieve and maintain an appropriate level of accuracy, robustness, and cybersecurity throughout their lifecycle.",
                    "control_objective": "To maintain the system's trustworthiness and prevent harm from inaccurate or insecure operation."
                  },
                  {
                    "control": "[Art-15][Par-2] - Encourage the development of benchmarks and measurement methodologies for accuracy and robustness in cooperation with relevant stakeholders.",
                    "control_objective": "To establish standardized methods for evaluating and verifying the performance of AI systems."
                  },
                  {
                    "control": "[Art-15][Par-3] - Clearly state the levels of accuracy and the relevant accuracy metrics in the AI system's instructions for use.",
                    "control_objective": "To provide transparency to users about the system's expected performance."
                  },
                  {
                    "control": "[Art-15][Par-4] - Design AI systems to be resilient to errors, faults, or inconsistencies, using technical redundancies and fail-safe plans where appropriate, and mitigate risks from biased feedback loops in learning systems.",
                    "control_objective": "To ensure the system can handle unexpected situations and maintain stable performance without being negatively influenced by its own outputs."
                  },
                  {
                    "control": "[Art-15][Par-5] - Implement cybersecurity measures to protect high-risk AI systems from unauthorized alteration of their use, outputs, or performance by exploiting vulnerabilities.",
                    "control_objective": "To safeguard the AI system against malicious attacks such as data poisoning, model poisoning, and adversarial examples."
                  }
                ]
              }
        ]
    },
    
    "(6.2.1) AI Lifecycle Phase requirements - Design and Development": {
        "WebFormTitle": "Define the security requirements for - Design and Development.",
        "Fields": [

        ]
    },

    "(6.2.1) AI Lifecycle Phase requirements - Training": {
        "WebFormTitle": "Define the security requirements for - Training.",
        "Fields": [

        ]
    },

    "(6.2.1) AI Lifecycle Phase requirements - Package": {
        "WebFormTitle": "Define the security requirements for - Package.",
        "Fields": [

        ]
    },

    "(6.2.1) AI Lifecycle Phase requirements - Deployment, Maintenance and Updates": {
        "WebFormTitle": "Define the security requirements for - Deployment, Maintenance and Updates.",
        "Fields": [

        ]
    },

    "(6.2.1) AI Lifecycle Phase requirements - Use and Decommissioning": {
        "WebFormTitle": "Define the security requirements for - Use and Decommissioning.",
        "Fields": [

        ]
    },

    "(5.4) Assessing AI system impact on individuals or groups of individuals": {
        "WebFormTitle": "Assess the AI system's impact on individuals or groups of individuals.",
        "Fields": [
            {

            }
        ]
    },
    "(A.4.4) AI Systems Software and Tooling Resources": {
        "WebFormTitle": "Define the software and tools used by the AI system.",
        "Fields": [
            {
                "FieldName": "(A.4.2, A.4.4) - Tool Name and Version",
                "FieldLabel": "Tool Name and Version",
                "FieldText": "Name of the software, library, or framework and Version number.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.4) - Category",
                "FieldLabel": "",
                "FieldText": "Category of the tool?",
                "FieldType": "Dropdown box with values:/Programming Language/IDE/Data Processing/ML Framework/Version Control/Deployment"
            },
            {
                "FieldName": "(A.4.2, A.4.4) - Purpose/Use Case in Project",
                "FieldLabel": "Purpose/Use Case in Project",
                "FieldText": "Tooling Resources: How this tool will be used in the AI system's lifecycle.",
                "FieldType": "TextBox"
            }
        ]
    },
    "(A.4.5) AI Systems Computing Resources": {
        "WebFormTitle": "Define the computing resources used by the AI system",
        "Fields": [
            {
                "FieldName": "(A.4.2, A.4.5) - Computing Resource Name and Version",
                "FieldLabel": "Computing Resource Name and Version",
                "FieldText": "Name of the software, library, or framework.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.5) - Category",
                "FieldLabel": "",
                "FieldText": "Category of the computing resource.",
                "FieldType": "Dropdown box with values:/Dev Workstation/ML Training Cluster/Inference API Server/Data Lake Storage/EC2/S3/SQL Database"
            },
            {
                "FieldName": "(A.4.2, A.4.5) - Lifecycle Phase(s) Supported",
                "FieldLabel": "",
                "FieldText": "Which part of the AI lifecycle does this resource supports?",
                "FieldType": "Dropdown box with values:/Development/Training/Testing/Staging/Production/Monitoring"
            }
        ]
    },
    "(A.4.3) AI Systems Data Resources": {
        "WebFormTitle": "Define the data resources used by the AI system",
        "Fields": [
            {
                "FieldName": "(A.4.2, A.4.3) - Dataset Name",
                "FieldLabel": "Dataset Name",
                "FieldText": "Common or descriptive name of the dataset.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Description",
                "FieldLabel": "Description",
                "FieldText": "Brief overview of the dataset's content and general purpose.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.3, A.7.5) - Source",
                "FieldLabel": "",
                "FieldText": "Where does the data originate from?",
                "FieldType": "Dropdown box with values:/Internal database/Third-party vendor/Public repository/Synthetic generation"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Intended Use",
                "FieldLabel": "",
                "FieldText": "What is the specific purpose(s) of the data?",
                "FieldType": "Dropdown box with values:/Training data/Validation data/Test data/Production data"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Format",
                "FieldLabel": "",
                "FieldText": "What is the File format or storage system?",
                "FieldType": "Dropdown box with values:/CSV/JSON/Parquet/SQL DB"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Data Labeling",
                "FieldLabel": "",
                "FieldText": "How is the Data Labeled?",
                "FieldType": "Dropdown box with values:/Sensitive/Internal/Public"
            },
            {
                "FieldName": "(A.4.2, A.4.3, A.7.3,A.7.2) - Acquisition of data",
                "FieldLabel": "",
                "FieldText": "How will the Data be acquired and selected?",
                "FieldType": "Dropdown box with values:/Extracted from internal company databases (e.g., CRM, ERP)/Sourced from a publicly available dataset/Purchased or licensed from a third-party data provider/Collected directly from users with explicit consent/Scraped from public websites in compliance with terms of service/Streamed from IoT sensors or application logs/Artificially generated (synthetic data)/Selected based on defined quality and relevance criteria/Manually curated by subject matter experts/Sampled to ensure fair representation of subgroups (stratified sampling)/A combination of multiple sources/methods/Other (requires specific documentation)"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Retention Schedules",
                "FieldLabel": "",
                "FieldText": "What is the data Retention schedules based on legal and operational requirements?",
                "FieldType": "Dropdown box with values:/1 Year/5 Years/10 Years"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Secure Disposing",
                "FieldLabel": "Secure Disposing",
                "FieldText": "Descripbe the Secure methods for disposing of obsolete or redundant data.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Approximate Size",
                "FieldLabel": "Approximate Size",
                "FieldText": "What is the Estimated size of the data (e.g., number of records, GB, TB)?",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Access Method",
                "FieldLabel": "",
                "FieldText": "How will the data be accessed?",
                "FieldType": "Dropdown box with values:/S3 bucket path/API endpoint/Database query/Shared drive"
            },
            {
                "FieldName": "(A.4.2, A.4.3) - Owner/Custodian",
                "FieldLabel": "Owner/Custodian",
                "FieldText": "Person or team responsible for the data?",
                "FieldType": "TextBox"
            }
        ]
    },
    "(A.7.4) AI System Data Quality Requirements for Sensitive data": {
        "WebFormTitle": "Define the AI system's Data Quality Requirements for Sensitive data",
        "Fields": [ 
            {
                "FieldName": "(A.7.4) - Accuracy",
                "FieldLabel": "Accuracy",
                "FieldText": "Specify the minimum acceptable accuracy level, defined as the percentage of data points that are correct when compared to a trusted source.",
                "FieldType": "Dropdown box with values:/> 95%/> 50%/> 20%"
            },
            {
                "FieldName": "(A.7.4) - Completeness",
                "FieldLabel": "Completeness",
                "FieldText": "Specify the required level of data completeness, ensuring that all necessary data fields are populated.",
                "FieldType": "Dropdown box with values:/All critical information present/No nulls in essential fields/> 98% completeness for important fields"
            },
            {
                "FieldName": "(A.7.4) - Consistency",
                "FieldLabel": "Consistency",
                "FieldText": "Define the requirement for data consistency, ensuring data is free from logical contradictions and maintains integrity across related datasets.",
                "FieldType": "Dropdown box with values:/No contradictory information/No logical contradictions/< 1% inconsistency rate"
            },
            {
                "FieldName": "(A.7.4) - Recency",
                "FieldLabel": "Recency",
                "FieldText": "Specify how frequently the data must be updated to be considered current for its intended use.",
                "FieldType": "Dropdown box with values:/Real-time/Daily/Monthly/Yearly"
            },
            {
                "FieldName": "(A.7.4) - Source Traceability",
                "FieldLabel": "",
                "FieldText": "Specify whether the origin and history (provenance) of the data can be fully traced and verified.",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "(A.7.4) - Versioning Applied",
                "FieldLabel": "",
                "FieldText": "Specify the system or method used to manage and track different versions of the dataset.",
                "FieldType": "Dropdown box with values:/Git/DVC/Manual/Not Applicable"
            }
        ]
    },
    "(A.7.6) AI System Data Preparation Plan for Sensitive data": {
        "WebFormTitle": "Define the AI system's Data Preparation Plan for Sensitive Data",
        "Fields": [ 
            {
                "FieldName": "(A.7.2, A.7.6) - De-identification & Anonymization - Masking",
                "FieldLabel": "Masking",
                "FieldText": "Replace parts of sensitive data with a generic character (e.g., 'XXX-XX-1234' for a Social Security Number).",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - De-identification & Anonymization - Tokenization",
                "FieldLabel": "Tokenization",
                "FieldText": "Replace a sensitive data element with a non-sensitive equivalent, referred to as a \"token.\" The original data is stored in a secure vault.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - De-identification & Anonymization - Hashing",
                "FieldLabel": "Hashing",
                "FieldText": "Data Preparation Plan - Hashing||Use a cryptographic function to convert sensitive data into a fixed-size string of characters. It's a one-way process.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - De-identification & Anonymization - Generalization",
                "FieldLabel": "Generalization",
                "FieldText": "Reduce the precision of data. For example, changing a specific age ('34') to an age range ('30-40') or a full date of birth to just the year.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Access Control & Governance - Data Segregation",
                "FieldLabel": "Data Segregation",
                "FieldText": "Create physically or logically separate data stores for sensitive information, with strict access controls.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Access Control & Governance - Attribute-Based Access Control",
                "FieldLabel": "Attribute-Based Access Control",
                "FieldText": "Apply rules so that only users with specific attributes (e.g., role, department) can access certain data fields.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Minimization - Feature Pruning",
                "FieldLabel": "Feature Pruning",
                "FieldText": "Remove any data fields or columns that are not strictly necessary for the AI model's purpose.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Minimization",
                "FieldLabel": "Data Minimization",
                "FieldText": "Remove records of individuals who have not given consent for their data to be used for AI training.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Quality & Integrity (Post-Anonymization) - Integrity Checks",
                "FieldLabel": "Integrity Checks",
                "FieldText": "After de-identification, verify that relationships between anonymized fields (e.g., a tokenized user ID and their records) remain intact.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Cleaning & Quality - Handling Missing Values",
                "FieldLabel": "Handling Missing Values",
                "FieldText": "Remove empty or null fields, such as filling them with a mean/median/mode, or removing the row/column.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Cleaning & Quality - Correcting Inaccuracies",
                "FieldLabel": "Correcting Inaccuracies",
                "FieldText": "Identify and fixing demonstrably incorrect data points (e.g., typos, out-of-range values like a temperature of '1000°C').",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            },
            {
                "FieldName": "(A.7.2, A.7.6) - Data Cleaning & Quality - Removing Duplicates",
                "FieldLabel": "Removing Duplicates",
                "FieldText": "Identify and deleting redundant records from the dataset.",
                "FieldType": "Option box with values:Applicable/ Not Applicable"
            }
        ]
    },
    "(A.8.4) AI System Documentation and User Information": {
        "WebFormTitle": "Define and document the information, reporting, and incident communication plan for all internal and external interested parties.",
        "Fields": [
            {
                "FieldName": "(A.8.4) - Incident Communication Plan - Data Breach",
                "FieldLabel": "Data Breach",
                "FieldText": "Describe how incidents related to \"Unintended exposure of training data\" will be comunicated.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.8.4) - Incident Communication Plan - Model Misuse",
                "FieldLabel": "Model Misuse",
                "FieldText": "Describe how incidents related to \"AI model used outside intended scope\" will be comunicated.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.8.4) - Incident Communication Plan - Model Failure",
                "FieldLabel": "Model Failure",
                "FieldText": "Describe how incidents related to \"False predictions causing harm\" will be comunicated.",
                "FieldType": "TextBox"
            }
        ]
    },
    "(A.8.5) Information for interested parties": {
        "WebFormTitle": "Establish a process to manage all stakeholder relationships, ensuring that responsibilities are clearly allocated, supplier activities align with internal AI policies, and customer needs are fully considered.",
        "Fields": [
            {
                "FieldName": "(A.8.5, A.8.3) - Interested parties Names",
                "FieldLabel": "Interested parties Names",
                "FieldText": "List the Interested parties who receive reporting information about the AI system.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.8.5, A.8.3) - Interested parties Primary Point of Contact",
                "FieldLabel": "Primary Point of Contact",
                "FieldText": "List the Interested parties Primary Point of Contact [Name, Title, Email]",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.8.5, A.8.3) - Interested parties General Description of Involvement",
                "FieldLabel": "General Description of Involvement",
                "FieldText": "Briefly describe the reporting obligation to the Interested parties.",
                "FieldType": "TextBox"
            }  
        ]
    },
    "(A.6.1.2) Objectives for Responsible and Ethical Development of AI Systems": {
        "WebFormTitle": "Describe the Responsible and Ethical objectives to guide the development of AI systems",
        "Fields": [
            {
                "Control": "A.6.1.2 – Objectives for responsible development of AI system",
                "FieldName": "(A.6.1.2, A.6.2.3) - Human-Centric",
                "FieldLabel": "Human-Centric",
                "FieldText": "To design the AI system to support, assist, and augment human capabilities and decision-making processes, prioritizing human well-being and agency.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.1.2 – Objectives for responsible development of AI system",
                "FieldName": "(A.6.1.2, A.6.2.3) - Transparency and Explainability",
                "FieldLabel": "Transparency & Explainability",
                "FieldText": "To ensure the AI system provides clear, understandable information about its purpose, processes, and decisions to all relevant stakeholders.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.1.2 – Objectives for responsible development of AI system",
                "FieldName": "(A.6.1.2, A.6.2.3) - Human Oversight",
                "FieldLabel": "Human Oversight",
                "FieldText": "To implement meaningful human oversight mechanisms that allow for monitoring system performance, reviewing high-risk decisions, and intervening effectively when necessary.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.1.2 – Objectives for responsible development of AI system",
                "FieldName": "(A.6.1.2, A.6.2.3) - Fairness and Non-discrimination",
                "FieldLabel": "Fairness & Non-discrimination",
                "FieldText": "To identify, assess, and mitigate biases in data and models throughout the AI lifecycle to prevent discriminatory or unjust outcomes for individuals or groups.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.1.2 – Objectives for responsible development of AI system",
                "FieldName": "(A.6.1.2, A.6.2.3) - Accountability",
                "FieldLabel": "Accountability",
                "FieldText": "To establish a clear governance structure with defined roles and responsibilities for the AI system's outcomes, including accessible mechanisms for redress and remediation.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.1.2 – Objectives for responsible development of AI system",
                "FieldName": "(A.6.1.2, A.6.2.3) - Safety and Robustness",
                "FieldLabel": "Safety & Robustness",
                "FieldText": "To ensure the AI system is resilient, operates reliably and safely under a variety of conditions, and minimizes the risk of unintended harm or failure.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.1.2 – Objectives for responsible development of AI system",
                "FieldName": "(A.6.1.2, A.6.2.3) - Security",
                "FieldLabel": "Security",
                "FieldText": "To implement comprehensive security measures to protect the AI system, its models, and its data from unauthorized access, manipulation, and adversarial attacks.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.1.2 – Objectives for responsible development of AI system",
                "FieldName": "(A.6.1.2, A.6.2.3) - Privacy",
                "FieldLabel": "Privacy",
                "FieldText": "To incorporate privacy-preserving techniques into the AI system's design to protect personal data throughout its lifecycle and ensure compliance with data protection regulations.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.1.2 – Objectives for responsible development of AI system",
                "FieldName": "(A.6.1.2, A.6.2.3) - Sustainability",
                "FieldLabel": "Sustainability",
                "FieldText": "To measure and minimize the environmental impact of the AI system by optimizing computational resources and energy consumption during its training and operation.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            }              
        ]
    },
    "(A.6.2.6, A.6.2.8) AI system recording of event logs and monitoring": {
        "WebFormTitle": "Define the events to be logged when the AI system is in use and how they will ensure the Responsible and Ethical use of AI systems.",
        "Fields": [
            {
                "FieldName": "(A.6.2.6, A.6.2.8) - Human-Centric",
                "FieldLabel": "Human-Centric",
                "FieldText": "Describe the event logging and monitoring in place during the AI system's use phase to track user interactions, system assists, and human overrides. Detail how these logs will be used to monitor the system's impact on human capabilities and decision-making.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "((A.6.2.6, A.6.2.8) - Transparency and Explainability",
                "FieldLabel": "Transparency",
                "FieldText": "Describe the event logging mechanisms implemented during the AI system's use phase to record inputs, outputs, and explanations generated. Explain how these logs will be monitored to verify the ongoing accuracy and completeness of the system's decisions.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.6.2.6, A.6.2.8) - Human Oversight",
                "FieldLabel": "Human Oversight",
                "FieldText": "Describe the event logging and monitoring processes established for the AI system's use phase to capture high-risk decisions. Detail how these logs will be used to support human reviews, approves, or intervenes in a high-risk decision.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.6.2.6, A.6.2.8) - Fairness and Non-Discrimination",
                "FieldLabel": "Fairness and Non-Discrimination",
                "FieldText": "Describe the event logging and performance monitoring procedures in place during the AI system's use phase to assess fairness. Detail how system outputs are logged against key demographic subgroups to continuously monitor for and address potential biases.",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "(A.6.2.6, A.6.2.8) - Accuracy, Robustness, and Cybersecurity",
                "FieldLabel": "EU AI Act Art 15 - Accuracy, Robustness, and Cybersecurity",
                "FieldText": "Describe the event logging and monitoring strategy for the AI system's use phase. Detail what specific events will be recorded to monitor technical performance, accuracy drift, system uptime, security events (e.g., potential adversarial inputs), and overall operational robustness.",
                "FieldType": "TextBox"
            }            
        ]
    },
    "AI Systems development objective and roles": {
        "WebFormTitle": "Define Objective and roles for Development",
        "Fields": [
            {
                "FieldName": "Development Roles",
                "FieldLabel": "xxx",
                "FieldText": "Development roles: ???",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "Development objectives",
                "FieldLabel": "xxx",
                "FieldText": "Development objectives: ???",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "Development measures",
                "FieldLabel": "xxx",
                "FieldText": "Development measures: ???",
                "FieldType": "TextBox"
            }
        ]
    },
    "(A.6.2.4) AI Systems verifications": {
        "WebFormTitle": "Document verification and validation measures for the AI system and specify criteria for their use.",
        "Fields": [
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Performance and Fairness Monitoring V&V",
                "FieldLabel": "Performance Monitoring Verification",
                "FieldText": "Verify the implementation of monitoring tools and dashboards. Test the system's ability to detect simulated performance degradation (e.g., accuracy drop >5%) and fairness metric violations (e.g., disparate impact ratio <0.8). Confirm that automated alerts are configured and successfully trigger notifications to the designated personnel.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Human Oversight V&V",
                "FieldLabel": "Human Oversight Validation",
                "FieldText": "Review and approve the documented human oversight procedures. Validate that the user interface provides the necessary information and controls for a human to intervene, override, or stop the system's process. Conduct user acceptance testing (UAT) with designated overseers to confirm they can effectively perform their roles.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Adherence to Intended Use V&V",
                "FieldLabel": "Intended Use Adherence Verification",
                "FieldText": "Verify that the 'Intended Use' documentation is clear, complete, and accessible to all users. Test any implemented technical controls (e.g., access restrictions, input validation) designed to prevent use outside the defined scope. Confirm user training materials explicitly cover approved use cases and limitations.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Incident Management V&V",
                "FieldLabel": "Incident Management Validation",
                "FieldText": "Verify that an AI-specific incident management plan exists. Conduct a tabletop exercise or simulation of a critical AI failure (e.g., major bias detection, system outage). Validate that reporting channels, escalation paths, and response roles function as documented and meet defined SLAs.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Operational Transparency V&V",
                "FieldLabel": "Operational Transparency Validation",
                "FieldText": "Validate that all user interfaces clearly disclose that an AI system is in use. Review system-generated notifications and explanations for clarity, accuracy, and completeness. Verify that mechanisms for users to access more detailed information or provide feedback are implemented as specified in the requirements.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - Data Management V&V",
                "FieldLabel": "Operational Data Management Verification",
                "FieldText": "Verify that data handling processes align with the Data Privacy Impact Assessment (DPIA). Conduct penetration testing and vulnerability scans on data storage and transmission channels. Validate that data minimization techniques (e.g., anonymization) are correctly implemented and that data retention policies are automatically enforced.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            },
            {
                "Control": "A.6.2.4 – AI system verification and validation",
                "FieldName": "(6.2.4) - System Maintenance V&V",
                "FieldLabel": "System Maintenance Plan Verification",
                "FieldText": "Verify the existence of a comprehensive system maintenance plan, including schedules for performance reviews and security patching. Validate the documented procedure for model retraining and redeployment. Review and approve the decommissioning plan to ensure it addresses data archival/deletion and stakeholder communication.",
                "FieldType": "Option box with values:Applicable/Not Applicable"
            }
        ]
    },
    "AI Systems use objective and roles": {
        "WebFormTitle": "Define Objective and roles for Use",
        "Fields": [
            {
                "FieldName": "Usage roles",
                "FieldLabel": "xxx",
                "FieldText": "Usage roles: ???",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "Usage objectives",
                "FieldLabel": "xxx",
                "FieldText": "Usage objectives: ???",
                "FieldType": "TextBox"
            }, 
            {
                "FieldName": "Usage measures",
                "FieldLabel": "xxx",
                "FieldText": "Usage measures: ???",
                "FieldType": "TextBox"
            }
        ]
    },
    "AI Systems approvals": {
        "WebFormTitle": "Document AI system approvals",
        "Fields": [
            {
                "FieldName": "AI System Security Approver",
                "FieldLabel": "Security Approver",
                "FieldText": "Name/Role of the Security Aprover",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "AI System Security Approval",
                "FieldLabel": "Security Approved",
                "FieldText": "",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "AI System DPO Approver",
                "FieldLabel": "DPO Approver",
                "FieldText": "Name/Role of the DPO Aprover",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "AI System DPO Approval",
                "FieldLabel": "DPO Approved",
                "FieldText": "",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "AI System Risk Approver",
                "FieldLabel": "Risk Approver",
                "FieldText": "Name/Role of the Risk Aprover",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "AI System Risk Approval",
                "FieldLabel": "Risk Approved",
                "FieldText": "",
                "FieldType": "Option box with values:Yes/No"
            },
            {
                "FieldName": "AI System Business Approver",
                "FieldLabel": "Business Approver",
                "FieldText": "Name/Role of the Business Approver",
                "FieldType": "TextBox"
            },
            {
                "FieldName": "AI System Business Approval",
                "FieldLabel": "Business Approved",
                "FieldText": "",
                "FieldType": "Option box with values:Yes/No"
            }
        ]
    }
}
