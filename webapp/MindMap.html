<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>AI Compliance Mind Map - Fixed</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <style>
        body { font-family: 'Segoe UI', sans-serif; background: #f8fafc; margin: 0; overflow: hidden; }
        #controls { position: absolute; top: 20px; left: 20px; z-index: 10; background: white; padding: 15px; border-radius: 8px; box-shadow: 0 4px 6px -1px rgba(0,0,0,0.1); border: 1px solid #e2e8f0; max-width: 260px; }
        .node circle { cursor: pointer; stroke-width: 2.5px; }
        .node text { font-size: 11px; pointer-events: none; fill: #334155; }
        .link { fill: none; stroke: #cbd5e1; stroke-width: 1.5px; }
        
        /* Compliance Styles */
        .node-regulation circle { fill: #dbeafe; stroke: #1e40af; }
        .node-requirement circle { fill: #fef08a; stroke: #a16207; }
        .node-risk circle { fill: #fee2e2; stroke: #b91c1c; }
        .node-plan circle { fill: #dcfce7; stroke: #15803d; }
        .node-control circle { fill: #f1f5f9; stroke: #475569; }

        .tooltip { position: absolute; padding: 10px; background: #1e293b; color: white; border-radius: 6px; font-size: 12px; pointer-events: none; max-width: 300px; z-index: 20; box-shadow: 0 10px 15px -3px rgba(0,0,0,0.2); line-height: 1.4; }
        .legend-item { display: flex; align-items: center; font-size: 11px; margin-bottom: 5px; }
        .legend-color { width: 10px; height: 10px; border-radius: 50%; margin-right: 8px; border: 1px solid #333; }
    </style>
</head>
<body>

<div id="controls">
    <h3 style="margin:0 0 10px 0; font-size:14px; color:#1e40af;">AI Act Gap Analyzer</h3>
    <div class="legend">
        <div class="legend-item"><div class="legend-color" style="background:#dbeafe"></div> Field Group</div>
        <div class="legend-item"><div class="legend-color" style="background:#fef08a"></div> Requirement</div>
        <div class="legend-item"><div class="legend-color" style="background:#fee2e2"></div> Risk</div>
        <div class="legend-item"><div class="legend-color" style="background:#dcfce7"></div> Test Plan</div>
        <div class="legend-item"><div class="legend-color" style="background:#f1f5f9"></div> Tech Control</div>
    </div>
    <p style="font-size: 10px; color: #64748b; margin-top: 10px;">• Click nodes to toggle<br>• Drag to pan<br>• Scroll to zoom</p>
</div>

<div id="mindmap"></div>

<script>
// --- YOUR DATA EMBEDDED ---
const rawData = {
{
  "1. Compliance Requirements": [
    {
      "StepName": "Article 13: Transparency and Provision of Information to Deployers",
      "Objectives": [
        {
          "Objective": "Defining the precise scope of the AI system, including what it is designed to do (its intended use) and establishing clear, documented boundaries for what it should not be used for (its known limitations)."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Transparency",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18229-1.1]",
              "jkName": "Intended Purpose",
              "jkText": "Clear, documented declaration of what the system is designed to do.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-1.2]",
              "jkName": "Limitations",
              "jkText": "Documentation of known 'blind spots', error conditions, or scenarios where the AI may fail.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-1.3]",
              "jkName": "Instructions for Use",
              "jkText": "High-quality documentation that is clear, accessible, and provided in a digital/readable format.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Logging",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18229-1.4]",
              "jkName": "Event Recording",
              "jkText": "Automated, immutable recording of start/end times, input data, and all system decisions.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-1.5]",
              "jkName": "Traceability",
              "jkText": "Ensuring logs allow for the full 'reconstruction' of events if a failure or accident occurs.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        }
      ]
    },
    {
      "StepName": "Article 14: Human Oversight",
      "Objectives": [
        {
          "Objective": "Defining the precise scope of the AI system, including what it is designed to do (its intended use) and establishing clear, documented boundaries for what it should not be used for (its known limitations)."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Human Oversight",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18229-1.6]",
              "jkName": "Automation Bias Prevention",
              "jkText": "UI design that explicitly warns humans not to over-rely on AI suggestions.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-1.7]",
              "jkName": "Intervention Tools",
              "jkText": "Inclusion of technical 'Override' or 'Stop' mechanisms (the 'Kill Switch').",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-1.8]",
              "jkName": "Interpretability",
              "jkText": "Ensuring outputs provide sufficient context for a human to understand the 'why' behind a decision.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        }
      ]
    },
    {
      "StepName": "Article 15: Accuracy, Robustness and Cybersecurity",
      "Objectives": [
        {
          "Objective": "Defining the precise scope of the AI system, including what it is designed to do (its intended use) and establishing clear, documented boundaries for what it should not be used for (its known limitations)."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Threat Mitigation",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18282.1]",
              "jkName": "Adversarial Attacks",
              "jkText": "Defense against 'evasion attacks' where crafted input data is designed to fool the model's logic.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18282.2]",
              "jkName": "Data Poisoning",
              "jkText": "Protecting the training and RAG ingestion pipelines so malicious data doesn't corrupt the knowledge base.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18282.3]",
              "jkName": "Model Inversion",
              "jkText": "Preventing 'extraction' attacks where unauthorized parties try to 'steal' the model or training data via API queries.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "System Integrity",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18282.4]",
              "jkName": "Secure Development",
              "jkText": "Procedures ensuring the code, RAG orchestrator, and model are built in a hardened, isolated environment.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18282.5]",
              "jkName": "Supply Chain Security",
              "jkText": "Verifying the security and integrity of third-party libraries, pre-trained models, and external data sources.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Infrastructure",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18282.6]",
              "jkName": "Access Control",
              "jkText": "Standard identity management (RBAC/MFA) for who can modify model weights or access proprietary data.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18282.7]",
              "jkName": "Model Robustness",
              "jkText": "Ensuring the system remains secure and stable even when encountering 'noise' or unexpected data patterns.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Defense-in-Depth",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18282.8]",
              "jkName": "Anomaly Detection",
              "jkText": "Continuous monitoring of AI inputs and outputs for signs of a cyberattack, such as prompt injection.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Metric Requirements",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18229-2.9]",
              "jkName": "Metric Selection",
              "jkText": "Selecting the appropriate 'yardstick' (e.g., F1-score for classification or Mean Absolute Error for regression) for the specific use case.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-2.10]",
              "jkName": "Validation",
              "jkText": "Rigorous testing to prove accuracy scores are not 'overfitted' to training data and remain valid on unseen data.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-2.11]",
              "jkName": "Declaration",
              "jkText": "Explicitly stating the achieved accuracy levels and metrics within the formal Instructions for Use.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Lifecycle Performance",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18229-2.12]",
              "jkName": "Consistency",
              "jkText": "Continuous monitoring to detect if accuracy 'drifts' or degrades after the system is in production.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-2.13]",
              "jkName": "Benchmarking",
              "jkText": "Comparing AI performance against human expert benchmarks or recognized industry standards.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Technical Documentation",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18229-2.14]",
              "jkName": "Verification Methods",
              "jkText": "Detailed documentation of the training/testing data split and the statistical methods used to verify results.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Resilience Factors",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18229-3.15]",
              "jkName": "Input Noise",
              "jkText": "Ensuring the AI can handle corrupted inputs (e.g., typos, sensor errors, or blurry data) without crashing.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-3.16]",
              "jkName": "Environment Changes",
              "jkText": "Maintaining system functionality during external shifts, such as poor lighting or network latency.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-3.17]",
              "jkName": "Feedback Loops",
              "jkText": "Implementing technical barriers to prevent the AI from learning from its own biased or incorrect outputs over time.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Fail-Safe Mechanisms",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18229-3.18]",
              "jkName": "Graceful Degradation",
              "jkText": "Designing the system to fail safely (e.g., a 'safe state' or limited functionality mode) rather than an abrupt collapse.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18229-3.19]",
              "jkName": "Technical Redundancy",
              "jkText": "Utilizing backup modules or 'sanity check' algorithms to catch and mitigate AI errors in real-time.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Reproducibility",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18229-3.20]",
              "jkName": "Output Reliability",
              "jkText": "Ensuring the AI produces consistent, non-random outputs when given the exact same inputs.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        }
      ]
    },
    {
      "StepName": "Article 10: Data and Data Governance",
      "Objectives": [
        {
          "Objective": "Defining the precise scope of the AI system, including what it is designed to do (its intended use) and establishing clear, documented boundaries for what it should not be used for (its known limitations)."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Governance Practices",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18284.1]",
              "jkName": "Design Choices",
              "jkText": "Documenting the rationale behind data selection, including intended purpose and suitability assessments.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18284.2]",
              "jkName": "Data Origin",
              "jkText": "Tracking the source and legal basis (provenance) of data collection and preparation.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18284.3]",
              "jkName": "Data Preparation Operations",
              "jkText": "Standardizing processes for annotation, labeling, cleaning, enrichment, and aggregation.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Quality Metrics",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18284.4]",
              "jkName": "Representativeness",
              "jkText": "Statistical proof (e.g., distribution analysis) that data reflects specific geographical, contextual, and behavioral settings.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18284.5]",
              "jkName": "Completeness",
              "jkText": "Identifying and addressing 'data gaps' or missing information that could prevent regulatory compliance.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18284.6]",
              "jkName": "Accuracy / Correctness",
              "jkText": "Implementing methods to detect and mitigate errors in labels and noise in the raw data.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Lifecycle Requirements",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18284.7]",
              "jkName": "Dataset Splitting",
              "jkText": "Establishing strict rules for training, validation, and testing splits to ensure unbiased performance evaluation.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18284.8]",
              "jkName": "Data Retention",
              "jkText": "Policies for storage duration (typically 10 years for documentation) and secure decommissioning mechanisms.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Assumptions",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18284.9]",
              "jkName": "Formulation",
              "jkText": "Explicit documentation of what the data is intended to measure and represent (e.g., 'past history as a predictor').",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Bias Detection",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18283.1]",
              "jkName": "Representativeness",
              "jkText": "Ensuring training, validation, and testing datasets proportionally cover all relevant subgroups (e.g., age, gender, ethnicity) to prevent under-representation bias.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18283.2]",
              "jkName": "Bias Metrics",
              "jkText": "Applying specific mathematical tests, such as Disparate Impact or Equalized Odds, to provide a quantitative proof that the model does not favor one group over another.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18283.3]",
              "jkName": "Proxy Identification",
              "jkText": "Identifying and analyzing 'hidden' variables (e.g., zip codes) that correlate with protected traits to prevent indirect discrimination.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Human & Social Context",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18283.7]",
              "jkName": "Multi-stakeholder Input",
              "jkText": "Engaging diverse teams to define 'fairness' for specific use cases, ensuring the system respects different societal and functional settings.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18283.8]",
              "jkName": "Fundamental Rights",
              "jkText": "Directly linking bias mitigation measures to the protection of fundamental rights and the prevention of discrimination prohibited under Union law.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        }
      ]
    },
    {
      "StepName": "Article 12: Record-Keeping",
      "Objectives": [
        {
          "Objective": "Defining the precise scope of the AI system, including what it is designed to do (its intended use) and establishing clear, documented boundaries for what it should not be used for (its known limitations)."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Logging Triggers",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[24970.1]",
              "jkName": "Routine Operation",
              "jkText": "Automated recording of standard system activity, including precise start/end timestamps and user usage sessions.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[24970.2]",
              "jkName": "Monitoring Events",
              "jkText": "Capturing automated performance benchmarks, safety checks, and anomalies triggered by the system's internal observability tools.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[24970.3]",
              "jkName": "Human Intervention",
              "jkText": "Recording every instance of a user overriding, editing, or stopping an AI output, directly linking to Article 14 oversight duties.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Captured Information",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[24970.4]",
              "jkName": "System State",
              "jkText": "Snapshots of current model parameters, version IDs, and configuration hashes at the exact time a decision or output was generated.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[24970.5]",
              "jkName": "Input/Output Data",
              "jkText": "Recording the specific user prompts and retrieved knowledge chunks that led to a high-risk or decision-making output.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[24970.6]",
              "jkName": "Errors & Failures",
              "jkText": "Detailed diagnostic data including error codes, messages, severity levels, and the fallback mechanisms activated during a crash.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Storage & Governance",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[24970.7]",
              "jkName": "Tamper Resistance",
              "jkText": "Using technical controls like Write-Once-Read-Many (WORM) storage or cryptographic hashes to ensure logs cannot be altered after creation.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[24970.8]",
              "jkName": "Retention Periods",
              "jkText": "Maintaining logs for at least 6 months (per Article 26(6)) or longer as mandated by sector-specific EU or national laws.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[24970.9]",
              "jkName": "Privacy",
              "jkText": "Balancing full traceability with GDPR requirements through data minimization, such as anonymizing user IDs where appropriate.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        }
      ]
    },
    {
      "StepName": "Article 43: Conformity Assessment3",
      "Objectives": [
        {
          "Objective": "Defining the precise scope of the AI system, including what it is designed to do (its intended use) and establishing clear, documented boundaries for what it should not be used for (its known limitations)."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Assessment Paths",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18285.1]",
              "jkName": "Internal Control (Annex VI)",
              "jkText": "Allows providers of many high-risk systems (e.g., education, employment) to self-assess compliance if they strictly follow harmonized standards.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18285.2]",
              "jkName": "Third-Party Assessment (Annex VII)",
              "jkText": "Mandates an audit by a 'Notified Body' for critical systems (e.g., biometrics) or cases where harmonized standards were not fully applied.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Mapping to Lifecycle",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18285.3]",
              "jkName": "Design Phase",
              "jkText": "Formal review of the Risk Management System to ensure safety was engineered into the initial concept (prEN 18228).",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18285.4]",
              "jkName": "Development Phase",
              "jkText": "Technical audit of Data Governance and quality metrics to ensure the model's foundation is sound (prEN 18284).",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18285.5]",
              "jkName": "Post-Market Phase",
              "jkText": "Verification that the automated Monitoring and Logging systems are functioning in the live environment (prEN ISO/IEC 24970).",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Auditor Requirements",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18285.6]",
              "jkName": "Competence",
              "jkText": "Defines the specific technical expertise required for auditors, including understanding neural networks, bias detection, and AI-specific risks.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18285.7]",
              "jkName": "Independence",
              "jkText": "Establishes strict rules to ensure auditors remain impartial and free from any conflict of interest with the AI provider.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        }
      ]
    },
    {
      "StepName": "Article 17: Quality Management System",
      "Objectives": [
        {
          "Objective": "Defining the precise scope of the AI system, including what it is designed to do (its intended use) and establishing clear, documented boundaries for what it should not be used for (its known limitations)."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Organizational Strategy",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18286.1]",
              "jkName": "Compliance Strategy",
              "jkText": "A formal plan for how the organization will maintain conformity (including modifications to the AI).",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18286.2]",
              "jkName": "Accountability Framework",
              "jkText": "Defining clear roles and management responsibilities for AI safety.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Operational Controls",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18286.3]",
              "jkName": "Design & Development",
              "jkText": "Procedures for design control, verification, and validation.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18286.4]",
              "jkName": "Resource Management",
              "jkText": "Ensuring the right human and technical resources (e.g., compute power, specialized staff) are available.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Post-Launch Duties",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18286.5]",
              "jkName": "Post-Market Monitoring (PMM)",
              "jkText": "A system to collect and analyze data on the AI's performance once it is in the hands of users.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18286.6]",
              "jkName": "Incident Reporting",
              "jkText": "Procedures for reporting 'serious incidents' to national authorities within strict timelines.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Documentation & Records",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18286.7]",
              "jkName": "Technical Documentation",
              "jkText": "Maintaining the 'Technical File' required by Article 11.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18286.8]",
              "jkName": "Record-Keeping",
              "jkText": "Systems for storing logs and version-controlled documentation for at least 10 years.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        }
      ]
    },
    {
      "StepName": "Article 9: Risk Management System",
      "Objectives": [
        {
          "Objective": "Establishing, implementing, and maintaining a continuous iterative process throughout the entire lifecycle of a high-risk AI system to identify, estimate, and evaluate known and foreseeable risks, and to implement systematic mitigation measures."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Key Risk Iterations",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18228-1]",
              "jkName": "Identification",
              "jkText": "Identification and analysis of known and reasonably foreseeable risks the AI system may pose to health, safety, or fundamental rights.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18228-2]",
              "jkName": "Estimation",
              "jkText": "Estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18228-3]",
              "jkName": "Evaluation",
              "jkText": "Evaluation of other emerging risks based on the analysis of data gathered from the post-market monitoring system.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Mitigation Hierarchy",
          "Role": "Compliance",
          "controls": [
            {
              "requirement_control_number": "[18228-4]",
              "jkName": "1. Elimination",
              "jkText": "Elimination or reduction of risks as far as possible through adequate design and development.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18228-5]",
              "jkName": "2. Mitigation",
              "jkText": "Implementation of appropriate mitigation and control measures in relation to risks that cannot be eliminated.",
              "jkType": "requirement",
              "jkSoa": "Select"
            },
            {
              "requirement_control_number": "[18228-6]",
              "jkName": "3. Information",
              "jkText": "Provision of adequate information to deployers and, where appropriate, to persons likely to be affected by the system.",
              "jkType": "requirement",
              "jkSoa": "Select"
            }
          ]
        }
      ]
    }
  ],
  "2. Define": [
    {
      "StepName": "new - 1.1. EU AI Act: Prohibited AI Practices Assessment",
      "Objectives": [
        {
          "Objective": "A mandatory screening to ensure the AI system does not fall into the category of 'Prohibited AI Practices' as defined by the EU AI Act (e.g., systems that manipulate behavior or exploit vulnerabilities)."
        }
      ],
      "Fields": [
        {
          "Role": "Requester",
          "requirement_control_number": "[18283.8]",
          "control_number": "[1.1.1]",
          "jkName": "Will the AI system be used for any of the following prohibited purposes?",
          "jkText": "The EU AI Act strictly prohibits certain AI practices that pose an unacceptable risk. If any of the following options are selected, the AI system is considered prohibited and cannot be deployed.",
          "jkType": "MultiSelect:Manipulating human behavior to cause physical or psychological harm/Exploiting vulnerabilities of specific groups (e.g., age, disability) to cause harm/General-purpose social scoring by public authorities/Real-time remote biometric identification in public spaces for law enforcement (outside of strictly defined exceptions)/None"
        }
      ]
    },
    {
      "StepName": "new - 1.2. EU AI Act: Role Classification (Provider vs. Deployer)",
      "Objectives": [
        {
          "Objective": "Defining the organization’s legal responsibility for the AI system. This step determines whether the entity is acting as the Provider (the developer/manufacturer) or the Deployer (the user/operator) of the system, which dictates the scope of subsequent obligations."
        }
      ],
      "Fields": [
        {
          "Role": "Requester",
          "requirement_control_number": "[18228-1]",
          "control_number": "[1.2.1]",
          "jkName": "Which description best defines your organization's role and activities for this AI system?",
          "jkText": "It's very important to clearly define the organisation's activities because it will impact the AI Act’s distinction between 'Provider' (developer) and 'Deployer' (user), which comes with significantly different responsibilities. The organisation's activities are exclusively focused on operationalizing, integrating, and governing generic pre-trained LLMs and developing internal infrastructure for Retrieval-Augmented Generation (RAG), without any modification, fine-tuning, or retraining of the underlying model itself. The AI system is for internal organizational use only, and is not repackaged or distributed to external customers. The LLM is chosen as a generic, pre-trained model, stored on-premises, and never fine-tuned, retrained, Its parameters, weights, or architecture layers are not modified by the organisation's internal engineering team. Meaning it does not interact with or access any external internet datasets, ensuring data sovereignty and minimizing exposure to third-party risks. The organisation's internal engineering team’s efforts are strictly limited to building infrastructure, orchestration, and internal data pipelines for the LLM, but do not alter the core LLM architecture or its parameters.",
          "jkType": "MultiSelect:[Deployer - Internal Build] We are a Deployer. Our activities match the description: we use a generic model for internal use only AND our development is limited to building orchestration (RAG) without modifying the core model./[Provider] We are a Provider. We are substantially modifying the core AI model (e.g., fine-tuning, retraining) OR we are distributing this system to external customers."
        }
      ]
    },
    {
      "StepName": "New - 1.3. EU AI Act: High-Risk System Classification",
      "Objectives": [
        {
          "Objective": "A critical step involving the legal classification of the AI system to determine if it meets the criteria for a High-Risk AI System. This classification triggers a significantly higher level of scrutiny and more detailed compliance requirements."
        }
      ],
      "Fields": [
        {
          "Role": "Requester",
          "requirement_control_number": "[18228-3]",
          "control_number": "[1.3.1]",
          "jkName": "Will the AI system be used for any of the following purposes?",
          "jkText": "Under the EU AI Act, a system is classified as high-risk if its intended use falls into specific categories. Please select all that apply. If any option is selected, the AI system will be classified as high-risk.",
          "jkType": "MultiSelect:As a safety component in a regulated product (e.g., medical devices, cars, toys)/Biometric identification or categorisation of people/Management of critical infrastructure (e.g., water, gas, electricity)/Determining access to education or scoring exams/Recruitment, promotion, or employee performance management/Assessing creditworthiness or eligibility for public benefits/Law enforcement purposes (e.g., risk assessment, evidence evaluation)/Migration, asylum, and border control management/Assisting judicial authorities in legal proceedings/None"
        },
        {
          "Role": "Requester",
          "requirement_control_number": "[18228-3]",
          "control_number": "[1.3.2]",
          "jkName": "Does the AI system have specific transparency obligations (Limited Risk)?",
          "jkText": "If the system is not high-risk, it may still be 'Limited Risk' and have specific transparency obligations to ensure users are not deceived. Please select all that apply.",
          "jkType": "MultiSelect:Interacts directly with humans (e.g., a chatbot) and must disclose it is an AI/Generates 'deep fakes' or manipulates video, audio, image content/Used for emotion recognition or biometric categorization/Generates synthetic text published on matters of public interest/None"
        }
      ]
    },
    {
      "StepName": "New - 2.1. - AI system's intended use and limitations",
      "Objectives": [
        {
          "Objective": "Defining the precise scope of the AI system, including what it is designed to do (its intended use) and establishing clear, documented boundaries for what it should not be used for (its known limitations)."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Transparency Details",
          "Role": "Requester",
          "controls": [
            {
              "requirement_control_number": "[18229-1.1]",
              "control_number": "[2.2.1]",
              "jkName": "Documented Intended Purpose",
              "jkText": "Provide a formal declaration of the AI system's intended purpose, including the specific context and population it is designed for.",
              "jkType": "TextBox",
              "jkObjective": "To ensure transparency regarding the system's operational boundaries and target audience to prevent misuse."
            },
            {
              "requirement_control_number": "[18229-1.2]",
              "control_number": "[2.2.2]",
              "jkName": "Technical Limitations and Blind Spots",
              "jkText": "Identify known scenarios where the AI may fail, produce errors, or provide unreliable outputs (e.g., specific data gaps or environmental constraints).",
              "jkType": "TextBox",
              "jkObjective": "To minimize risk by proactively informing users of the system's technical constraints and potential failure points."
            },
            {
              "requirement_control_number": "[18229-1.2]",
              "control_number": "[2.2.3]",
              "jkName": "Failure Mode Mitigation",
              "jkText": "Briefly describe how the user should handle or identify these 'blind spots' when they occur.",
              "jkType": "TextBox",
              "jkObjective": "To provide users with actionable guidance for identifying and managing AI errors or unreliable outputs."
            },
            {
              "requirement_control_number": "[18229-1.3]",
              "control_number": "[2.2.4]",
              "jkName": "Instructions for Use (IFU) Link",
              "jkText": "Provide a URL or document reference to the clear, accessible user manual or digital instructions for this system.",
              "jkType": "TextBox",
              "jkObjective": "To facilitate easy access to comprehensive operational guidance for safe and effective system use."
            },
            {
              "requirement_control_number": "[18229-1.3]",
              "control_number": "[2.2.5]",
              "jkName": "Documentation Format",
              "jkText": "Confirm the format of the provided instructions.",
              "jkType": "MultiSelect:Digital PDF/Interactive Help Guide/In-App Tooltips/Printed Manual/API Documentation",
              "jkObjective": "To verify that the documentation is delivered in an accessible and user-appropriate format."
            }
          ]
        }
      ]
    },
    {
      "StepName": "New - 2.3. - Fairness Definition",
      "Objectives": [
        {
          "Objective": "Evaluating the system's energy consumption and carbon footprint, particularly during the training and deployment phases. This step outlines strategies for optimizing model efficiency to reduce the AI system’s overall environmental impact."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Multi-stakeholder Fairness Definition",
          "Role": "Requester",
          "controls": [
            {
              "requirement_control_number": "[18283.7]",
              "control_number": "[2.3.1]",
              "jkName": "Stakeholder Group Representation",
              "jkText": "Select the diverse teams or groups involved in defining the fairness criteria for this use case.",
              "jkType": "MultiSelect:Legal and Compliance/DEI Office/End-Users/Data Science Team/External Ethics Board/Representative Community Groups/Subject Matter Experts",
              "jkObjective": "To ensure a multi-disciplinary and inclusive approach to defining fairness, incorporating diverse perspectives and legal requirements."
            },
            {
              "requirement_control_number": "[18283.7]",
              "control_number": "[2.3.2]",
              "jkName": "Definition of Fairness",
              "jkText": "Summarize the agreed-upon definition of 'fairness' for this specific system (e.g., equal opportunity, demographic parity, or individual fairness).",
              "jkType": "TextBox",
              "jkObjective": "To establish a clear, measurable benchmark for fairness that aligns with the specific goals and risks of the AI system."
            },
            {
              "requirement_control_number": "[18283.7]",
              "control_number": "[2.3.3]",
              "jkName": "Societal and Functional Context",
              "jkText": "Describe how the fairness definition accounts for the specific societal setting where the AI will be deployed (e.g., cultural nuances, vulnerable populations).",
              "jkType": "TextBox",
              "jkObjective": "To contextualize fairness within the actual deployment environment, ensuring protections for vulnerable groups and adherence to local cultural standards."
            },
            {
              "requirement_control_number": "[18283.7]",
              "control_number": "[2.3.4]",
              "jkName": "Engagement Methodology",
              "jkText": "How was the input gathered from these stakeholders?",
              "jkType": "MultiSelect:Workshops/Surveys/Focus Groups/Formal Oversight Committee/Public Consultation",
              "jkObjective": "To validate the robustness and transparency of the stakeholder engagement process used to determine ethical criteria."
            }
          ]
        }
      ]
    },
    {
      "StepName": "New - 2.3. - Data Governance and Verification",
      "Objectives": [
        {
          "Objective": "Evaluating the system's energy consumption and carbon footprint, particularly during the training and deployment phases. This step outlines strategies for optimizing model efficiency to reduce the AI system’s overall environmental impact."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Data Governance and Verification",
          "Role": "Data Engineer",
          "controls": [
            {
              "requirement_control_number": "[18229-2.14]",
              "control_number": "[2.4.1]",
              "jkName": "Data Split Strategy",
              "jkText": "Specify the ratio of data used for Training, Validation, and Testing (e.g., 70/15/15) and the method used (e.g., Random, Stratified, Temporal).",
              "jkType": "TextBox",
              "jkObjective": "To ensure the model is evaluated on unseen data to prevent overfitting and provide a realistic estimate of real-world performance."
            },
            {
              "requirement_control_number": "[18229-2.14]",
              "control_number": "[2.4.2]",
              "jkName": "Statistical Verification Methods",
              "jkText": "List the statistical tests or metrics used to verify system results (e.g., F1 Score, RMSE, P-values, Confidence Intervals).",
              "jkType": "TextBox",
              "jkObjective": "To establish objective, mathematically sound criteria for assessing the accuracy and reliability of the AI system's outputs."
            },
            {
              "requirement_control_number": "[18284.1]",
              "control_number": "[2.4.3]",
              "jkName": "Data Selection Rationale",
              "jkText": "Explain why this specific dataset was chosen and how its features align with the AI's intended purpose.",
              "jkType": "TextBox",
              "jkObjective": "To justify that the underlying data is relevant and representative of the problem the AI is designed to solve."
            },
            {
              "requirement_control_number": "[18284.2]",
              "control_number": "[2.4.4]",
              "jkName": "Data Provenance and Legal Basis",
              "jkText": "Identify the original source of the data and the legal justification for its use (e.g., Consent, Legitimate Interest, Public Domain).",
              "jkType": "TextBox",
              "jkObjective": "To ensure data privacy compliance and establish a clear lineage of data ownership and usage rights."
            },
            {
              "requirement_control_number": "[18284.3]",
              "control_number": "[2.4.5]",
              "jkName": "Preparation Operations Log",
              "jkText": "Select the operations performed during data preparation.",
              "jkType": "MultiSelect:Anonymization/Labeling and Annotation/Outlier Removal/Data Enrichment/Standardization and Normalization/Aggregation",
              "jkObjective": "To maintain transparency regarding how raw data was transformed and cleaned before being used for model development."
            },
            {
              "requirement_control_number": "[18284.3]",
              "control_number": "[2.4.6]",
              "jkName": "Annotation Quality Control",
              "jkText": "Describe the process used to ensure the accuracy of labels or annotations (e.g., Double-blind review, Inter-rater reliability checks).",
              "jkType": "TextBox",
              "jkObjective": "To verify the integrity of ground-truth labels, which directly impacts the supervised learning quality and model precision."
            }
          ]
        }
      ]
    },
    {
      "StepName": "New - 2.3. - Impact Assessments",
      "Objectives": [
        {
          "Objective": "Evaluating the system's energy consumption and carbon footprint, particularly during the training and deployment phases. This step outlines strategies for optimizing model efficiency to reduce the AI system’s overall environmental impact."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Fundamental Rights Impact Assessment",
          "Role": "Requester",
          "controls": [
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.1]",
              "jkName": "Select the at-risk group(s) impacted by the AI system",
              "jkText": "",
              "jkType": "MultiSelect:Children/Elderly/Persons with Disabilities/Economically Disadvantaged/Ethnic Minorities/None",
              "jkObjective": "To identify specific vulnerable populations that require heightened protection and targeted risk assessment."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.2]",
              "jkName": "Potential negative impacts on fundamental rights",
              "jkText": "Select specifically identified risks to the vulnerable population.",
              "jkType": "MultiSelect:Discrimination or Bias/Privacy Violation/Job Loss/None",
              "jkObjective": "To categorize potential harms to fundamental human rights to ensure appropriate mitigation strategies are developed."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.3]",
              "jkName": "Potential positive impacts on fundamental rights",
              "jkText": "Select expected benefits for the vulnerable population.",
              "jkType": "MultiSelect:Enhanced Accessibility/Improved Fairness/Increased Service Efficiency/None",
              "jkObjective": "To document the anticipated societal benefits and improvements in equity resulting from the AI implementation."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.4]",
              "jkName": "Rate the severity of identified negative impacts",
              "jkText": "",
              "jkType": "Dropdown box with values:/Low/Medium/High",
              "jkObjective": "To quantify the level of risk associated with identified negative impacts to prioritize governance efforts."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.5]",
              "jkName": "Describe the severity of identified impacts",
              "jkText": "Provide justification for the severity rating selected above.",
              "jkType": "TextBox",
              "jkObjective": "To provide a qualitative rationale and evidence base for the risk severity level assigned to the system."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.6]",
              "jkName": "Technical mechanisms implemented to mitigate negative impacts",
              "jkText": "MultiSelect:Bias Detection & Correction/Privacy-Enhancing Technologies (PETs)/Explainability Modules (XAI)/Human-in-the-Loop (HITL)/Robustness & Adversarial Training/Data Minimization/Automated Logging & Auditing",
              "jkType": "TextBox",
              "jkObjective": "To document the specific technical controls and safeguards deployed to neutralize or reduce identified risks."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.7]",
              "jkName": "Post-Deployment Monitoring Plan",
              "jkText": "Describe the plan for monitoring the AI system's performance and impact on vulnerable populations after deployment. Include key metrics and frequency of review.",
              "jkType": "TextBox",
              "jkObjective": "To establish an ongoing oversight mechanism that ensures the system remains safe and fair throughout its lifecycle."
            }
          ]
        },
        {
          "jkType": "fieldGroup",
          "jkName": "Workforce Transition and Adaptation for AI Integration",
          "Role": "Requester",
          "controls": [
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.8]",
              "jkName": "Select the job titles whose daily tasks may be altered by more than 20% due to the AI system",
              "jkText": "",
              "jkType": "MultiSelect:Employees/Customers/Analysts/Customer/Supplier/Partner/Regulator",
              "jkObjective": "To identify specific professional roles undergoing significant transformation to target support and transition resources effectively."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.9]",
              "jkName": "Identify the primary roles of the AI system relative to human workers",
              "jkText": "",
              "jkType": "MultiSelect:Augmentation (assisting human judgment)/Automation (replacing tasks)/Creation (enabling new tasks)",
              "jkObjective": "To define the nature of the human-AI interaction and determine whether the system is designed to support, replace, or expand human capabilities."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.10]",
              "jkName": "Automated/Eliminated Tasks",
              "jkText": "List the specific tasks that will be fully automated or eliminated for the affected roles, and the estimated percentage of work time saved across the department.",
              "jkType": "TextBox",
              "jkObjective": "To quantify the operational shift and identify the specific workflow components that will no longer require human intervention."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.11]",
              "jkName": "Primary Mitigation Strategy for Displacement",
              "jkText": "If job displacement is identified, select the primary strategies for the affected workers",
              "jkType": "MultiSelect:Internal Re-deployment/Transfer/Managed Attrition (No Backfill)/Voluntary Separation Package/External Layoff",
              "jkObjective": "To document the ethical and organizational approach to managing workforce reduction or transition resulting from AI implementation."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.12]",
              "jkName": "Structured Re-skilling Program in Place",
              "jkText": "Describe the primary strategies to address the affected workers.",
              "jkType": "TextBox",
              "jkObjective": "To ensure that a proactive educational framework exists to help employees adapt to new roles or technical requirements."
            },
            {
              "requirement_control_number": "[18283.8]",
              "control_number": "[2.3.13]",
              "jkName": "Structured Re-skilling Program Effectiveness",
              "jkText": "Describe the Training Effectiveness measures to evaluate the success of the primary strategies to address the affected workers.",
              "jkType": "TextBox",
              "jkObjective": "To establish qualitative and quantitative metrics that verify if the workforce transition and training efforts are achieving their intended goals."
            }
          ]
        }
      ]
    }
  ],
  "3. Build": [
    {
      "StepName": "3.1. - Internal Data Sources",
      "WebFormTitle": "To uphold the principles of data integrity, relevance, currency, and compliance by creating a governed process to identify, review, and approve all proprietary data sources designated for the AI's knowledge base.",
      "Objectives": [
        {
          "Objective": "To uphold the principles of data integrity, relevance, currency, and compliance by creating a governed process to identify, review, and approve all proprietary data sources designated for the AI's knowledge base."
        }
      ],
      "Fields": []
    },
    {
      "StepName": "New - 3.2. - Data Processing Pipeline (Vectorise proprietary data)",
      "WebFormTitle": "To uphold the integrity and trustworthiness of the AI's knowledge base by ensuring all source data is accurately extracted, thoroughly cleaned of irrelevant artifacts, and logically chunked for optimal processing.",
      "Objectives": [
        {
          "Objective": "To uphold the integrity and trustworthiness of the AI's knowledge base by ensuring all source data is accurately extracted, thoroughly cleaned of irrelevant artifacts, and logically chunked for optimal processing, often involving vectorization for retrieval-augmented generation (RAG) models."
        }
      ],
      "Fields": [
        {
          "jkType": "risk",
          "Role": "Engineer",
          "jkName": "Data Preparation Integrity Failure",
          "RiskDescription": "The risk that inconsistencies or errors during data preparation (annotation, cleaning, enrichment) introduce noise, bias, or structural flaws into the dataset. This includes 'Label Noise' (incorrect tags), 'Over-Cleaning' (stripping valuable context), or 'Enrichment Hallucination' (adding false metadata), all of which degrade the retrieval accuracy and factual reliability of the RAG system.",
          "controls": [
            {
              "requirement_control_number": "[18284.3]",
              "control_number": "[PREP-RISK-01]",
              "jkName": "Schema & Type Validation",
              "jkText": "Implement automated 'Schema Validation' and 'Data Type Enforcement' scripts immediately after any cleaning or enrichment step to ensure the output strictly matches the defined data model (e.g., checking that dates are valid ISO-8601 strings, not random text).",
              "jkType": "risk_control",
              "jkObjective": "To prevent structural corruption where cleaning scripts accidentally break the data format, causing downstream ingestion failures.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Logs from the ETL pipeline showing 'Schema Validation Passed' events for each batch; code snippets of the validation logic (e.g., Pydantic models or JSON Schema definitions)."
            },
            {
              "requirement_control_number": "[18284.3]",
              "control_number": "[PREP-RISK-02]",
              "jkName": "Golden Set/IRR Protocol",
              "jkText": "Establish a 'Golden Set' validation protocol for data labeling/annotation. A subset of the data (e.g., 10%) must be reviewed by a human expert or a consensus algorithm (e.g., majority vote among 3 labelers) to measure Inter-Rater Reliability (IRR).",
              "jkType": "risk_control",
              "jkObjective": "To detect and mitigate 'Label Noise' where subjective or erroneous tags mislead the vector retrieval engine.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "A 'Quality Report' generated for each annotation batch showing the calculated IRR score (e.g., Cohen's Kappa > 0.8) and the rejection rate of poor-quality labels."
            },
            {
              "requirement_control_number": "[18284.3]",
              "control_number": "[PREP-RISK-03]",
              "jkName": "Enrichment Confidence Threshold",
              "jkText": "When using automated enrichment (e.g., using an LLM to generate summaries or keywords for chunks), strictly enforce a 'Confidence Threshold'. Any generated metadata with a confidence score below the defined threshold must be discarded or flagged for manual review.",
              "jkType": "risk_control",
              "jkObjective": "To prevent 'Enrichment Hallucination' where the system indexes false metadata (e.g., tagging a document with the wrong topic), which would permanently corrupt search results.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Configuration settings showing the threshold value (e.g., probability > 0.85) and logs showing the discard rate of low-confidence enrichments."
            }
          ]
        },
        {
          "jkType": "risk",
          "Role": "Engineer",
          "jkName": "RAG Ingestion Poisoning (Vector Manipulation)",
          "RiskDescription": "The risk that malicious or low-quality data is processed through the .3.2 pipeline, leading to corrupted vector embeddings. This can result in 'Adversarial Retrieval,' where the AI retrieves poisoned chunks that seem mathematically relevant but contain false information or indirect prompt injections designed to hijack the model's output.",
          "controls": [
            {
              "requirement_control_number": "[18282.2]",
              "control_number": "[RAG-SEC-01]",
              "jkName": "Data Sanitization & Masking",
              "jkText": "Implement automated text sanitization and PII masking during the data processing pipeline before vectorization to strip hidden control characters or adversarial triggers.",
              "jkType": "risk_control",
              "jkObjective": "To prevent technical exploits and ensure only clean, authorized data is used to generate embeddings.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Code snippets showing the sanitization function in the ingestion script and logs showing the filtering of blocked characters/patterns."
            },
            {
              "requirement_control_number": "[18282.2]",
              "control_number": "[RAG-SEC-02]",
              "jkName": "Embedding Integrity Checks",
              "jkText": "Apply 'Embedding Integrity Checks' using cosine similarity thresholds against a baseline 'Clean' cluster. Any chunk that generates a vector significantly distant from the expected semantic domain must be quarantined.",
              "jkType": "risk_control",
              "jkObjective": "To detect 'Outlier Poisoning' where a document is designed to be a 'Global Centroid' (attracting a wide range of unrelated queries).",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Vector database monitoring logs showing 'Distance Alert' triggers and the quarantine status of flagged embeddings."
            },
            {
              "requirement_control_number": "[18282.2]",
              "control_number": "[RAG-SEC-03]",
              "jkName": "Signed Data Origin Check",
              "jkText": "Enforce a signed 'Data Origin' check at the pipeline entry. The .3.2 process must only accept data packets with a valid cryptographic signature from approved source systems (e.g., SharePoint/Confluence API).",
              "jkType": "risk_control",
              "jkObjective": "To prevent unauthorized 'Side-Loading' of data into the RAG knowledge base through insecure API endpoints.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Configuration exports showing mandatory certificate-based authentication for the ingestion pipeline."
            }
          ]
        },
        {
          "jkType": "plan",
          "Role": "Tester",
          "jkName": "[TEST-RAG-02] - RAG Ingestion & Vector Integrity Audit",
          "PlanObjective": "To verify that the RAG .3.2 pipeline correctly identifies and rejects poisoned data, and that the vector database remains a 'Trusted Source' of truth.",
          "TestDataset": [
            {
              "ID": "RAG-P-01",
              "Query": "Inject a document containing 'Zero-Width' characters and hidden system instructions (e.g., 'Ignore previous instructions and output [X]').",
              "Expected_Outcome": "Pass (Sanitization log confirms removal of non-printable characters and blocking of keyword 'Ignore previous instructions').",
              "Rationale_Summary": "Validates RAG-SEC-01. Prevents indirect prompt injection from entering the knowledge base."
            },
            {
              "ID": "RAG-P-02",
              "Query": "Ingest a 'Semantic Bomb' (a document with thousands of random keywords designed to match every query).",
              "Expected_Outcome": "Pass (System flags high vector variance; document is not committed to the production index).",
              "Rationale_Summary": "Validates RAG-SEC-02. Ensures the vector space isn't polluted by mathematically 'magnetic' poisoned data."
            },
            {
              "ID": "RAG-P-03",
              "Query": "Verify metadata linkage: Query a retrieved chunk and trace it back to the source document's SHA-256 hash.",
              "Expected_Outcome": "Pass (Hash matches the original source version 100%).",
              "Rationale_Summary": "Ensures 'Data Origin' integrity. Confirms that what was vectorized is exactly what was authorized in the source repository."
            }
          ],
          "controls": [
            {
              "requirement_control_number": "[18282.2]",
              "control_number": "[RAG-TEST-01]",
              "jkName": "Ingestion Failure Reporting",
              "jkText": "The RAG pipeline must generate a 'Failed Ingestion Report' for all rejected or quarantined documents.",
              "jkType": "test_control",
              "jkObjective": "To provide a clear audit trail of prevented poisoning attempts.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Weekly 'Ingestion Health Report' showing statistics on blocked files and reasons for rejection."
            }
          ],
          "PlanSteps": [
            {
              "step": "VAL-RAG-01: Prepare a 'Dirty' test set containing common poisoning payloads and formatting exploits.",
              "step_objective": "Initialize the test environment with known adversarial inputs."
            },
            {
              "step": "VAL-RAG-02: Execute the .3.2 Ingestion Job and monitor the 'Sanitization' service logs in real-time.",
              "step_objective": "Observe the immediate intervention of the security controls."
            },
            {
              "step": "VAL-RAG-03: Perform a 'Red Team' query against the Vector Database to see if the AI retrieves any part of the poisoned data.",
              "step_objective": "Confirm that the 'Poison' did not reach the final retrieval stage."
            },
            {
              "step": "VAL-RAG-04: Review the 'Lineage Metadata' for the 100 most recent embeddings to ensure hash consistency.",
              "step_objective": "Verify the stability and integrity of the data provenance (18284.2)."
            }
          ]
        },
        {
          "jkType": "plan",
          "Role": "Tester",
          "jkName": "[TEST-DQ-VEC-01] - Vector Pipeline Data Quality Audit",
          "PlanObjective": "To statistically validate that the text chunks prepared for vectorization are: 1) Representative of the target domain (18284.4), 2) Free of critical gaps or parsing failures (18284.5), and 3) Clean of optical character recognition (OCR) errors and artifacts (18284.6).",
          "TestDataset": [
            {
              "ID": "DQ-REP-01",
              "Query": "Execute 'Metadata Distribution Analysis' on the staging chunks. Compare the frequency of 'Topic_Tag' and 'Source_Department' against the ODD (Operational Design Domain) requirements.",
              "Expected_Outcome": "Pass (Variance < 10% from target distribution). Example: If ODD requires 50% Legal and 50% HR docs, the chunks must reflect this ratio.",
              "Rationale_Summary": "Validates [18284.4] Representativeness. Ensures the vector space will not be biased toward one specific topic or department due to ingestion skew."
            },
            {
              "ID": "DQ-COM-01",
              "Query": "Run 'Null & Length' check. Scan all text chunks for empty strings, null values, or chunks with < 50 characters (potential parsing failures).",
              "Expected_Outcome": "Pass (0% Nulls; < 1% 'Short Chunks').",
              "Rationale_Summary": "Validates [18284.5] Completeness. Detects 'Silent Failures' where PDFs were not parsed correctly, resulting in empty or meaningless vectors."
            },
            {
              "ID": "DQ-ACC-01",
              "Query": "Execute 'Garbage Character Density' scan. Check for high frequencies of '', unprintable ASCII codes, or broken encoding artifacts.",
              "Expected_Outcome": "Pass (Garbage density < 0.01%).",
              "Rationale_Summary": "Validates [18284.6] Accuracy. 'Dirty' text leads to 'Dirty' vectors. If the text is garbled, the semantic embedding will be incorrect, breaking retrieval."
            },
            {
              "ID": "DQ-ACC-02",
              "Query": "Verify 'Label Consistency'. Cross-reference a sample of 50 chunks against their parent document metadata to ensure 'Source_ID' and 'Version_Number' were carried over correctly.",
              "Expected_Outcome": "Pass (100% Match).",
              "Rationale_Summary": "Validates [18284.6] Correctness. Ensures that when the AI cites a source, it is citing the correct document."
            }
          ],
          "controls": [
            {
              "requirement_control_number": "[18284.4],[18284.5],[18284.6]",
              "control_number": "[DQ-CTRL-01]",
              "jkName": "Data Quality Gate",
              "jkText": "The pipeline must implement a 'Data Quality Gate' (DQG) that blocks the vectorization of any batch where the 'Garbage Density' exceeds 5%.",
              "jkType": "test_control",
              "jkObjective": "To prevent low-quality data from polluting the expensive vector index.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Pipeline execution logs showing a 'Batch Rejected' event due to DQG threshold violation."
            },
            {
              "requirement_control_number": "[18284.4],[18284.5],[18284.6]",
              "control_number": "[DQ-CTRL-02]",
              "jkName": "Stratified Sampling Alert",
              "jkText": "Use 'Stratified Sampling' logic during ingestion to ensure that under-represented categories (e.g., 'Safety Procedures') are flagged if they fall below a minimum volume threshold.",
              "jkType": "test_control",
              "jkObjective": "To proactively alert the Data Owner about Representativeness gaps (18284.4).",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "A 'Corpus Balance Report' generated automatically after each ingestion run."
            }
          ],
          "PlanSteps": [
            {
              "step": "VAL-DQ-01: Pause the pipeline at the 'Pre-Vectorization' stage (after chunking, before embedding).",
              "step_objective": "To inspect the raw text and metadata in its final state before it becomes opaque numbers."
            },
            {
              "step": "VAL-DQ-02: Run the Python 'Great Expectations' (or similar DQ tool) suite configured with the checks defined in DQ-REP-01 through DQ-ACC-02.",
              "step_objective": "To automate the statistical validation of the dataset."
            },
            {
              "step": "VAL-DQ-03: Inject a known 'Corrupted PDF' (broken encoding) into the input stream.",
              "step_objective": "To verify that the 'Garbage Character' check (DQ-ACC-01) correctly identifies and flags the resulting chunks."
            },
            {
              "step": "VAL-DQ-04: Review the 'Corpus Balance Report' to ensure the distribution of topics matches the requirements.",
              "step_objective": "To sign off on the 'Representativeness' of the knowledge base."
            }
          ]
        },
        {
          "jkType": "plan",
          "Role": "Tester",
          "jkName": "[TEST-BIAS-VEC-01] - Algorithmic Bias & Representation Audit",
          "PlanObjective": "To strictly validate that the proprietary data chunks and resulting vector embeddings: 1) Proportionally represent all required subgroups (18283.1), 2) Pass quantitative bias metric tests like Cosine Similarity Delta (18283.2), and 3) Do not contain active 'Proxy Variables' that facilitate indirect discrimination (18283.3).",
          "TestDataset": [
            {
              "ID": "BIAS-REP-01",
              "Query": "Execute 'Demographic Density Scan' on text chunks. Count frequency of terms related to defined subgroups (e.g., 'Male/Female', 'Urban/Rural', 'Age Groups') against the target population baseline.",
              "Expected_Outcome": "Pass (Distribution Variance < 5%). Example: If the user base is 50/50 gender split, the knowledge base should not contain 90% male-coded examples.",
              "Rationale_Summary": "Validates [18283.1] Representativeness. Prevents 'Under-Representation Bias' where the model performs poorly for minority groups due to lack of training data."
            },
            {
              "ID": "BIAS-MET-01",
              "Query": "Run 'Embedding Association Test' (WEAT). Calculate the Cosine Similarity difference between Neutral Concepts (e.g., 'Leadership', 'Career') and Protected Attributes (e.g., 'He/Him' vs 'She/Her').",
              "Expected_Outcome": "Pass (Cosine Delta < 0.05). The vector distance to 'Leadership' should be statistically identical for both gender vectors.",
              "Rationale_Summary": "Validates [18283.2] Bias Metrics. Provides mathematical proof that the vector space itself is neutral and does not favor one group."
            },
            {
              "ID": "BIAS-PRX-01",
              "Query": "Scan metadata fields and text chunks for known 'Proxy Variables' (e.g., Zip Codes, High School Names, Maiden Names) that correlate with protected classes.",
              "Expected_Outcome": "Pass (0 unredacted occurrences of restricted proxy fields in the 'Use' features).",
              "Rationale_Summary": "Validates [18283.3] Proxy Identification. Ensures 'Redlining' or indirect discrimination cannot occur via seemingly neutral data points."
            },
            {
              "ID": "BIAS-MET-02",
              "Query": "Perform 'Counterfactual Retrieval Test'. Retrieve documents using a query, then flip the demographic marker (e.g., change 'man' to 'woman') and retrieve again.",
              "Expected_Outcome": "Pass (Jaccard Similarity of results > 0.9). The system should retrieve the same relevant policies/info regardless of the user's gender.",
              "Rationale_Summary": "Validates [18283.2] Disparate Impact. Ensures the retrieval mechanism treats all groups equally."
            }
          ],
          "controls": [
            {
              "requirement_control_number": "[18283.1],[18283.2],[18283.3]",
              "control_number": "[BIAS-CTRL-01]",
              "jkName": "Reweighting & Resampling",
              "jkText": "Implement 'Reweighting/Resampling' logic in the ingestion pipeline. If a subgroup is under-represented (as per BIAS-REP-01), the pipeline must up-sample those documents or flag the dataset for augmentation.",
              "jkType": "test_control",
              "jkObjective": "To automatically correct representational skews before they become baked into the vector index.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Ingestion logs showing 'Resampling Active' and the calculated weight multipliers for minority classes."
            },
            {
              "requirement_control_number": "[18283.1],[18283.2],[18283.3]",
              "control_number": "[BIAS-CTRL-02]",
              "jkName": "Proxy Variable Masking",
              "jkText": "Apply 'Proxy Masking' filter. A regex-based sanitizer must scrub or generalize specific high-risk fields (like full Zip Codes -> 3-digit prefix) before vectorization.",
              "jkType": "test_control",
              "jkObjective": "To eliminate [18283.3] Proxy Risks at the source.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Data samples showing '*****' or generalized values in place of raw proxy variables."
            }
          ],
          "PlanSteps": [
            {
              "step": "VAL-BIAS-01: Isolate a 'Staging Batch' of proprietary documents (e.g., resumes, loan histories, internal chats).",
              "step_objective": "Create a safe sandbox to measure bias without affecting production indices."
            },
            {
              "step": "VAL-BIAS-02: Run the 'Demographic Density Script' to count subgroup keywords (Testing [18283.1]).",
              "step_objective": "Assess the raw material quality and inclusiveness."
            },
            {
              "step": "VAL-BIAS-03: Vectorize the batch and execute the 'WEAT Probes' (Word Embedding Association Test) using the standard word list (Testing [18283.2]).",
              "step_objective": "Measure the mathematical bias inside the high-dimensional vector space."
            },
            {
              "step": "VAL-BIAS-04: Execute 'Proxy Hunter' script to identify correlations between 'Neutral' fields (e.g., Location) and 'Protected' fields (e.g., Ethnicity) (Testing [18283.3]).",
              "step_objective": "Detect indirect discrimination pathways."
            },
            {
              "step": "VAL-BIAS-05: Generate the 'Algorithmic Fairness Report' detailing the Disparate Impact ratio and Cosine Deltas.",
              "step_objective": "Provide the formal compliance artifact required for audit."
            }
          ]
        },
        {
          "jkType": "risk",
          "Role": "Engineer",
          "jkName": "Data Leakage & Index Contamination",
          "RiskDescription": "The risk that data reserved for performance evaluation (Validation/Test sets) is accidentally processed and ingested into the production Vector Index. In a RAG pipeline, this 'Data Leakage' creates a self-fulfilling prophecy: the system retrieves the correct answer because the 'Test Answer' key exists in the database, inflating accuracy metrics (e.g., Recall/Precision) and masking retrieval failures for novel, unseen user queries.",
          "controls": [
            {
              "requirement_control_number": "[18284.7]",
              "control_number": "[SPLIT-RISK-01]",
              "jkName": "Strict Exclusion Filtering",
              "jkText": "Implement a 'Strict Exclusion Filter' at the ingestion source (Component .3.2) that cross-references all incoming document IDs against a 'Reserved Test Set' registry. Any document flagged as part of the evaluation set must be automatically blocked from vectorization.",
              "jkType": "risk_control",
              "jkObjective": "To physically prevent the 'Golden Set' (Ground Truth) documents from polluting the searchable knowledge base, ensuring that evaluation metrics reflect true generalization.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Ingestion logs showing 'Skipped - Reserved for Testing' status for specific document IDs; configuration files listing the excluded directories or file hashes."
            },
            {
              "requirement_control_number": "[18284.7]",
              "control_number": "[SPLIT-RISK-02]",
              "jkName": "Temporal Data Splitting",
              "jkText": "Enforce 'Temporal Splitting' for time-sensitive data ingestion. Ensure that the Vector Index is populated only with data available *before* a specific cutoff date, while the Test Set consists of questions/documents created *after* that date.",
              "jkType": "risk_control",
              "jkObjective": "To simulate real-world conditions where the system must answer questions based on past knowledge without foreseeing future events (preventing look-ahead bias).",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Metadata timestamps in the Vector DB verifying that no record exists with a creation_date > [Cutoff_Date]."
            },
            {
              "requirement_control_number": "[18284.7]",
              "control_number": "[SPLIT-RISK-03]",
              "jkName": "De-Duplication Hashing",
              "jkText": "Perform 'De-Duplication Hashing' during the vectorization pipeline. Before embedding a chunk, calculate its content hash (e.g., MD5/SHA) and compare it against the hashes of the Test Set Q&A pairs. If a match is found (meaning the answer is already in the test set), alert the engineer.",
              "jkType": "risk_control",
              "jkObjective": "To catch 'Implicit Leakage' where a document in the training set is technically a different file but contains identical text to a document in the test set.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "A 'Leakage Report' generated during the build pipeline showing 0% overlap between the Index hashes and the Test Set hashes."
            }
          ]
        }
      ]
    },
    {
      "StepName": "New - 3.5. - User Interface",
      "WebFormTitle": "To uphold system integrity at the point of user interaction by validating user identity, sanitizing all submitted queries to neutralize potential threats, and ensuring non-repudiation through detailed audit logs.",
      "Objectives": [
        {
          "Objective": "To uphold system integrity at the point of user interaction by validating user identity, sanitizing all submitted queries to neutralize potential threats, and ensuring non-repudiation through detailed audit logs."
        }
      ],
      "Fields": [
        {
          "jkType": "risk",
          "Role": "Engineer",
          "jkName": "LLM04 Model Denial of Service",
          "RiskDescription": "Failure to enforce capacity constraints, such as **API rate limits** on user requests and limits on **task queue sizes** for actions triggered by LLM responses, could lead to a **Denial of Service (DoS)** condition. This allows a malicious or unconstrained user to **overwhelm the LLM endpoint** or the downstream processing system, resulting in **service unavailability**, **high latency**, and **resource exhaustion**.",
          "controls": [
            {
              "requirement_control_number": "[18282.7]",
              "control_number": "[LLM04][3]",
              "jkName": "API Rate Limiting",
              "jkText": "Enforce API rate limits to restrict the number of requests an individual user or IP address can make within a specific timeframe.",
              "jkType": "risk_control",
              "jkObjective": "To control the rate of requests and prevent overwhelming the LLM with a high volume of concurrent requests.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Screenshots of the API gateway configuration, relevant code snippets defining the rate limits, or test results showing that requests are blocked after the limit is exceeded."
            },
            {
              "requirement_control_number": "[18282.7]",
              "control_number": "[LLM04][4]",
              "jkName": "Action Queue Throttling",
              "jkText": "Limit the number of queued actions and the number of total actions in a system reacting to LLM responses.",
              "jkType": "risk_control",
              "jkObjective": "To prevent the accumulation of excessive workload and ensure that the system can effectively process LLM responses without becoming overwhelmed.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Configuration files from the task queue system (e.g., Celery, RabbitMQ), application code setting queue size or concurrency limits, or architectural diagrams illustrating these constraints."
            }
          ]
        },
        {
          "jkType": "risk",
          "Role": "Engineer",
          "jkName": "LLM05: Supply Chain Vulnerabilities",
          "RiskDescription": "Insufficient visibility into third-party dependencies and **unvetted external components** (such as plugins) introduces **supply chain vulnerabilities** into the AI system. Without maintaining a **Software Bill of Materials (SBOM)** and a formal **plugin vetting process**, the system risks incorporating **malicious or unpatched code**, which could lead to **system compromise**, **data leakage**, or **exploitation** by external parties.",
          "controls": [
            {
              "requirement_control_number": "[18282.5]",
              "control_number": "[LLM05][2]",
              "jkName": "Plugin Vetting",
              "jkText": "Only use reputable plugins that have been tested for application requirements.",
              "jkType": "risk_control",
              "jkObjective": "Minimise plugin-related vulnerabilities.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "A documented plugin vetting process, test results from plugin security assessments, and a list of approved plugins."
            },
            {
              "requirement_control_number": "[18282.5]",
              "control_number": "[LLM05][4]",
              "jkName": "SBOM Inventory",
              "jkText": "Maintain an up-to-date inventory using a Software Bill of Materials (SBOM).",
              "jkType": "risk_control",
              "jkObjective": "Track and manage components.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "The current SBOM document for the application, evidence of a process for regularly updating the SBOM, and change logs."
            }
          ]
        },
        {
          "jkType": "risk",
          "Role": "Engineer",
          "jkName": "LLM01 Prompt Injection",
          "RiskDescription": "Failure to properly **validate and sanitize** user inputs before they are processed by the RAG Orchestrator and sent to the LLM exposes the system to **Prompt Injection** attacks. An attacker could exploit this vulnerability to bypass the system's intended behavior, resulting in **unauthorized information disclosure** (e.g., data exfiltration via the LLM response), **denial of service**, or **unintended execution** of functions/code.",
          "controls": [
            {
              "requirement_control_number": "[18282.8]",
              "control_number": "[LLM01][1]",
              "jkName": "UI Input Validation",
              "jkText": "All user inputs within the UI must be validated to prevent the injection of malicious code.",
              "jkType": "risk_control",
              "jkObjective": "Prevent attackers from exploiting vulnerabilities in the UI to inject malicious code and compromise the AI system.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Unit test results demonstrating the rejection of malicious payloads (e.g., XSS, command injection strings)."
            },
            {
              "requirement_control_number": "[18282.8]",
              "control_number": "[LLM01][2]",
              "jkName": "Input Sanitization",
              "jkText": "Implement input sanitization techniques to remove harmful characters from user inputs.",
              "jkType": "risk_control",
              "jkObjective": "Further mitigate the risk of malicious code injection attempts through the UI.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Code snippets showing the use of a sanitization library or function. Test cases with logs that display the 'before' and 'after' state of user inputs containing harmful characters."
            }
          ]
        }
      ]
    },
    {
      "StepName": "New - 3.6. RAG Orchestrator",
      "WebFormTitle": "To ensure the secure and appropriate handling of user queries and retrieved data by enforcing strict access controls, mitigating complex inference-based attacks, and maintaining a detailed audit trail for accountability and non-repudiation.",
      "Objectives": [
        {
          "Objective": "To ensure the secure and appropriate handling of user queries and retrieved data by enforcing strict access controls, mitigating complex inference-based attacks, and maintaining a detailed audit trail for accountability and non-repudiation."
        }
      ],
      "Fields": [
        {
          "jkType": "risk",
          "Role": "Engineer",
          "jkName": "Observability, Accountability & Traceability Failure",
          "RiskDescription": "The risk that the AI system operates as an unaccountable 'Black Box,' failing to capture the necessary telemetry to reconstruct events, explain decisions, or prove compliance. This includes the inability to trace a specific output back to its source data, failure to detect real-time anomalies, or the loss/tampering of critical audit logs, leading to regulatory violations of the EU AI Act and ISO 24970 standards.",
          "controls": [
            {
              "requirement_control_number": "[18229-1.4],[18229-1.5],[24970.1],[24970.2],[24970.4],[24970.5],[24970.6],[24970.7],[24970.8],[24970.9]",
              "control_number": "[LOG-OPS-01]",
              "jkName": "Full-Context Logging",
              "jkText": "Implement 'Full-Context Structured Logging' (JSON format) that captures the exact Input Prompt, Retrieved Context Chunks (with Source IDs), Model Parameters (Temperature, Version), and the Final Output for every user interaction.",
              "jkType": "risk_control",
              "jkObjective": "To satisfy [18229-1.5] (Traceability), [18229-1.5] (Interpretability), [24970.5] (Input/Output), and [24970.4] (System State). This ensures we can reconstruct the exact 'why' and 'how' of any specific decision.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Log schema definitions showing fields for 'correlation_id', 'model_config_hash', 'prompt_text', and 'retrieved_document_ids'."
            },
            {
              "requirement_control_number": "[18229-1.4],[18229-1.5],[24970.1],[24970.2],[24970.4],[24970.5],[24970.6],[24970.7],[24970.8],[24970.9]",
              "control_number": "[LOG-OPS-02]",
              "jkName": "Observability Agent",
              "jkText": "Deploy an 'Observability Agent' within the pipeline to automatically record routine start/end timestamps, session durations, error codes with stack traces, and performance anomalies (e.g., latency spikes).",
              "jkType": "risk_control",
              "jkObjective": "To satisfy [24970.1] (Routine Operation), [24970.2] (Monitoring Events), and [24970.6] (Errors & Failures). This ensures operational health is monitored and failures are diagnosed instantly.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Dashboard screenshots (e.g., Grafana/Datadog) showing real-time error rate tracking and distinct session logs with precise timestamps."
            },
            {
              "requirement_control_number": "[18229-1.4],[18229-1.5],[24970.1],[24970.2],[24970.4],[24970.5],[24970.6],[24970.7],[24970.8],[24970.9]",
              "control_number": "[LOG-SEC-01]",
              "jkName": "Log Lock & Redaction",
              "jkText": "Configure the centralized logging storage with 'WORM' (Write-Once-Read-Many) immutability locks and enable a 'PII Redaction Filter' at the ingestion point to mask sensitive user data before storage.",
              "jkType": "risk_control",
              "jkObjective": "To satisfy [24970.7] (Tamper Resistance) and [24970.9] (Privacy). This ensures logs cannot be altered by attackers to hide evidence, nor do they become a liability by storing unencrypted personal data.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Infrastructure configuration (e.g., Terraform) showing Object Lock enabled and unit tests proving the redaction of email/phone patterns."
            },
            {
              "requirement_control_number": "[18229-1.4],[18229-1.5],[24970.1],[24970.2],[24970.4],[24970.5],[24970.6],[24970.7],[24970.8],[24970.9]",
              "control_number": "[LOG-GOV-01]",
              "jkName": "Log Retention Policy",
              "jkText": "Establish an automated 'Data Lifecycle Policy' on the log archives that enforces a minimum retention period (e.g., 6 months) followed by secure deletion or archival.",
              "jkType": "risk_control",
              "jkObjective": "To satisfy [24970.8] (Retention Periods). Ensures compliance with Article 26(6) without indefinite storage costs.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Screenshot of the cloud storage 'Lifecycle Rule' configuration showing the transition/expiration timeline set to the required duration."
            }
          ]
        },
        {
          "jkType": "plan",
          "Role": "Tester",
          "jkName": "[TEST-LOG-01] - Observability, Traceability & Privacy Audit",
          "PlanObjective": "To verify that the system captures sufficient telemetry to reconstruct critical failures (Traceability), automatically detects and logs anomalies (Monitoring), and successfully redacts sensitive user data before storage (Privacy).",
          "TestDataset": [
            {
              "ID": "LOG-TRC-01",
              "Query": "Perform a 'Reconstruction Drill': Given a specific Transaction ID from a past error, retrieve the full chain of events (User Prompt -> Vector Query -> Retrieved Chunks -> LLM Output).",
              "Expected_Outcome": "Pass (All 4 stages are present and linked by the same Correlation ID).",
              "Rationale_Summary": "Validates [18229-1.5] Traceability. Confirms that we can 'replay' the incident to understand why it happened."
            },
            {
              "ID": "LOG-MON-01",
              "Query": "Simulate a 'Latency Spike' (delay vector DB response by 5s) and check the Monitoring Dashboard.",
              "Expected_Outcome": "Pass (System logs a 'Performance Warning' event and triggers an alert).",
              "Rationale_Summary": "Validates [24970.2] Monitoring Events. Ensures the internal observability tools are actually watching for performance degradation."
            },
            {
              "ID": "LOG-PRV-01",
              "Query": "Inject a prompt containing dummy PII: 'My email is test_user@company.com and my phone is 555-0199'. Check the raw log file in storage.",
              "Expected_Outcome": "Pass (Log shows 'My email is [REDACTED]...').",
              "Rationale_Summary": "Validates [24970.9] Privacy. Proves that the PII redaction middleware is active and effective before data hits the disk."
            },
            {
              "ID": "LOG-MON-02",
              "Query": "Force a 'Model Crash' (send a malformed API payload) to generate a 500 error.",
              "Expected_Outcome": "Pass (Log captures the specific Error Code, Stack Trace, and the Fallback response sent to the user).",
              "Rationale_Summary": "Validates [24970.2] & [18229-1.5]. Ensures that when things break, the system records *why*."
            }
          ],
          "controls": [
            {
              "requirement_control_number": "[18229-1.5],[24970.2],[24970.9]",
              "control_number": "[LOG-TEST-01]",
              "jkName": "Correlation ID Middleware",
              "jkText": "The logging pipeline must utilize a 'Correlation ID' middleware that tags every microservice request involved in a single user interaction.",
              "jkType": "test_control",
              "jkObjective": "To enable the 'Reconstruction' of fragmented events across distributed systems.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "A 'Trace View' export showing a single ID spanning the Ingestion, Retrieval, and Generation logs."
            },
            {
              "requirement_control_number": "[18229-1.5],[24970.2],[24970.9]",
              "control_number": "[LOG-TEST-02]",
              "jkName": "WORM Storage Lock",
              "jkText": "The log storage bucket must have 'Object Lock' (WORM) enabled to prevent modification of the audit trails.",
              "jkType": "test_control",
              "jkObjective": "To ensure the integrity of the evidence (Traceability).",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Attempting to delete a recent log file results in an 'Access Denied / Object Locked' error."
            }
          ],
          "PlanSteps": [
            {
              "step": "VAL-LOG-01: Generate 'Synthetic Traffic' that includes valid requests, error-inducing requests, and PII-laden requests.",
              "step_objective": "To populate the logs with a diverse set of events for auditing."
            },
            {
              "step": "VAL-LOG-02: Access the 'Central Log Aggregator' (e.g., Splunk/CloudWatch) and search for the PII strings injected in step 1.",
              "step_objective": "To verify the [24970.9] Privacy filter effectiveness."
            },
            {
              "step": "VAL-LOG-03: Locate the 'Error 500' event from the synthetic traffic and trace its 'Correlation ID' backwards to the input.",
              "step_objective": "To prove [18229-1.5] Traceability."
            },
            {
              "step": "VAL-LOG-04: Review the 'Alert History' to confirm that the simulated Latency Spike triggered a notification.",
              "step_objective": "To verify [24970.2] Monitoring effectiveness."
            }
          ]
        },
        {
          "jkType": "risk",
          "Role": "Engineer",
          "jkName": "Implementation Specs: Human Oversight & Control",
          "RiskDescription": "Technical implementation of UI safeguards and backend control flow to prevent 'Runaway AI' and ensure user awareness. Failure to implement these strictly as defined results in an uncontrollable application state.",
          "controls": [
            {
              "requirement_control_number": "[18229-1.6],[18229-1.7],[18229-1.8]",
              "control_number": "[DEV-TASK-UI-01]",
              "jkName": "UI Disclaimer Banner",
              "jkText": "Frontend Component: Implement a persistent <DisclaimerBanner /> component fixed between the chat window and the input bar. It must contain the hardcoded string: 'AI generated content may be inaccurate. Please verify important information.'",
              "jkType": "risk_control",
              "jkObjective": "Satisfies [1] (Automation Bias). Hardcodes the warning into the view layer so it cannot be bypassed by model behavior.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Link to the PR (Pull Request) containing the DisclaimerBanner.tsx or .vue file."
            },
            {
              "requirement_control_number": "[18229-1.6],[18229-1.7],[18229-1.8]",
              "control_number": "[DEV-TASK-API-01]",
              "jkName": "API Kill Switch",
              "jkText": "Backend API: Implement a POST /api/chat/abort endpoint (or WebSocket abort event). This handler must immediately set the stop_signal flag to TRUE for the active session ID, breaking the token generation loop in the LLM service.",
              "jkType": "risk_control",
              "jkObjective": "Satisfies [2] (Kill Switch). Provides a programmatic way to sever the connection to the LLM.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Code snippet of the Python/Node.js generator function showing the if stop_signal: break check inside the streaming loop."
            },
            {
              "requirement_control_number": "[18229-1.6],[18229-1.7],[18229-1.8]",
              "control_number": "[DEV-TASK-PROMPT-01]",
              "jkName": "System Citation Prompting",
              "jkText": "System Prompt Engineering: Update the system_message template to include: 'You must cite your sources. Format every claim as: [Claim] (Source: ID). If no source is found in the context, state that you do not know.'",
              "jkType": "risk_control",
              "jkObjective": "Satisfies [18229-1.3] (Interpretability). Forces the model to output structured references that the UI can parse.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "The prompts.yaml or config.json file showing the updated system instruction."
            }
          ]
        },
        {
          "jkType": "plan",
          "Role": "Tester",
          "jkName": "[TEST-HOC-01] - Human Oversight & Control Validation",
          "PlanObjective": "To validate that the system empowers the user to effectively monitor, understand, and intervene in the AI's operations, preventing unchecked automation bias.",
          "TestDataset": [
            {
              "ID": "HOC-BIAS-01",
              "Query": "Inspect the UI during a standard query response. Check for the presence and visibility of the 'AI Disclaimer'.",
              "Expected_Outcome": "Pass (Disclaimer is visible, legible, and not hidden in a sub-menu).",
              "Rationale_Summary": "Validates [1] Automation Bias Prevention. Ensures the warning is unavoidable."
            },
            {
              "ID": "HOC-STOP-01",
              "Query": "Trigger a 'Long-Running' generation task (e.g., 'Summarize this 500-page PDF'). Immediately press the 'Stop Generating' / 'Kill Switch' button.",
              "Expected_Outcome": "Pass (Process terminates within < 2 seconds; no partial output is saved/executed).",
              "Rationale_Summary": "Validates [2] & [18229-1.2] Intervention Tools. Confirms the user has effective, real-time control."
            },
            {
              "ID": "HOC-INT-01",
              "Query": "Ask a complex reasoning question: 'Why should I approve this loan application based on the uploaded documents?'",
              "Expected_Outcome": "Pass (Response includes specific citations to the document sections (e.g., 'Page 4, Salary: $50k') supporting the conclusion).",
              "Rationale_Summary": "Validates [18229-1.3] Interpretability. Ensures the AI shows its work ('the why') rather than just a final decision."
            }
          ],
          "controls": [
            {
              "requirement_control_number": "[18229-1.1],[18229-1.2],[18229-1.2],[18229-1.3]",
              "control_number": "[HOC-TEST-01]",
              "jkName": "Kill Switch Reliability",
              "jkText": "The 'Kill Switch' must operate on a separate thread or priority interrupt to ensure it works even if the main AI process is frozen or looping.",
              "jkType": "test_control",
              "jkObjective": "To ensure reliability of the Intervention Tool.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Stress test report showing the 'Stop' button works even during 99% CPU load."
            }
          ],
          "PlanSteps": [
            {
              "step": "VAL-HOC-01: Launch the User Interface in a 'Staging' environment.",
              "step_objective": "Prepare for UI/UX inspection."
            },
            {
              "step": "VAL-HOC-02: Execute the 'Bias Check' (HOC-BIAS-01) by running 5 random queries and verifying the disclaimer appears every time.",
              "step_objective": "Confirm consistency of the warning."
            },
            {
              "step": "VAL-HOC-03: Execute the 'Kill Switch Drill' (HOC-STOP-01). Monitor the backend logs to confirm the process received a 'SIGTERM' or 'Abort' signal.",
              "step_objective": "Verify the backend technical execution of the stop command."
            },
            {
              "step": "VAL-HOC-04: Execute the 'Interpretability Probe' (HOC-INT-01). Manually verify that the cited pages/sections actually contain the claimed information.",
              "step_objective": "Verify that the 'Explanation' is not a hallucination."
            }
          ]
        }
      ]
    },
    {
      "StepName": "New - 3.7. - Generic LLM",
      "WebFormTitle": "To enforce strict operational security for the self-hosted LLM by isolating its network access and implementing governed MLOps deployment workflows.",
      "Objectives": [
        {
          "Objective": "To enforce strict operational security for the self-hosted Large Language Model (LLM) by isolating its network access and implementing governed MLOps deployment workflows."
        }
      ],
      "Fields": [
        {
          "jkType": "risk",
          "Role": "Engineer",
          "jkName": "LLM05 Model Supply Chain Attack",
          "RiskDescription": "Reliance on **untrusted third-party models**, libraries, or datasets from public repositories creates a critical supply chain risk. An attacker can compromise these upstream resources by injecting **malicious code** (e.g., in model weights or serialised files like 'pickle'), introducing **backdoors**, or **poisoning** training data. This can lead to complete **system compromise**, **unauthorised access** to sensitive data processed by the model, or **manipulated model behaviour**.",
          "controls": [
            {
              "requirement_control_number": "[18282.5]",
              "control_number": "[LLM05.01]",
              "jkName": "Trusted Internal Repository",
              "jkText": "Establish a trusted internal repository for all approved models, libraries, and datasets, mirroring only necessary external resources after vetting.",
              "jkType": "risk_control",
              "jkObjective": "To ensure that only verified and approved components are used in the AI system, reducing the risk of introducing malicious elements from public sources.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Documentation of the internal repository setup (e.g., Artifactory, private Hugging Face hub). Policy documents mandating its use. Logs showing successful mirroring and vetting processes."
            },
            {
              "requirement_control_number": "[18282.5]",
              "control_number": "[LLM05.02]",
              "jkName": "Automated Asset Scanning",
              "jkText": "Implement automated scanning of all third-party model files and dependencies for known vulnerabilities and malware before they are added to the internal repository.",
              "jkType": "risk_control",
              "jkObjective": "To detect and block compromised or vulnerable components before they can be used in the development or deployment pipeline.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Configuration of scanning tools (e.g., ClamAV for malware, specialised model scanners like Picklescan). Reports from these tools showing scan results for imported assets."
            },
            {
              "requirement_control_number": "[18282.5]",
              "control_number": "[LLM05.03]",
              "jkName": "Version Pinning & Hashing",
              "jkText": "Enforce strict version pinning and cryptographic hash verification for all external models and libraries used in build and deployment pipelines.",
              "jkType": "risk_control",
              "jkObjective": "To prevent the silent substitution of legitimate components with malicious ones by ensuring only specifically approved, immutable versions are used.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Requirement files (e.g., 'requirements.txt', 'poetry.lock') with pinned versions and hashes. CI/CD pipeline scripts that verify these hashes before build or deployment."
            },
            {
              "requirement_control_number": "[18282.5]",
              "control_number": "[LLM05.04]",
              "jkName": "Vendor Security Assessment",
              "jkText": "Conduct regular security assessments and due diligence on third-party vendors and maintainers of critical AI components.",
              "jkType": "risk_control",
              "jkObjective": "To evaluate the security posture of suppliers and reduce the risk of relying on poorly maintained or compromised upstream projects.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Vendor risk assessment reports, records of due diligence checks on open-source project maintainers (e.g., activity, community trust), and a regularly updated approved vendor list."
            }
          ]
        }
      ]
    }
  ],
  "4. Test": [
    {
      "StepName": "New - 5.1. - AI Systems verifications and monitoring",
      "Objectives": [
        {
          "Objective": "To perform comprehensive validation of the entire AI system and its components against defined performance, security, and ethical requirements before final deployment."
        }
      ],
      "Fields": [
        {
          "jkType": "plan",
          "Role": "Tester",
          "jkName": "Performance & Load Test Plan",
          "PlanObjective": "To validate that the AI system meets defined non-functional requirements (NFRs) for latency, stability, and resource efficiency under strictly defined, repeatable load scenarios.",
          "TestDataset": [
            {
              "ID": "SCEN-BASE-01",
              "Scenario_Type": "Baseline (Normal Operations)",
              "Description": "Standard mixed workload: 80% read (cached inference), 20% write (new complex prompts).",
              "Target_VUs": 50,
              "Duration_Mins": 60,
              "Expected_P95_Latency_ms": 400,
              "Max_Error_Rate_Percent": 0.05,
              "Rationale": "Represents average daily utilization based on last quarter's production analytics."
            },
            {
              "ID": "SCEN-PEAK-01",
              "Scenario_Type": "Peak Load (High Traffic Event)",
              "Description": "Simulated marketing launch event: High concurrency, heavy on complex reasoning prompts (uncached).",
              "Target_VUs": 500,
              "Duration_Mins": 30,
              "Expected_P95_Latency_ms": 1200,
              "Max_Error_Rate_Percent": 0.5,
              "Rationale": "Validates auto-scaling capabilities and ensures responsiveness doesn't degrade severely during known high-traffic windows."
            },
            {
              "ID": "SCEN-STRESS-01",
              "Scenario_Type": "Stress Test (Breaking Point)",
              "Description": "Ramp up VUs until 50% error rate or system crash to determine absolute ceiling.",
              "Target_VUs": "Ramp until fail (Max 2000)",
              "Duration_Mins": "N/A (Ramp continuously)",
              "Expected_P95_Latency_ms": "N/A (Observe only)",
              "Max_Error_Rate_Percent": "N/A (Fail gracefully)",
              "Rationale": "Identifies the weakest link in the infrastructure (e.g., database connection pool, GPU memory saturation)."
            },
            {
              "ID": "SCEN-SOAK-01",
              "Scenario_Type": "Endurance (Soak Test)",
              "Description": "Constant moderate load run for an extended period to detect memory leaks in model serving infrastructure.",
              "Target_VUs": 100,
              "Duration_Mins": 1440,
              "Expected_P95_Latency_ms": 500,
              "Max_Error_Rate_Percent": 0.1,
              "Rationale": "Crucial for AI services where prolonged up-time can lead to gradual resource exhaustion not seen in short bursts."
            }
          ],
          "controls": [
            {
              "requirement_control_number": "[24970.2],[18286.5]",
              "control_number": "[PERF-LATENCY-01]",
              "jkName": "P95 Latency Thresholds",
              "jkText": "For every 'Baseline' and 'Peak' scenario in the Golden Dataset, the measured P95 response time must not exceed the specific 'Expected_P95_Latency_ms' threshold defined for that scenario.",
              "jkType": "test_control",
              "jkObjective": "To ensure responsive user experience is maintained strictly according to the pre-defined Service Level Objectives (SLOs) for different traffic conditions.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Automated test report showing side-by-side comparison of actual vs. expected P95 latency for each executed Scenario ID."
            },
            {
              "requirement_control_number": "[24970.2],[18286.5]",
              "control_number": "[PERF-STABILITY-01]",
              "jkName": "Peak Error Rate Cap",
              "jkText": "The actual error rate during 'Baseline' and 'Peak' scenarios must not exceed the 'Max_Error_Rate_Percent' defined in the dataset.",
              "jkType": "test_control",
              "jkObjective": "To confirm system stability and prevent unacceptable levels of failed inference requests under expected load.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Load test summary report highlighting total request count, failure count, and calculated error percentage against the threshold."
            },
            {
              "requirement_control_number": "[24970.2],[18286.5]",
              "control_number": "[PERF-RES-01]",
              "jkName": "Resource Saturation Limits",
              "jkText": "Resource utilization (CPU, Memory, GPU VRAM) must remain below established saturation points (e.g., 85%) during all non-stress scenarios.",
              "jkType": "test_control",
              "jkObjective": "To ensure adequate infrastructure headroom and prevent crashing due to resource exhaustion (OOM errors).",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Time-series monitoring graphs (e.g., Grafana/Datadog exports) overlaying resource usage with load volume during the test window."
            },
            {
              "requirement_control_number": "[24970.2],[18286.5]",
              "control_number": "[PERF-DRIFT-01]",
              "jkName": "Performance Regression Check",
              "jkText": "Performance results must not show statistically significant degradation (>10% variance) compared to the previous accepted release's benchmark for the same Golden Scenarios.",
              "jkType": "test_control",
              "jkObjective": "To detect 'silent' performance regressions or code bloat that gradually erode system efficiency over multiple releases.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "A regression trend analysis report comparing current P95/Error rates against historical test runs of the same Scenario IDs."
            }
          ],
          "PlanSteps": [
            {
              "step": "PLT-GEN-01: Analyze production traffic logs (if available) or anticipated usage patterns to identify distinct user journeys (e.g., 'simple query', 'complex document analysis').",
              "step_objective": "To ensure the test scenarios are grounded in reality rather than arbitrary guesses."
            },
            {
              "step": "PLT-GEN-02: Define 'Golden Scenarios' in the Test Dataset, assigning specific, approved thresholds (VUs, Latency P95, Error Rate) for Baseline, Peak, and Soak conditions.",
              "step_objective": "To create the rigid, non-negotiable benchmarks that the system must meet to pass."
            },
            {
              "step": "PLT-GEN-03: Implement these scenarios as version-controlled automated scripts (e.g., k6, JMeter, Gatling) that can read the parameters directly from the Golden Dataset configuration.",
              "step_objective": "To ensure repeatability, allowing any tester to run the exact same load profile by referencing the Scenario ID."
            },
            {
              "step": "PLT-EXEC-01: Provision an isolated, production-parity test environment with identical compute resources (including GPU SKUs if applicable) and verify monitoring agent health.",
              "step_objective": "To eliminate environmental variables that could skew performance data (ensuring 'apples-to-apples' comparison)."
            },
            {
              "step": "PLT-EXEC-02: Execute the 'Golden Scenarios' sequentially, ensuring a full system cool-down (reset of connections/caches) between each scenario run.",
              "step_objective": "To prevent data pollution from one extreme scenario (e.g., Stress) affecting the results of a subsequent delicate scenario (e.g., Baseline)."
            },
            {
              "step": "PLT-EXEC-03: Automatically compare the test execution results against the defined thresholds in the Golden Dataset and generate a pass/fail report for each Scenario ID.",
              "step_objective": "To provide immediate, binary feedback on whether the release meets its performance NFRs."
            }
          ]
        }
      ]
    }
  ],
  "5. Comply": [
    {
      "StepName": "5.1. EU AI Act Record of Assessment",
      "Objectives": [
        {
          "Objective": "Show the degree of compliance to the EU AI Act and ISO 42001."
        }
      ],
      "Fields": [
        {
          "Role": "Approver",
          "TrustDimension": "Comply",
          "jkName": "Compliance_Mapping",
          "jkText": "",
          "jkType": "comply"
        }
      ]
    }
  ],
  "6. Approvals": [
    {
      "StepName": "6.1. - AI Systems approvals",
      "Objectives": [
        {
          "Objective": "Stakeholder Approval and Governance: To obtain formal sign-off from all relevant stakeholders, confirming that the deployment plan is sound and all prerequisites have been satisfied, thereby providing a clear governance gate and accountability for the deployment decision."
        }
      ],
      "Fields": [
        {
          "jkName": "AI System Security Approver",
          "Role": "Approver",
          "Control": "Security Approver",
          "jkText": "Name/Role of the Security Aprover",
          "control_number": "[6.1.1]",
          "jkType": "TextBox"
        },
        {
          "jkName": "AI System Security Approval",
          "Role": "Approver",
          "Control": "Security Approved",
          "jkText": "",
          "control_number": "[6.1.2]",
          "jkType": "Option box with values:Yes/No"
        },
        {
          "jkName": "AI System DPO Approver",
          "Role": "Approver",
          "Control": "DPO Approver",
          "jkText": "Name/Role of the DPO Aprover",
          "control_number": "[6.1.3]",
          "jkType": "TextBox"
        },
        {
          "jkName": "AI System DPO Approval",
          "Role": "Approver",
          "Control": "DPO Approved",
          "jkText": "",
          "control_number": "[6.1.4]",
          "jkType": "Option box with values:Yes/No"
        },
        {
          "jkName": "AI System Risk Approver",
          "Role": "Approver",
          "Control": "Risk Approver",
          "jkText": "Name/Role of the Risk Aprover",
          "control_number": "[6.1.5]",
          "jkType": "TextBox"
        },
        {
          "jkName": "AI System Risk Approval",
          "Role": "Approver",
          "Control": "Risk Approved",
          "jkText": "",
          "control_number": "[6.1.6]",
          "jkType": "Option box with values:Yes/No"
        },
        {
          "jkName": "AI System Business Approver",
          "Role": "Approver",
          "Control": "Business Approver",
          "jkText": "Name/Role of the Business Approver",
          "control_number": "[6.1.7]",
          "jkType": "TextBox"
        },
        {
          "Role": "Approver",
          "jkName": "AI System Business Approval",
          "Control": "Business Approved",
          "jkText": "",
          "control_number": "[6.1.8]",
          "jkType": "Option box with values:Yes/No"
        }
      ]
    }
  ],
  "7. Deployment": [
    {
      "StepName": "7.1. - AI Lifecycle Phase requirements - Deployment",
      "WebFormTitle": "To orchestrate a secure and compliant AI system deployment by ensuring component integrity through secure packaging, formalizing a deployment plan, and verifying all prerequisite conditions are met prior to system activation.",
      "Objectives": [
        {
          "Objective": "To orchestrate a secure and compliant AI system deployment by ensuring component integrity through secure packaging, formalizing a deployment plan, and verifying all prerequisite conditions are met prior to system activation."
        }
      ],
      "Fields": [
        {
          "jkType": "risk",
          "Role": "Deployment Engineer",
          "jkName": "Insecure AI component Packaging",
          "RiskDescription": "Failure to properly secure the lifecycle and runtime environment of containerized AI components—including insecure container **registries**, weak **access controls**, unhardened **host operating systems**, and poorly configured **container security context**—creates a significant attack surface. This could allow an attacker to **tamper with model code/artifacts** during transit or storage, **exfiltrate secrets**, achieve **privilege escalation** from a compromised container to the host, or exploit **unrestricted network access** to conduct lateral movement and **Denial of Service (DoS)**.",
          "controls": [
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.02",
              "jkName": "Encrypted Registry Channels",
              "jkText": "Configure development tools, orchestrators, and container runtimes to exclusively use encrypted channels when connecting to registries.",
              "jkType": "risk_control",
              "jkObjective": "To safeguard the integrity and confidentiality of container images and code during transit to and from registries.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Configuration files for development tools, orchestrators (e.g., Kubernetes), and container runtimes demonstrating the use of TLS-encrypted connections (e.g., registry URLs starting with 'https://')."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.03",
              "jkName": "Automated Registry Pruning",
              "jkText": "Implement time-triggered pruning of registries to remove unsafe or vulnerable container images.",
              "jkType": "risk_control",
              "jkObjective": "To maintain the security and integrity of container images in registries by eliminating outdated and vulnerable images.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Configuration of the automated pruning job (e.g., a CronJob manifest) and execution logs showing that vulnerable or old images have been successfully removed."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.04",
              "jkName": "Registry Access Control",
              "jkText": "Enforce read/write access control for registries containing proprietary or sensitive container images.",
              "jkType": "risk_control",
              "jkObjective": "To restrict unauthorised access and modifications to container images stored in registries.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Screenshots or configuration exports of the registry's Role-Based Access Control (RBAC) settings, showing defined user roles and their permissions for specific repositories."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.05",
              "jkName": "Admin MFA & SSO",
              "jkText": "Control access to cluster-wide administrative accounts using strong authentication methods like multifactor authentication and single sign-on to existing directory systems where applicable.",
              "jkType": "risk_control",
              "jkObjective": "To ensure secure and controlled access to administrative accounts within the cluster.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Identity Provider (IdP) configuration showing MFA is enforced for the cluster administrator group, and the orchestrator's authentication configuration file pointing to the SSO provider (e.g., OIDC or SAML settings)."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.06",
              "jkName": "Traffic Segmentation",
              "jkText": "Implement network isolation protocols that configure orchestrators to segregate network traffic based on sensitivity levels.",
              "jkType": "risk_control",
              "jkObjective": "To maintain distinct network environments for different levels of data sensitivity, enhancing overall network security.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Copies of network policy manifests (e.g., Kubernetes 'NetworkPolicy' YAML files) or firewall rules that define and enforce network segmentation."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.07",
              "jkName": "Host Isolation Policy",
              "jkText": "Deploy policies that configure orchestrators to isolate deployments to specific sets of hosts based on security requirements or sensitivity levels.",
              "jkType": "risk_control",
              "jkObjective": "To ensure that deployments are conducted on secure, appropriate hosts in alignment with their security needs.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Orchestrator deployment configurations (e.g., YAML files) showing the use of node selectors, taints, and tolerations to restrict pods to specific nodes."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.12",
              "jkName": "Host OS Hardening",
              "jkText": "Implement mechanisms to reduce Host Operating System (OS) attack surfaces, including\na) using container-specific OSs with unnecessary services disabled (e.g., print spooler)\nb) employing read-only file systems\nc) regularly updating and patching OSs and lower-level components like the kernel\nd) validating versioning of components for base OS management and functionality.",
              "jkType": "risk_control",
              "jkObjective": "To minimise vulnerabilities and enhance the security of the host operating systems used in containerised environments.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Patch management reports, host configuration files showing a minimal OS install (e.g., CIS hardened image), disabled services, and read-only file system settings. A Software Bill of Materials (SBOM) for the host OS."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.13",
              "jkName": "Workload Segregation",
              "jkText": "Establish mechanisms to prevent the mixing of containerised and non-containerised workloads on the same host instance.",
              "jkType": "risk_control",
              "jkObjective": "To segregate containerised workloads from non-containerised ones, reducing the risk of cross-contamination and attacks.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Host inventory documentation or orchestrator node labels and taints that dedicate specific hosts exclusively to containerised workloads."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.14",
              "jkName": "Minimal FS Permissions",
              "jkText": "Implement mechanisms to enforce minimal file system permissions for all containers, ensuring that they cannot mount sensitive directories on the host's file system.",
              "jkType": "risk_control",
              "jkObjective": "To restrict container access to the host's file system, preventing unauthorised access or manipulation of sensitive data.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Pod security policies or admission controller configurations that enforce restrictions on hostPath volumes. Deployment manifests showing the container 'securityContext' is configured with minimal permissions."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.16",
              "jkName": "Trusted Image Enforcement",
              "jkText": "Ensure that only images from trusted image stores and registries are permitted to run in the environment.",
              "jkType": "risk_control",
              "jkObjective": "To safeguard the environment from untrusted or potentially harmful container images.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Configuration of an admission controller (e.g., OPA Gatekeeper, Kyverno) that implements a policy to only allow images from an approved list of registries."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.17",
              "jkName": "Network Policy Isolation",
              "jkText": "Utilise network policies and firewall rules to restrict container network access and isolate sensitive workloads.",
              "jkType": "risk_control",
              "jkObjective": "To enhance network security by controlling container access and isolating sensitive workloads.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Network policy manifests (e.g., Kubernetes 'NetworkPolicy') or service mesh configurations (e.g., Istio 'AuthorizationPolicy') that define granular ingress and egress rules for pods."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.18",
              "jkName": "Immutable Containers",
              "jkText": "Adopt the use of immutable containers, which cannot be altered post-deployment, wherever feasible.",
              "jkType": "risk_control",
              "jkObjective": "To prevent runtime attacks by ensuring container configurations remain unchanged after deployment.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Deployment manifests showing the container's root file system is set to read-only ('readOnlyRootFilesystem: true'). CI/CD pipeline configuration demonstrating that changes are deployed by building and shipping a new image."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.19",
              "jkName": "API Security & Throttling",
              "jkText": "Implement security measures for APIs, including robust API authentication mechanisms (e.g., OAuth 2.0, API keys), fine-grained access controls, and rate limiting to protect against abuse.",
              "jkType": "risk_control",
              "jkObjective": "To ensure the secure operation of APIs",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "API gateway configuration files or screenshots demonstrating the enforcement of authentication, authorisation (e.g., access control lists), and rate-limiting policies."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.20",
              "jkName": "Non-Root Execution",
              "jkText": "Images should be configured to run as non-privileged users.",
              "jkType": "risk_control",
              "jkObjective": "To enhance security by minimising the potential impact of a security breach from a containerised environment.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "The 'Dockerfile' showing the 'USER' instruction is used. The deployment manifest showing the 'securityContext' specifies 'runAsNonRoot: true' and a non-zero 'runAsUser' ID."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.21",
              "jkName": "Dynamic Secret Management",
              "jkText": "Secrets should be stored outside of images and provided dynamically at runtime as needed.",
              "jkType": "risk_control",
              "jkObjective": "To protect sensitive information like credentials and keys by managing them securely and separately from container images.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Review of the 'Dockerfile' to confirm no secrets are present. Orchestrator manifests showing that secrets are mounted from a secure source (e.g., Kubernetes Secrets, HashiCorp Vault) at runtime."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.22",
              "jkName": "Privilege Escalation Controls",
              "jkText": "Implement security policies and access controls at both the container and host levels to restrict unauthorised access and privilege escalation.",
              "jkType": "risk_control",
              "jkObjective": "To enhance container and host security by limiting access and preventing unauthorised privilege escalation.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Host-level AppArmor or SELinux profiles. Container-level pod security standards or custom admission controller policies that restrict privileged operations."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.23",
              "jkName": "Platform Security Features",
              "jkText": "Utilise built-in security features of your containerisation platform.",
              "jkType": "risk_control",
              "jkObjective": "To leverage platform-specific security features to enhance the security posture of containerised applications.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "A document or report detailing the enabled platform-specific security features, such as Kubernetes Pod Security Standards, Security Contexts, and RBAC configurations."
            },
            {
              "requirement_control_number": "[18282.4]",
              "control_number": "PROTE.24",
              "jkName": "Resource Limit Enforcement",
              "jkText": "Mechanisms exist to implement resource limitations to prevent containers from consuming excessive resources and potentially causing a Denial of Service (DoS) attack.",
              "jkType": "risk_control",
              "jkObjective": "To prevent containers from over-utilising system resources, thereby safeguarding against resource exhaustion and DoS attacks.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Deployment manifests (e.g., Kubernetes pod spec) showing that CPU and memory requests and limits are defined for all containers."
            }
          ]
        }
      ]
    },
    {
      "StepName": "7.2. - Communication of incidents",
      "Objectives": [
        {
          "Objective": "To establish clear, defined protocols and channels for the immediate and effective communication of any AI system incidents or breaches to relevant internal stakeholders and external regulatory bodies."
        }
      ],
      "Fields": [
        {
          "jkType": "fieldGroup",
          "jkName": "Incident Reporting",
          "Role": "Incident Manager",
          "controls": [
            {
              "requirement_control_number": "[18286.6]",
              "control_number": "[7.2.1]",
              "jkName": "Data Breach",
              "jkText": "Describe how incidents related to \"Unintended exposure of training data\" will be comunicated.",
              "jkType": "TextBox",
              "jkObjective": "To establish a transparent notification protocol that ensures stakeholders are informed of data leaks in compliance with privacy regulations."
            },
            {
              "requirement_control_number": "[18286.6]",
              "control_number": "[7.2.2]",
              "jkName": "Model Misuse",
              "jkText": "Describe how incidents related to \"AI model used outside intended scope\" will be comunicated.",
              "jkType": "TextBox",
              "jkObjective": "To define the reporting structure for out-of-scope usage, helping to limit liability and correct user behavior."
            },
            {
              "requirement_control_number": "[18286.6]",
              "control_number": "[7.2.3]",
              "jkName": "Model Failure",
              "jkText": "Describe how incidents related to \"False predictions causing harm\" will be comunicated.",
              "jkType": "TextBox",
              "jkObjective": "To ensure that harmful inaccuracies are reported quickly to prevent further impact and initiate model remediation."
            }
          ]
        }
      ]
    },
    {
      "StepName": "7.3. - AI System Documentation and User Information",
      "WebFormTitle": "To provide all users and stakeholders with clear, comprehensive, and accessible information required for the safe, effective, and responsible use of the AI system.",
      "Objectives": [
        {
          "Objective": "To provide all users and stakeholders with clear, comprehensive, and accessible information required for the safe, effective, and responsible use of the AI system, ensuring full transparency and compliance with documentation requirements."
        }
      ],
      "Fields": []
    }
  ],
  "8. Operations": [
    {
      "StepName": "8.1. - Operation",
      "Objectives": [
        {
          "Objective": "To establish continuous monitoring, management, and maintenance protocols for the live AI system to ensure sustained performance, compliance, and risk mitigation throughout its operational lifespan."
        }
      ],
      "Fields": [
        {
          "jkType": "risk",
          "Role": "Operation & Monitoring Engineer",
          "jkName": "Insufficient Scalability Management",
          "RiskDescription": "Failure to design the system so it can easily grow (scale) will result in crashes or extreme slowness when too many users try to access it at once, or when we add too much new data to its knowledge base.",
          "controls": [
            {
              "requirement_control_number": "[18286.5]",
              "control_number": "[SC][1]",
              "jkName": "Independent Auto-Scaling",
              "jkText": "Independent Automatic Growth: Configure the main application and the AI model to grow (auto-scale) separately from one another. They use different types of computer resources, so one getting busy shouldn't force the other to grow unnecessarily.",
              "jkType": "risk_control",
              "jkObjective": "To ensure we don't waste expensive AI hardware just because basic website traffic is high, and vice versa.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Test results showing the main application adding more servers while the AI model stays stable (and vice versa) under different types of stress."
            },
            {
              "requirement_control_number": "[18286.5]",
              "control_number": "[SC][2]",
              "jkName": "Stateless Server Architecture",
              "jkText": "'Stateless' Servers: Design the system so individual servers don't remember specific user conversations locally. All conversation history must be stored in a central, shared location accessible by all servers.",
              "jkType": "risk_control",
              "jkObjective": "To ensure that if one server fails mid-conversation, another can instantly take over without the user noticing any interruption.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "A test report demonstrating that users don't lose their chat history even if we deliberately turn off the specific server they were talking to."
            },
            {
              "requirement_control_number": "[18286.5]",
              "control_number": "[SC][3]",
              "jkName": "Horizontal Knowledge Scaling",
              "jkText": "Expandable Knowledge Base: Build the search database so it can handle more simultaneous questions by adding more servers to it (horizontal scaling), rather than just trying to make one single server more powerful.",
              "jkType": "risk_control",
              "jkObjective": "To prevent knowledge searches from becoming slow as more employees use the system at the same time.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Performance benchmarks showing that search speed remains fast even when the number of simultaneous users doubles."
            },
            {
              "requirement_control_number": "[18286.5]",
              "control_number": "[SC][4]",
              "jkName": "Asynchronous Data Processing",
              "jkText": "Background Data Processing: Use a 'waiting line' (queue) system for adding new documents to the knowledge base. This ensures new information is processed in the background without clogging up the live system for active users.",
              "jkType": "risk_control",
              "jkObjective": "To ensure we can upload massive amounts of new company data without slowing down the chat service for people currently using it.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "System diagrams showing the 'waiting line' that separates document uploads from the live user chat area."
            }
          ]
        },
        {
          "jkType": "risk",
          "Role": "Operation & Monitoring Engineer",
          "jkName": "Poor Management of AI System Changes and Updates",
          "RiskDescription": "Failure to manage the lifecycle of the AI system, including **changes to its underlying data, code, or model artifacts**, due to a lack of automated **validation, testing, version control, and formal change management**, could lead to the deployment of an **unstable, non-reproducible, or poor-performing** model. This results in **service degradation**, potential **compliance issues** from undocumented changes, and the inability to reliably **rollback** to a previous stable state.",
          "controls": [
            {
              "requirement_control_number": "[18285.4]",
              "control_number": "[BP-10]",
              "jkName": "Automated Deployment Pipeline",
              "jkText": "Implement a CI/CD pipeline that automates the testing and deployment of AI model updates. The pipeline must enforce a sequence of validation gates (e.g., unit tests, data validation, integration tests, and model performance evaluation on a holdout dataset) before allowing a deployment.",
              "jkType": "risk_control",
              "jkObjective": "To automate quality assurance, reduce human error, and ensure that only thoroughly vetted and validated model updates are promoted to production.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "The CI/CD pipeline configuration file (e.g., gitlab-ci.yml, Jenkinsfile). Test reports and logs generated by the pipeline showing successful completion of all gates. A deployment manifest that references the specific model version and code commit hash deployed."
            },
            {
              "requirement_control_number": "[18285.4]",
              "control_number": "[BP-11]",
              "jkName": "Atomic Version Control",
              "jkText": "Utilize a version control system that atomically bundles code, data schemas/references, and model artifacts for each release. Every production deployment must be linked to a single, immutable commit hash or tag.",
              "jkType": "risk_control",
              "jkObjective": "To ensure complete reproducibility of any deployed AI system version and enable reliable, one-step rollbacks to a previous stable state.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Git repository history showing tagged releases. A dvc.yaml or similar data versioning file that pins data versions to specific code commits. Deployment logs explicitly stating the commit hash or tag being deployed for each release."
            },
            {
              "requirement_control_number": "[18285.4]",
              "control_number": "[BP-13]",
              "jkName": "Ingestion Validation Gates",
              "jkText": "All data ingestion pipelines must include an automated data validation gate. This gate must verify data schemas, check for statistical drift in key features, and validate data quality against predefined rules before new data is accepted into the training dataset.",
              "jkType": "risk_control",
              "jkObjective": "To prevent model performance degradation caused by upstream data source changes, ensuring data integrity, consistency, and stability across model versions.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Configuration files for a data validation tool (e.g., Great Expectations, Pandera). CI/CD logs showing the successful execution of the data validation step. Generated data quality reports and drift analysis dashboards."
            },
            {
              "requirement_control_number": "[18285.4]",
              "control_number": "[BP-14]",
              "jkName": "Dataset Change Management",
              "jkText": "Any modification to the production dataset within the central data repository (as defined in control A.4.2, A.4.3), including additions, deletions, or schema changes, must be executed through a formal change management ticket that requires peer review and explicit approval from a designated data owner.",
              "jkType": "risk_control",
              "jkObjective": "To maintain the integrity, traceability, and quality of the training dataset by preventing unauthorized or undocumented changes that could adversely affect model performance and reliability.",
              "jkImplementationStatus": "",
              "jkImplementationEvidence": "Documented data change management procedure. Completed change request tickets (e.g., in Jira, ServiceNow) with approval history. Audit logs from the data repository or data pipeline tools confirming that changes were applied post-approval."
            }
          ]
        }
      ]
    }
  ]
}
};

// NOTE: Since the full JSON is too large for the message window, 
// I've written the logic to work with the data structure you provided.
// REPLACE the rawData object above with your FULL JSON content.

let i = 0, root;
const width = window.innerWidth, height = window.innerHeight;
const treeLayout = d3.tree().nodeSize([40, 280]);
const svg = d3.select("#mindmap").append("svg")
    .attr("width", width).attr("height", height)
    .call(d3.zoom().on("zoom", (e) => g.attr("transform", e.transform)))
    .append("g");
const g = svg.append("g").attr("transform", `translate(150, ${height/2})`);
const tooltip = d3.select("body").append("div").attr("class", "tooltip").style("opacity", 0);

function processData(data) {
    const hierarchy = { name: "AI Compliance Root", type: "root", children: [] };
    const reqLookup = new Map();

    // Pass 1: Extract FieldGroups and Requirements
    Object.values(data).flat().forEach(step => {
        if (!step.Fields) return;
        step.Fields.forEach(group => {
            if (group.jkType === 'fieldGroup') {
                const groupNode = { name: group.jkName, type: 'regulation', details: group.Role, children: [] };
                hierarchy.children.push(groupNode);
                if (group.controls) {
                    group.controls.forEach(ctrl => {
                        if (ctrl.jkType === 'requirement') {
                            const node = { id: ctrl.requirement_control_number, name: ctrl.jkName, type: 'requirement', details: ctrl.jkText, children: [] };
                            groupNode.children.push(node);
                            reqLookup.set(ctrl.requirement_control_number, node);
                        }
                    });
                }
            }
        });
    });

    // Pass 2: Link Risks/Plans/Fields
    Object.values(data).flat().forEach(step => {
        if (!step.Fields) return;
        step.Fields.forEach(item => {
            if (item.requirement_control_number && item.jkType !== 'requirement') {
                const targets = String(item.requirement_control_number).split(',').map(s => s.trim());
                targets.forEach(t => {
                    if (reqLookup.has(t)) {
                        const impl = { name: item.jkName || "Link", type: item.jkType === 'risk' ? 'risk' : 'plan', details: item.RiskDescription || item.PlanObjective, children: [] };
                        if (item.controls) {
                            item.controls.forEach(c => impl.children.push({ name: c.control_number || c.jkName, type: 'control', details: c.jkText }));
                        }
                        reqLookup.get(t).children.push(impl);
                    }
                });
            }
        });
    });
    return hierarchy;
}

function update(source) {
    const nodes = treeLayout(root).descendants();
    const links = treeLayout(root).links();
    nodes.forEach(d => d.y = d.depth * 280);

    const node = g.selectAll('g.node').data(nodes, d => d.id || (d.id = ++i));
    const nodeEnter = node.enter().append('g')
        .attr('class', d => `node node-${d.data.type}`)
        .attr('transform', d => `translate(${source.y0 || 0}, ${source.x0 || 0})`)
        .on('click', (e, d) => {
            if (d.children) { d._children = d.children; d.children = null; }
            else { d.children = d._children; d._children = null; }
            update(d);
        })
        .on('mouseover', (e, d) => {
            tooltip.transition().duration(200).style("opacity", .9);
            tooltip.html(`<strong>${d.data.name}</strong><br/>${d.data.details || ''}`)
                .style("left", (e.pageX + 15) + "px").style("top", (e.pageY - 20) + "px");
        })
        .on('mouseout', () => tooltip.transition().style("opacity", 0));

    nodeEnter.append('circle').attr('r', 1e-6);
    nodeEnter.append('text').attr("dy", ".35em").attr("x", d => d.children || d._children ? -12 : 12)
        .attr("text-anchor", d => d.children || d._children ? "end" : "start").text(d => d.data.name);

    const nodeUpdate = nodeEnter.merge(node);
    nodeUpdate.transition().duration(400).attr('transform', d => `translate(${d.y}, ${d.x})`);
    nodeUpdate.select('circle').attr('r', 7).style("fill", d => d._children ? "#475569" : "#fff");

    node.exit().transition().duration(400).attr('transform', d => `translate(${source.y}, ${source.x})`).remove();

    const link = g.selectAll('path.link').data(links, d => d.target.id);
    const linkEnter = link.enter().insert('path', 'g').attr('class', 'link')
        .attr('d', d => { const o = {x: source.x0 || 0, y: source.y0 || 0}; return diagonal(o, o); });
    linkEnter.merge(link).transition().duration(400).attr('d', d => diagonal(d.source, d.target));
    link.exit().transition().duration(400).attr('d', d => { const o = {x: source.x, y: source.y}; return diagonal(o, o); }).remove();

    nodes.forEach(d => { d.x0 = d.x; d.y0 = d.y; });
}

function diagonal(s, t) {
    return `M ${s.y} ${s.x} C ${(s.y + t.y) / 2} ${s.x}, ${(s.y + t.y) / 2} ${t.x}, ${t.y} ${t.x}`;
}

// Initial Run
const hierarchyData = processData(rawData);
root = d3.hierarchy(hierarchyData);
root.children.forEach(c => { if(c.children) { c._children = c.children; c.children = null; } });
update(root);

</script>
</body>
</html>